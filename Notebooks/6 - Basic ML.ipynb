{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "490a64b3-ef71-4463-bb99-3903b5782fd0",
   "metadata": {},
   "source": [
    "# Basic ML: Phonocardiograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1bcf3d-b7a4-46e4-89b0-c3073d6a5e10",
   "metadata": {},
   "source": [
    "Author: Jake Dumbauld <br>\n",
    "Contact: jacobmilodumbauld@gmail.com<br>\n",
    "Date: 3.15.22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8632aee3-b257-4d30-9be6-13034a9a4c96",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a727db3-572e-4988-abac-7e33c5d7dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca4e45f-7c17-4d89-b52b-45b798ac31e4",
   "metadata": {},
   "source": [
    "## Building a Simple Feed Forward Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba3608-a70b-4491-a3cc-1268e387bedd",
   "metadata": {},
   "source": [
    "### Raw Signal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ad96ac-603a-4973-9643-310efa70af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = np.load('/Users/jmd/Documents/BOOTCAMP/Capstone/arrays/signal_murmur_presimple_4k.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e774fae-a8e5-4f4a-866b-5ac310c22a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = raw[:,0] #murmurs are just the first column\n",
    "X = raw[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8700e168-ed96-4c3b-bce5-ad781e8bed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2a75d99-8f38-4679-8da4-305c92aa5147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Declare the hidden layers\n",
    "model.add(layers.Dense(1024, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.BatchNormalization()) \n",
    "\n",
    "model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.BatchNormalization())  \n",
    "\n",
    "model.add(layers.Dense(128, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.BatchNormalization())  \n",
    "\n",
    "model.add(layers.Dense(32, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "# Declare the output layer\n",
    "model.add(layers.Dense(1, kernel_regularizer=regularizers.l2(0.001), activation=\"sigmoid\"))\n",
    "\n",
    "#declaring learning rate schedule\n",
    "lr_schedule = keras.optimizers.schedules.InverseTimeDecay(0.0001, decay_steps=1.0, decay_rate=0.1)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    # Optimizer\n",
    "    optimizer=keras.optimizers.Adam(lr_schedule),  \n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    # Metric used to evaluate model\n",
    "    metrics=[keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e4e4a10-e7ad-40b1-803a-21adcd9e650d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 30s 630ms/step - loss: 3.6824 - binary_accuracy: 0.6136 - val_loss: 3.6331 - val_binary_accuracy: 0.7389\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.6075 - binary_accuracy: 0.6505 - val_loss: 3.6206 - val_binary_accuracy: 0.7943\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.6486 - binary_accuracy: 0.6446 - val_loss: 3.6087 - val_binary_accuracy: 0.8070\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 28s 618ms/step - loss: 3.6099 - binary_accuracy: 0.6735 - val_loss: 3.6059 - val_binary_accuracy: 0.7896\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 28s 619ms/step - loss: 3.6192 - binary_accuracy: 0.6530 - val_loss: 3.6003 - val_binary_accuracy: 0.7880\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 28s 618ms/step - loss: 3.6137 - binary_accuracy: 0.6581 - val_loss: 3.5946 - val_binary_accuracy: 0.7816\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 28s 612ms/step - loss: 3.5918 - binary_accuracy: 0.6599 - val_loss: 3.5892 - val_binary_accuracy: 0.7737\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.6022 - binary_accuracy: 0.6575 - val_loss: 3.5886 - val_binary_accuracy: 0.7563\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.5560 - binary_accuracy: 0.6908 - val_loss: 3.5891 - val_binary_accuracy: 0.7373\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5547 - binary_accuracy: 0.6986 - val_loss: 3.5913 - val_binary_accuracy: 0.7278\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 28s 611ms/step - loss: 3.5775 - binary_accuracy: 0.6780 - val_loss: 3.5915 - val_binary_accuracy: 0.7104\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 28s 613ms/step - loss: 3.5808 - binary_accuracy: 0.6613 - val_loss: 3.5885 - val_binary_accuracy: 0.7104\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 28s 619ms/step - loss: 3.5777 - binary_accuracy: 0.6761 - val_loss: 3.5897 - val_binary_accuracy: 0.6962\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 29s 627ms/step - loss: 3.5922 - binary_accuracy: 0.6672 - val_loss: 3.5875 - val_binary_accuracy: 0.6994\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 28s 612ms/step - loss: 3.6108 - binary_accuracy: 0.6485 - val_loss: 3.5862 - val_binary_accuracy: 0.7041\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.6001 - binary_accuracy: 0.6543 - val_loss: 3.5847 - val_binary_accuracy: 0.7104\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 28s 618ms/step - loss: 3.5953 - binary_accuracy: 0.6828 - val_loss: 3.5843 - val_binary_accuracy: 0.7168\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 28s 613ms/step - loss: 3.6012 - binary_accuracy: 0.6676 - val_loss: 3.5826 - val_binary_accuracy: 0.7136\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 28s 612ms/step - loss: 3.5693 - binary_accuracy: 0.7090 - val_loss: 3.5785 - val_binary_accuracy: 0.7199\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 28s 614ms/step - loss: 3.5475 - binary_accuracy: 0.7257 - val_loss: 3.5796 - val_binary_accuracy: 0.7184\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.5742 - binary_accuracy: 0.6872 - val_loss: 3.5778 - val_binary_accuracy: 0.7199\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5500 - binary_accuracy: 0.6858 - val_loss: 3.5806 - val_binary_accuracy: 0.7199\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.5289 - binary_accuracy: 0.7060 - val_loss: 3.5779 - val_binary_accuracy: 0.7247\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 28s 618ms/step - loss: 3.5822 - binary_accuracy: 0.6752 - val_loss: 3.5788 - val_binary_accuracy: 0.7199\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 28s 613ms/step - loss: 3.5709 - binary_accuracy: 0.6743 - val_loss: 3.5814 - val_binary_accuracy: 0.7199\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.5544 - binary_accuracy: 0.6988 - val_loss: 3.5812 - val_binary_accuracy: 0.7215\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 28s 619ms/step - loss: 3.5530 - binary_accuracy: 0.6810 - val_loss: 3.5770 - val_binary_accuracy: 0.7231\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 28s 613ms/step - loss: 3.5065 - binary_accuracy: 0.7287 - val_loss: 3.5768 - val_binary_accuracy: 0.7231\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5640 - binary_accuracy: 0.7077 - val_loss: 3.5758 - val_binary_accuracy: 0.7184\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 28s 614ms/step - loss: 3.5448 - binary_accuracy: 0.6893 - val_loss: 3.5722 - val_binary_accuracy: 0.7358\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 28s 618ms/step - loss: 3.5557 - binary_accuracy: 0.7111 - val_loss: 3.5742 - val_binary_accuracy: 0.7231\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 28s 619ms/step - loss: 3.5892 - binary_accuracy: 0.6627 - val_loss: 3.5761 - val_binary_accuracy: 0.7215\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5532 - binary_accuracy: 0.7040 - val_loss: 3.5771 - val_binary_accuracy: 0.7136\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 28s 617ms/step - loss: 3.5110 - binary_accuracy: 0.7210 - val_loss: 3.5777 - val_binary_accuracy: 0.7152\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5449 - binary_accuracy: 0.6752 - val_loss: 3.5768 - val_binary_accuracy: 0.7136\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 28s 613ms/step - loss: 3.5449 - binary_accuracy: 0.6887 - val_loss: 3.5764 - val_binary_accuracy: 0.7199\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 28s 618ms/step - loss: 3.5266 - binary_accuracy: 0.7018 - val_loss: 3.5721 - val_binary_accuracy: 0.7294\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5525 - binary_accuracy: 0.6804 - val_loss: 3.5720 - val_binary_accuracy: 0.7326\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.5364 - binary_accuracy: 0.6994 - val_loss: 3.5718 - val_binary_accuracy: 0.7310\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 28s 612ms/step - loss: 3.5515 - binary_accuracy: 0.7136 - val_loss: 3.5708 - val_binary_accuracy: 0.7342\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.5533 - binary_accuracy: 0.6787 - val_loss: 3.5706 - val_binary_accuracy: 0.7326\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5522 - binary_accuracy: 0.6698 - val_loss: 3.5725 - val_binary_accuracy: 0.7199\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 28s 617ms/step - loss: 3.5300 - binary_accuracy: 0.6985 - val_loss: 3.5725 - val_binary_accuracy: 0.7278\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.5167 - binary_accuracy: 0.7097 - val_loss: 3.5736 - val_binary_accuracy: 0.7199\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 28s 620ms/step - loss: 3.5410 - binary_accuracy: 0.7120 - val_loss: 3.5719 - val_binary_accuracy: 0.7263\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5745 - binary_accuracy: 0.6755 - val_loss: 3.5737 - val_binary_accuracy: 0.7231\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 28s 614ms/step - loss: 3.5525 - binary_accuracy: 0.6985 - val_loss: 3.5701 - val_binary_accuracy: 0.7310\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 28s 617ms/step - loss: 3.5574 - binary_accuracy: 0.6940 - val_loss: 3.5678 - val_binary_accuracy: 0.7358\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 28s 613ms/step - loss: 3.5076 - binary_accuracy: 0.7191 - val_loss: 3.5677 - val_binary_accuracy: 0.7373\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5244 - binary_accuracy: 0.7085 - val_loss: 3.5693 - val_binary_accuracy: 0.7310\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 28s 618ms/step - loss: 3.5488 - binary_accuracy: 0.7080 - val_loss: 3.5680 - val_binary_accuracy: 0.7358\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5261 - binary_accuracy: 0.7165 - val_loss: 3.5683 - val_binary_accuracy: 0.7326\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 28s 611ms/step - loss: 3.5286 - binary_accuracy: 0.7063 - val_loss: 3.5705 - val_binary_accuracy: 0.7247\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 28s 613ms/step - loss: 3.5102 - binary_accuracy: 0.7325 - val_loss: 3.5664 - val_binary_accuracy: 0.7342\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5077 - binary_accuracy: 0.6988 - val_loss: 3.5652 - val_binary_accuracy: 0.7373\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 28s 618ms/step - loss: 3.5134 - binary_accuracy: 0.7291 - val_loss: 3.5668 - val_binary_accuracy: 0.7278\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 28s 614ms/step - loss: 3.5824 - binary_accuracy: 0.6861 - val_loss: 3.5659 - val_binary_accuracy: 0.7373\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 29s 638ms/step - loss: 3.5151 - binary_accuracy: 0.7043 - val_loss: 3.5635 - val_binary_accuracy: 0.7405\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 28s 620ms/step - loss: 3.5231 - binary_accuracy: 0.6985 - val_loss: 3.5628 - val_binary_accuracy: 0.7373\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.5531 - binary_accuracy: 0.6766 - val_loss: 3.5610 - val_binary_accuracy: 0.7405\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5647 - binary_accuracy: 0.6760 - val_loss: 3.5635 - val_binary_accuracy: 0.7342\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 28s 613ms/step - loss: 3.5384 - binary_accuracy: 0.7066 - val_loss: 3.5659 - val_binary_accuracy: 0.7373\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.5404 - binary_accuracy: 0.6887 - val_loss: 3.5654 - val_binary_accuracy: 0.7373\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5425 - binary_accuracy: 0.6989 - val_loss: 3.5633 - val_binary_accuracy: 0.7405\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 28s 613ms/step - loss: 3.5305 - binary_accuracy: 0.6936 - val_loss: 3.5646 - val_binary_accuracy: 0.7342\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5277 - binary_accuracy: 0.6958 - val_loss: 3.5625 - val_binary_accuracy: 0.7389\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 28s 616ms/step - loss: 3.5273 - binary_accuracy: 0.7151 - val_loss: 3.5616 - val_binary_accuracy: 0.7468\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 28s 618ms/step - loss: 3.5426 - binary_accuracy: 0.6880 - val_loss: 3.5623 - val_binary_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 28s 621ms/step - loss: 3.5710 - binary_accuracy: 0.6786 - val_loss: 3.5629 - val_binary_accuracy: 0.7453\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 28s 611ms/step - loss: 3.5285 - binary_accuracy: 0.6971 - val_loss: 3.5634 - val_binary_accuracy: 0.7405\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 28s 619ms/step - loss: 3.4916 - binary_accuracy: 0.7287 - val_loss: 3.5637 - val_binary_accuracy: 0.7373\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 28s 618ms/step - loss: 3.5391 - binary_accuracy: 0.7039 - val_loss: 3.5613 - val_binary_accuracy: 0.7326\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 29s 636ms/step - loss: 3.5364 - binary_accuracy: 0.6922 - val_loss: 3.5644 - val_binary_accuracy: 0.7358\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 28s 623ms/step - loss: 3.4936 - binary_accuracy: 0.7177 - val_loss: 3.5641 - val_binary_accuracy: 0.7326\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 28s 617ms/step - loss: 3.5254 - binary_accuracy: 0.7147 - val_loss: 3.5656 - val_binary_accuracy: 0.7326\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 29s 625ms/step - loss: 3.5390 - binary_accuracy: 0.7172 - val_loss: 3.5627 - val_binary_accuracy: 0.7373\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 29s 624ms/step - loss: 3.5309 - binary_accuracy: 0.6989 - val_loss: 3.5626 - val_binary_accuracy: 0.7373\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 28s 613ms/step - loss: 3.5335 - binary_accuracy: 0.7099 - val_loss: 3.5635 - val_binary_accuracy: 0.7342\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 28s 613ms/step - loss: 3.5186 - binary_accuracy: 0.7272 - val_loss: 3.5647 - val_binary_accuracy: 0.7310\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.4856 - binary_accuracy: 0.7442 - val_loss: 3.5638 - val_binary_accuracy: 0.7342\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 28s 615ms/step - loss: 3.5105 - binary_accuracy: 0.7116 - val_loss: 3.5632 - val_binary_accuracy: 0.7326\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 29s 627ms/step - loss: 3.5092 - binary_accuracy: 0.7165 - val_loss: 3.5598 - val_binary_accuracy: 0.7389\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 29s 638ms/step - loss: 3.5114 - binary_accuracy: 0.7260 - val_loss: 3.5594 - val_binary_accuracy: 0.7437\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 28s 619ms/step - loss: 3.5542 - binary_accuracy: 0.6813 - val_loss: 3.5624 - val_binary_accuracy: 0.7294\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 28s 617ms/step - loss: 3.5389 - binary_accuracy: 0.7067 - val_loss: 3.5628 - val_binary_accuracy: 0.7294\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 28s 621ms/step - loss: 3.5077 - binary_accuracy: 0.7231 - val_loss: 3.5649 - val_binary_accuracy: 0.7310\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 28s 618ms/step - loss: 3.5101 - binary_accuracy: 0.7039 - val_loss: 3.5629 - val_binary_accuracy: 0.7326\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 29s 623ms/step - loss: 3.5312 - binary_accuracy: 0.6992 - val_loss: 3.5631 - val_binary_accuracy: 0.7342\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 28s 620ms/step - loss: 3.5287 - binary_accuracy: 0.7186 - val_loss: 3.5626 - val_binary_accuracy: 0.7310\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 28s 622ms/step - loss: 3.5314 - binary_accuracy: 0.7354 - val_loss: 3.5627 - val_binary_accuracy: 0.7358\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 28s 620ms/step - loss: 3.5246 - binary_accuracy: 0.6939 - val_loss: 3.5622 - val_binary_accuracy: 0.7342\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 28s 619ms/step - loss: 3.5320 - binary_accuracy: 0.7232 - val_loss: 3.5610 - val_binary_accuracy: 0.7310\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 28s 618ms/step - loss: 3.5185 - binary_accuracy: 0.7119 - val_loss: 3.5623 - val_binary_accuracy: 0.7326\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 28s 613ms/step - loss: 3.5004 - binary_accuracy: 0.7168 - val_loss: 3.5609 - val_binary_accuracy: 0.7342\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 28s 614ms/step - loss: 3.5390 - binary_accuracy: 0.7050 - val_loss: 3.5624 - val_binary_accuracy: 0.7294\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 29s 625ms/step - loss: 3.5242 - binary_accuracy: 0.7060 - val_loss: 3.5617 - val_binary_accuracy: 0.7342\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 29s 642ms/step - loss: 3.5019 - binary_accuracy: 0.7198 - val_loss: 3.5605 - val_binary_accuracy: 0.7421\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 28s 622ms/step - loss: 3.5341 - binary_accuracy: 0.6996 - val_loss: 3.5603 - val_binary_accuracy: 0.7405\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 30s 647ms/step - loss: 3.5184 - binary_accuracy: 0.6906 - val_loss: 3.5610 - val_binary_accuracy: 0.7405\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 29s 635ms/step - loss: 3.5352 - binary_accuracy: 0.6977 - val_loss: 3.5624 - val_binary_accuracy: 0.7326\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a451965-81a2-451b-8e62-8907f96e1e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1862a9cc-4f0f-4b73-b00f-d90ab893ddc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 9s 308ms/step - loss: 3.5599 - binary_accuracy: 0.7453\n",
      "Train Accuracy: 0.7072\n",
      "Test Accuracy: 0.7453\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the network\n",
    "train_accuracy = history.history[\"binary_accuracy\"][-1]\n",
    "result = model.evaluate(X_test,y_test, verbose=1)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {result[1]:.4f}\")\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "27f0aa5b-4b98-4067-bc77-5d4e00df3b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_74 (Dense)             (None, 1024)              50332672  \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 50,933,953\n",
      "Trainable params: 50,930,625\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7e5c40dd-05cb-4955-8693-224896850f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/jmd/Documents/BOOTCAMP/Capstone/neural_nets/FFN_raw_signal_no_patient/assets\n"
     ]
    }
   ],
   "source": [
    "#saving model\n",
    "model.save('/Users/jmd/Documents/BOOTCAMP/Capstone/neural_nets/FFN_raw_signal_no_patient')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aeefa3-bcaf-41f3-bf1d-f5992fc146ae",
   "metadata": {},
   "source": [
    "### MFCC w/o Patient Info: FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0469d9a6-6eee-40b9-897f-652af987c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('/Users/jmd/Documents/BOOTCAMP/Capstone/arrays/MFCCs_noPatient.npy', allow_pickle=True)\n",
    "y = np.load('/Users/jmd/Documents/BOOTCAMP/Capstone/arrays/target_array.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e7548a1-d54a-46cc-9aa9-d7c5d4c34643",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab399487-3006-412e-a515-6af0f1cc7c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2104, 20, 97)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61351265-004f-4088-a2ed-3cf4878afb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new sequential model\n",
    "FNN_MFCC_n_pt = keras.Sequential()\n",
    "\n",
    "# Declare the hidden layers\n",
    "FNN_MFCC_n_pt.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"))\n",
    "#model.add(layers.Dropout(0.4))\n",
    "FNN_MFCC_n_pt.add(layers.BatchNormalization())  \n",
    "\n",
    "FNN_MFCC_n_pt.add(layers.Dense(128, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"))\n",
    "#model.add(layers.Dropout(0.4))\n",
    "FNN_MFCC_n_pt.add(layers.BatchNormalization())  \n",
    "\n",
    "FNN_MFCC_n_pt.add(layers.Dense(32, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"))\n",
    "#model.add(layers.Dropout(0.4))\n",
    "\n",
    "# Declare the output layer\n",
    "FNN_MFCC_n_pt.add(layers.Dense(1, kernel_regularizer=regularizers.l2(0.001), activation=\"sigmoid\"))\n",
    "\n",
    "#declaring learning rate schedule\n",
    "lr_schedule = keras.optimizers.schedules.InverseTimeDecay(0.001, decay_steps=1.0, decay_rate=0.1)\n",
    "\n",
    "\n",
    "FNN_MFCC_n_pt.compile(\n",
    "    # Optimizer\n",
    "    optimizer=keras.optimizers.Adam(lr_schedule),  \n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    # Metric used to evaluate model\n",
    "    metrics=[keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0457e4a-96e8-4f85-839b-6c0a514d2382",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.9450 - binary_accuracy: 0.7848 - val_loss: 1.0170 - val_binary_accuracy: 0.7397\n",
      "Epoch 2/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8828 - binary_accuracy: 0.8012 - val_loss: 0.9220 - val_binary_accuracy: 0.7800\n",
      "Epoch 3/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8768 - binary_accuracy: 0.7945 - val_loss: 0.8924 - val_binary_accuracy: 0.7881\n",
      "Epoch 4/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8604 - binary_accuracy: 0.8012 - val_loss: 0.8791 - val_binary_accuracy: 0.7915\n",
      "Epoch 5/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8413 - binary_accuracy: 0.8086 - val_loss: 0.8727 - val_binary_accuracy: 0.7922\n",
      "Epoch 6/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8324 - binary_accuracy: 0.8104 - val_loss: 0.8678 - val_binary_accuracy: 0.7924\n",
      "Epoch 7/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8522 - binary_accuracy: 0.7934 - val_loss: 0.8645 - val_binary_accuracy: 0.7926\n",
      "Epoch 8/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8447 - binary_accuracy: 0.7959 - val_loss: 0.8615 - val_binary_accuracy: 0.7930\n",
      "Epoch 9/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8457 - binary_accuracy: 0.7920 - val_loss: 0.8592 - val_binary_accuracy: 0.7933\n",
      "Epoch 10/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8399 - binary_accuracy: 0.7934 - val_loss: 0.8572 - val_binary_accuracy: 0.7931\n",
      "Epoch 11/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8358 - binary_accuracy: 0.7939 - val_loss: 0.8553 - val_binary_accuracy: 0.7929\n",
      "Epoch 12/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8490 - binary_accuracy: 0.7841 - val_loss: 0.8537 - val_binary_accuracy: 0.7930\n",
      "Epoch 13/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8317 - binary_accuracy: 0.7950 - val_loss: 0.8522 - val_binary_accuracy: 0.7929\n",
      "Epoch 14/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8164 - binary_accuracy: 0.8048 - val_loss: 0.8510 - val_binary_accuracy: 0.7930\n",
      "Epoch 15/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8269 - binary_accuracy: 0.7956 - val_loss: 0.8495 - val_binary_accuracy: 0.7932\n",
      "Epoch 16/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8111 - binary_accuracy: 0.8062 - val_loss: 0.8484 - val_binary_accuracy: 0.7930\n",
      "Epoch 17/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8379 - binary_accuracy: 0.7839 - val_loss: 0.8472 - val_binary_accuracy: 0.7930\n",
      "Epoch 18/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8412 - binary_accuracy: 0.7800 - val_loss: 0.8461 - val_binary_accuracy: 0.7929\n",
      "Epoch 19/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8086 - binary_accuracy: 0.8038 - val_loss: 0.8451 - val_binary_accuracy: 0.7929\n",
      "Epoch 20/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8333 - binary_accuracy: 0.7837 - val_loss: 0.8442 - val_binary_accuracy: 0.7930\n",
      "Epoch 21/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7943 - binary_accuracy: 0.8141 - val_loss: 0.8433 - val_binary_accuracy: 0.7930\n",
      "Epoch 22/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8131 - binary_accuracy: 0.7985 - val_loss: 0.8426 - val_binary_accuracy: 0.7930\n",
      "Epoch 23/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8056 - binary_accuracy: 0.8030 - val_loss: 0.8418 - val_binary_accuracy: 0.7926\n",
      "Epoch 24/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8342 - binary_accuracy: 0.7794 - val_loss: 0.8411 - val_binary_accuracy: 0.7927\n",
      "Epoch 25/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8334 - binary_accuracy: 0.7802 - val_loss: 0.8404 - val_binary_accuracy: 0.7928\n",
      "Epoch 26/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8176 - binary_accuracy: 0.7922 - val_loss: 0.8398 - val_binary_accuracy: 0.7924\n",
      "Epoch 27/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8061 - binary_accuracy: 0.7977 - val_loss: 0.8391 - val_binary_accuracy: 0.7926\n",
      "Epoch 28/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.8286 - binary_accuracy: 0.7827 - val_loss: 0.8385 - val_binary_accuracy: 0.7925\n",
      "Epoch 29/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8412 - binary_accuracy: 0.7722 - val_loss: 0.8379 - val_binary_accuracy: 0.7927\n",
      "Epoch 30/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8049 - binary_accuracy: 0.7985 - val_loss: 0.8373 - val_binary_accuracy: 0.7927\n",
      "Epoch 31/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7986 - binary_accuracy: 0.8020 - val_loss: 0.8369 - val_binary_accuracy: 0.7927\n",
      "Epoch 32/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7912 - binary_accuracy: 0.8062 - val_loss: 0.8364 - val_binary_accuracy: 0.7926\n",
      "Epoch 33/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8033 - binary_accuracy: 0.7977 - val_loss: 0.8359 - val_binary_accuracy: 0.7928\n",
      "Epoch 34/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8068 - binary_accuracy: 0.7938 - val_loss: 0.8354 - val_binary_accuracy: 0.7929\n",
      "Epoch 35/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7896 - binary_accuracy: 0.8086 - val_loss: 0.8350 - val_binary_accuracy: 0.7926\n",
      "Epoch 36/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7738 - binary_accuracy: 0.8186 - val_loss: 0.8346 - val_binary_accuracy: 0.7927\n",
      "Epoch 37/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7938 - binary_accuracy: 0.8041 - val_loss: 0.8342 - val_binary_accuracy: 0.7925\n",
      "Epoch 38/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7999 - binary_accuracy: 0.7974 - val_loss: 0.8337 - val_binary_accuracy: 0.7926\n",
      "Epoch 39/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7984 - binary_accuracy: 0.7974 - val_loss: 0.8334 - val_binary_accuracy: 0.7926\n",
      "Epoch 40/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8016 - binary_accuracy: 0.7962 - val_loss: 0.8330 - val_binary_accuracy: 0.7926\n",
      "Epoch 41/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8053 - binary_accuracy: 0.7933 - val_loss: 0.8326 - val_binary_accuracy: 0.7926\n",
      "Epoch 42/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7506 - binary_accuracy: 0.8349 - val_loss: 0.8323 - val_binary_accuracy: 0.7924\n",
      "Epoch 43/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7853 - binary_accuracy: 0.8062 - val_loss: 0.8319 - val_binary_accuracy: 0.7925\n",
      "Epoch 44/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8032 - binary_accuracy: 0.7932 - val_loss: 0.8316 - val_binary_accuracy: 0.7926\n",
      "Epoch 45/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7916 - binary_accuracy: 0.8004 - val_loss: 0.8312 - val_binary_accuracy: 0.7926\n",
      "Epoch 46/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8030 - binary_accuracy: 0.7927 - val_loss: 0.8310 - val_binary_accuracy: 0.7926\n",
      "Epoch 47/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7865 - binary_accuracy: 0.8043 - val_loss: 0.8306 - val_binary_accuracy: 0.7924\n",
      "Epoch 48/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7917 - binary_accuracy: 0.8008 - val_loss: 0.8304 - val_binary_accuracy: 0.7926\n",
      "Epoch 49/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7803 - binary_accuracy: 0.8096 - val_loss: 0.8300 - val_binary_accuracy: 0.7926\n",
      "Epoch 50/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8079 - binary_accuracy: 0.7870 - val_loss: 0.8298 - val_binary_accuracy: 0.7926\n",
      "Epoch 51/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7869 - binary_accuracy: 0.8031 - val_loss: 0.8295 - val_binary_accuracy: 0.7925\n",
      "Epoch 52/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8134 - binary_accuracy: 0.7834 - val_loss: 0.8293 - val_binary_accuracy: 0.7926\n",
      "Epoch 53/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7789 - binary_accuracy: 0.8095 - val_loss: 0.8290 - val_binary_accuracy: 0.7924\n",
      "Epoch 54/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7955 - binary_accuracy: 0.7941 - val_loss: 0.8287 - val_binary_accuracy: 0.7924\n",
      "Epoch 55/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7877 - binary_accuracy: 0.8014 - val_loss: 0.8284 - val_binary_accuracy: 0.7926\n",
      "Epoch 56/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8013 - binary_accuracy: 0.7905 - val_loss: 0.8282 - val_binary_accuracy: 0.7925\n",
      "Epoch 57/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7720 - binary_accuracy: 0.8130 - val_loss: 0.8279 - val_binary_accuracy: 0.7925\n",
      "Epoch 58/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7681 - binary_accuracy: 0.8162 - val_loss: 0.8277 - val_binary_accuracy: 0.7924\n",
      "Epoch 59/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8008 - binary_accuracy: 0.7896 - val_loss: 0.8275 - val_binary_accuracy: 0.7925\n",
      "Epoch 60/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7877 - binary_accuracy: 0.7996 - val_loss: 0.8273 - val_binary_accuracy: 0.7923\n",
      "Epoch 61/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7975 - binary_accuracy: 0.7915 - val_loss: 0.8271 - val_binary_accuracy: 0.7922\n",
      "Epoch 62/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8058 - binary_accuracy: 0.7841 - val_loss: 0.8268 - val_binary_accuracy: 0.7922\n",
      "Epoch 63/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7681 - binary_accuracy: 0.8143 - val_loss: 0.8266 - val_binary_accuracy: 0.7923\n",
      "Epoch 64/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7964 - binary_accuracy: 0.7911 - val_loss: 0.8264 - val_binary_accuracy: 0.7922\n",
      "Epoch 65/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7914 - binary_accuracy: 0.7936 - val_loss: 0.8262 - val_binary_accuracy: 0.7922\n",
      "Epoch 66/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7853 - binary_accuracy: 0.7995 - val_loss: 0.8260 - val_binary_accuracy: 0.7922\n",
      "Epoch 67/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7996 - binary_accuracy: 0.7871 - val_loss: 0.8258 - val_binary_accuracy: 0.7923\n",
      "Epoch 68/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7905 - binary_accuracy: 0.7960 - val_loss: 0.8256 - val_binary_accuracy: 0.7923\n",
      "Epoch 69/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7750 - binary_accuracy: 0.8077 - val_loss: 0.8254 - val_binary_accuracy: 0.7924\n",
      "Epoch 70/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7805 - binary_accuracy: 0.8013 - val_loss: 0.8253 - val_binary_accuracy: 0.7922\n",
      "Epoch 71/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7652 - binary_accuracy: 0.8149 - val_loss: 0.8251 - val_binary_accuracy: 0.7922\n",
      "Epoch 72/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8002 - binary_accuracy: 0.7879 - val_loss: 0.8249 - val_binary_accuracy: 0.7922\n",
      "Epoch 73/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8041 - binary_accuracy: 0.7836 - val_loss: 0.8247 - val_binary_accuracy: 0.7922\n",
      "Epoch 74/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7882 - binary_accuracy: 0.7964 - val_loss: 0.8245 - val_binary_accuracy: 0.7922\n",
      "Epoch 75/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7951 - binary_accuracy: 0.7922 - val_loss: 0.8244 - val_binary_accuracy: 0.7922\n",
      "Epoch 76/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7779 - binary_accuracy: 0.8040 - val_loss: 0.8242 - val_binary_accuracy: 0.7921\n",
      "Epoch 77/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7797 - binary_accuracy: 0.7999 - val_loss: 0.8241 - val_binary_accuracy: 0.7921\n",
      "Epoch 78/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7871 - binary_accuracy: 0.7961 - val_loss: 0.8239 - val_binary_accuracy: 0.7922\n",
      "Epoch 79/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8125 - binary_accuracy: 0.7744 - val_loss: 0.8237 - val_binary_accuracy: 0.7921\n",
      "Epoch 80/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7765 - binary_accuracy: 0.8035 - val_loss: 0.8236 - val_binary_accuracy: 0.7921\n",
      "Epoch 81/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8009 - binary_accuracy: 0.7848 - val_loss: 0.8234 - val_binary_accuracy: 0.7921\n",
      "Epoch 82/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7719 - binary_accuracy: 0.8063 - val_loss: 0.8233 - val_binary_accuracy: 0.7923\n",
      "Epoch 83/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7668 - binary_accuracy: 0.8103 - val_loss: 0.8231 - val_binary_accuracy: 0.7921\n",
      "Epoch 84/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7704 - binary_accuracy: 0.8082 - val_loss: 0.8230 - val_binary_accuracy: 0.7922\n",
      "Epoch 85/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7660 - binary_accuracy: 0.8122 - val_loss: 0.8228 - val_binary_accuracy: 0.7922\n",
      "Epoch 86/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7750 - binary_accuracy: 0.8047 - val_loss: 0.8227 - val_binary_accuracy: 0.7922\n",
      "Epoch 87/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7740 - binary_accuracy: 0.8039 - val_loss: 0.8225 - val_binary_accuracy: 0.7923\n",
      "Epoch 88/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7747 - binary_accuracy: 0.8052 - val_loss: 0.8224 - val_binary_accuracy: 0.7923\n",
      "Epoch 89/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7873 - binary_accuracy: 0.7931 - val_loss: 0.8223 - val_binary_accuracy: 0.7925\n",
      "Epoch 90/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7875 - binary_accuracy: 0.7927 - val_loss: 0.8221 - val_binary_accuracy: 0.7923\n",
      "Epoch 91/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7919 - binary_accuracy: 0.7880 - val_loss: 0.8220 - val_binary_accuracy: 0.7923\n",
      "Epoch 92/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7824 - binary_accuracy: 0.7968 - val_loss: 0.8219 - val_binary_accuracy: 0.7922\n",
      "Epoch 93/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7605 - binary_accuracy: 0.8140 - val_loss: 0.8217 - val_binary_accuracy: 0.7922\n",
      "Epoch 94/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7858 - binary_accuracy: 0.7943 - val_loss: 0.8216 - val_binary_accuracy: 0.7922\n",
      "Epoch 95/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7927 - binary_accuracy: 0.7892 - val_loss: 0.8215 - val_binary_accuracy: 0.7922\n",
      "Epoch 96/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8011 - binary_accuracy: 0.7824 - val_loss: 0.8214 - val_binary_accuracy: 0.7922\n",
      "Epoch 97/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7643 - binary_accuracy: 0.8094 - val_loss: 0.8213 - val_binary_accuracy: 0.7923\n",
      "Epoch 98/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7950 - binary_accuracy: 0.7864 - val_loss: 0.8212 - val_binary_accuracy: 0.7923\n",
      "Epoch 99/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7784 - binary_accuracy: 0.7985 - val_loss: 0.8210 - val_binary_accuracy: 0.7923\n",
      "Epoch 100/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7746 - binary_accuracy: 0.8023 - val_loss: 0.8209 - val_binary_accuracy: 0.7924\n",
      "Epoch 101/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7752 - binary_accuracy: 0.8004 - val_loss: 0.8208 - val_binary_accuracy: 0.7922\n",
      "Epoch 102/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7926 - binary_accuracy: 0.7888 - val_loss: 0.8207 - val_binary_accuracy: 0.7924\n",
      "Epoch 103/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7779 - binary_accuracy: 0.7990 - val_loss: 0.8205 - val_binary_accuracy: 0.7923\n",
      "Epoch 104/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7911 - binary_accuracy: 0.7877 - val_loss: 0.8205 - val_binary_accuracy: 0.7925\n",
      "Epoch 105/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7752 - binary_accuracy: 0.8017 - val_loss: 0.8203 - val_binary_accuracy: 0.7925\n",
      "Epoch 106/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8046 - binary_accuracy: 0.7786 - val_loss: 0.8202 - val_binary_accuracy: 0.7925\n",
      "Epoch 107/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7805 - binary_accuracy: 0.7961 - val_loss: 0.8201 - val_binary_accuracy: 0.7925\n",
      "Epoch 108/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7934 - binary_accuracy: 0.7866 - val_loss: 0.8200 - val_binary_accuracy: 0.7925\n",
      "Epoch 109/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7748 - binary_accuracy: 0.7992 - val_loss: 0.8199 - val_binary_accuracy: 0.7926\n",
      "Epoch 110/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7661 - binary_accuracy: 0.8083 - val_loss: 0.8198 - val_binary_accuracy: 0.7925\n",
      "Epoch 111/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7671 - binary_accuracy: 0.8069 - val_loss: 0.8197 - val_binary_accuracy: 0.7926\n",
      "Epoch 112/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7775 - binary_accuracy: 0.7970 - val_loss: 0.8196 - val_binary_accuracy: 0.7926\n",
      "Epoch 113/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7585 - binary_accuracy: 0.8124 - val_loss: 0.8195 - val_binary_accuracy: 0.7926\n",
      "Epoch 114/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7605 - binary_accuracy: 0.8105 - val_loss: 0.8194 - val_binary_accuracy: 0.7926\n",
      "Epoch 115/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7858 - binary_accuracy: 0.7914 - val_loss: 0.8193 - val_binary_accuracy: 0.7926\n",
      "Epoch 116/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7859 - binary_accuracy: 0.7901 - val_loss: 0.8192 - val_binary_accuracy: 0.7926\n",
      "Epoch 117/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7510 - binary_accuracy: 0.8170 - val_loss: 0.8191 - val_binary_accuracy: 0.7926\n",
      "Epoch 118/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7839 - binary_accuracy: 0.7911 - val_loss: 0.8190 - val_binary_accuracy: 0.7926\n",
      "Epoch 119/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7813 - binary_accuracy: 0.7938 - val_loss: 0.8189 - val_binary_accuracy: 0.7926\n",
      "Epoch 120/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7812 - binary_accuracy: 0.7935 - val_loss: 0.8189 - val_binary_accuracy: 0.7926\n",
      "Epoch 121/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7725 - binary_accuracy: 0.8013 - val_loss: 0.8188 - val_binary_accuracy: 0.7926\n",
      "Epoch 122/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7769 - binary_accuracy: 0.7976 - val_loss: 0.8187 - val_binary_accuracy: 0.7926\n",
      "Epoch 123/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7937 - binary_accuracy: 0.7844 - val_loss: 0.8186 - val_binary_accuracy: 0.7926\n",
      "Epoch 124/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7614 - binary_accuracy: 0.8079 - val_loss: 0.8185 - val_binary_accuracy: 0.7926\n",
      "Epoch 125/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7814 - binary_accuracy: 0.7940 - val_loss: 0.8184 - val_binary_accuracy: 0.7925\n",
      "Epoch 126/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7647 - binary_accuracy: 0.8081 - val_loss: 0.8183 - val_binary_accuracy: 0.7925\n",
      "Epoch 127/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7715 - binary_accuracy: 0.8024 - val_loss: 0.8182 - val_binary_accuracy: 0.7924\n",
      "Epoch 128/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7767 - binary_accuracy: 0.7958 - val_loss: 0.8181 - val_binary_accuracy: 0.7925\n",
      "Epoch 129/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7694 - binary_accuracy: 0.8034 - val_loss: 0.8180 - val_binary_accuracy: 0.7925\n",
      "Epoch 130/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7891 - binary_accuracy: 0.7878 - val_loss: 0.8179 - val_binary_accuracy: 0.7924\n",
      "Epoch 131/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7816 - binary_accuracy: 0.7926 - val_loss: 0.8178 - val_binary_accuracy: 0.7925\n",
      "Epoch 132/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7625 - binary_accuracy: 0.8085 - val_loss: 0.8178 - val_binary_accuracy: 0.7926\n",
      "Epoch 133/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7701 - binary_accuracy: 0.8009 - val_loss: 0.8177 - val_binary_accuracy: 0.7925\n",
      "Epoch 134/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7702 - binary_accuracy: 0.8014 - val_loss: 0.8176 - val_binary_accuracy: 0.7925\n",
      "Epoch 135/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7775 - binary_accuracy: 0.7974 - val_loss: 0.8175 - val_binary_accuracy: 0.7924\n",
      "Epoch 136/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7674 - binary_accuracy: 0.8026 - val_loss: 0.8174 - val_binary_accuracy: 0.7926\n",
      "Epoch 137/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7693 - binary_accuracy: 0.8002 - val_loss: 0.8174 - val_binary_accuracy: 0.7925\n",
      "Epoch 138/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7788 - binary_accuracy: 0.7948 - val_loss: 0.8173 - val_binary_accuracy: 0.7925\n",
      "Epoch 139/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7638 - binary_accuracy: 0.8071 - val_loss: 0.8172 - val_binary_accuracy: 0.7926\n",
      "Epoch 140/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7504 - binary_accuracy: 0.8169 - val_loss: 0.8171 - val_binary_accuracy: 0.7926\n",
      "Epoch 141/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7568 - binary_accuracy: 0.8110 - val_loss: 0.8170 - val_binary_accuracy: 0.7925\n",
      "Epoch 142/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7637 - binary_accuracy: 0.8051 - val_loss: 0.8170 - val_binary_accuracy: 0.7926\n",
      "Epoch 143/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7699 - binary_accuracy: 0.8002 - val_loss: 0.8169 - val_binary_accuracy: 0.7925\n",
      "Epoch 144/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7724 - binary_accuracy: 0.7979 - val_loss: 0.8168 - val_binary_accuracy: 0.7925\n",
      "Epoch 145/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7499 - binary_accuracy: 0.8157 - val_loss: 0.8167 - val_binary_accuracy: 0.7925\n",
      "Epoch 146/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7667 - binary_accuracy: 0.8020 - val_loss: 0.8167 - val_binary_accuracy: 0.7925\n",
      "Epoch 147/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7655 - binary_accuracy: 0.8040 - val_loss: 0.8166 - val_binary_accuracy: 0.7926\n",
      "Epoch 148/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7868 - binary_accuracy: 0.7876 - val_loss: 0.8165 - val_binary_accuracy: 0.7925\n",
      "Epoch 149/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7616 - binary_accuracy: 0.8048 - val_loss: 0.8164 - val_binary_accuracy: 0.7924\n",
      "Epoch 150/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7771 - binary_accuracy: 0.7949 - val_loss: 0.8164 - val_binary_accuracy: 0.7925\n",
      "Epoch 151/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7768 - binary_accuracy: 0.7955 - val_loss: 0.8163 - val_binary_accuracy: 0.7923\n",
      "Epoch 152/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7726 - binary_accuracy: 0.7970 - val_loss: 0.8162 - val_binary_accuracy: 0.7923\n",
      "Epoch 153/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7718 - binary_accuracy: 0.7968 - val_loss: 0.8161 - val_binary_accuracy: 0.7924\n",
      "Epoch 154/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7695 - binary_accuracy: 0.7989 - val_loss: 0.8161 - val_binary_accuracy: 0.7924\n",
      "Epoch 155/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7871 - binary_accuracy: 0.7855 - val_loss: 0.8160 - val_binary_accuracy: 0.7924\n",
      "Epoch 156/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7655 - binary_accuracy: 0.8021 - val_loss: 0.8159 - val_binary_accuracy: 0.7925\n",
      "Epoch 157/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7822 - binary_accuracy: 0.7907 - val_loss: 0.8159 - val_binary_accuracy: 0.7924\n",
      "Epoch 158/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7490 - binary_accuracy: 0.8161 - val_loss: 0.8158 - val_binary_accuracy: 0.7923\n",
      "Epoch 159/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7822 - binary_accuracy: 0.7896 - val_loss: 0.8157 - val_binary_accuracy: 0.7925\n",
      "Epoch 160/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7600 - binary_accuracy: 0.8072 - val_loss: 0.8157 - val_binary_accuracy: 0.7924\n",
      "Epoch 161/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7654 - binary_accuracy: 0.8034 - val_loss: 0.8156 - val_binary_accuracy: 0.7925\n",
      "Epoch 162/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7659 - binary_accuracy: 0.7990 - val_loss: 0.8155 - val_binary_accuracy: 0.7925\n",
      "Epoch 163/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7630 - binary_accuracy: 0.8055 - val_loss: 0.8155 - val_binary_accuracy: 0.7925\n",
      "Epoch 164/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7757 - binary_accuracy: 0.7929 - val_loss: 0.8154 - val_binary_accuracy: 0.7925\n",
      "Epoch 165/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7794 - binary_accuracy: 0.7911 - val_loss: 0.8154 - val_binary_accuracy: 0.7925\n",
      "Epoch 166/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7775 - binary_accuracy: 0.7918 - val_loss: 0.8153 - val_binary_accuracy: 0.7925\n",
      "Epoch 167/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7754 - binary_accuracy: 0.7948 - val_loss: 0.8153 - val_binary_accuracy: 0.7925\n",
      "Epoch 168/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7440 - binary_accuracy: 0.8198 - val_loss: 0.8152 - val_binary_accuracy: 0.7925\n",
      "Epoch 169/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7764 - binary_accuracy: 0.7926 - val_loss: 0.8151 - val_binary_accuracy: 0.7925\n",
      "Epoch 170/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7626 - binary_accuracy: 0.8025 - val_loss: 0.8150 - val_binary_accuracy: 0.7925\n",
      "Epoch 171/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7644 - binary_accuracy: 0.8015 - val_loss: 0.8150 - val_binary_accuracy: 0.7926\n",
      "Epoch 172/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7964 - binary_accuracy: 0.7796 - val_loss: 0.8149 - val_binary_accuracy: 0.7926\n",
      "Epoch 173/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7658 - binary_accuracy: 0.8026 - val_loss: 0.8149 - val_binary_accuracy: 0.7926\n",
      "Epoch 174/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7833 - binary_accuracy: 0.7877 - val_loss: 0.8148 - val_binary_accuracy: 0.7926\n",
      "Epoch 175/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7672 - binary_accuracy: 0.7994 - val_loss: 0.8148 - val_binary_accuracy: 0.7926\n",
      "Epoch 176/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7648 - binary_accuracy: 0.8016 - val_loss: 0.8147 - val_binary_accuracy: 0.7926\n",
      "Epoch 177/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7761 - binary_accuracy: 0.7921 - val_loss: 0.8147 - val_binary_accuracy: 0.7926\n",
      "Epoch 178/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7534 - binary_accuracy: 0.8106 - val_loss: 0.8146 - val_binary_accuracy: 0.7926\n",
      "Epoch 179/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7572 - binary_accuracy: 0.8063 - val_loss: 0.8145 - val_binary_accuracy: 0.7926\n",
      "Epoch 180/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7430 - binary_accuracy: 0.8188 - val_loss: 0.8145 - val_binary_accuracy: 0.7925\n",
      "Epoch 181/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7485 - binary_accuracy: 0.8147 - val_loss: 0.8144 - val_binary_accuracy: 0.7926\n",
      "Epoch 182/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7621 - binary_accuracy: 0.8016 - val_loss: 0.8144 - val_binary_accuracy: 0.7925\n",
      "Epoch 183/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7485 - binary_accuracy: 0.8157 - val_loss: 0.8143 - val_binary_accuracy: 0.7926\n",
      "Epoch 184/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7688 - binary_accuracy: 0.7974 - val_loss: 0.8143 - val_binary_accuracy: 0.7926\n",
      "Epoch 185/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7555 - binary_accuracy: 0.8088 - val_loss: 0.8142 - val_binary_accuracy: 0.7926\n",
      "Epoch 186/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7643 - binary_accuracy: 0.8015 - val_loss: 0.8141 - val_binary_accuracy: 0.7925\n",
      "Epoch 187/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7489 - binary_accuracy: 0.8125 - val_loss: 0.8141 - val_binary_accuracy: 0.7926\n",
      "Epoch 188/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7520 - binary_accuracy: 0.8112 - val_loss: 0.8140 - val_binary_accuracy: 0.7925\n",
      "Epoch 189/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7699 - binary_accuracy: 0.7975 - val_loss: 0.8140 - val_binary_accuracy: 0.7925\n",
      "Epoch 190/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7706 - binary_accuracy: 0.7969 - val_loss: 0.8139 - val_binary_accuracy: 0.7925\n",
      "Epoch 191/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7846 - binary_accuracy: 0.7845 - val_loss: 0.8139 - val_binary_accuracy: 0.7925\n",
      "Epoch 192/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7387 - binary_accuracy: 0.8201 - val_loss: 0.8138 - val_binary_accuracy: 0.7926\n",
      "Epoch 193/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7458 - binary_accuracy: 0.8147 - val_loss: 0.8138 - val_binary_accuracy: 0.7926\n",
      "Epoch 194/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7577 - binary_accuracy: 0.8064 - val_loss: 0.8137 - val_binary_accuracy: 0.7925\n",
      "Epoch 195/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7555 - binary_accuracy: 0.8073 - val_loss: 0.8137 - val_binary_accuracy: 0.7925\n",
      "Epoch 196/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7532 - binary_accuracy: 0.8093 - val_loss: 0.8136 - val_binary_accuracy: 0.7924\n",
      "Epoch 197/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7505 - binary_accuracy: 0.8109 - val_loss: 0.8136 - val_binary_accuracy: 0.7926\n",
      "Epoch 198/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7782 - binary_accuracy: 0.7897 - val_loss: 0.8135 - val_binary_accuracy: 0.7924\n",
      "Epoch 199/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7481 - binary_accuracy: 0.8133 - val_loss: 0.8135 - val_binary_accuracy: 0.7925\n",
      "Epoch 200/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7803 - binary_accuracy: 0.7867 - val_loss: 0.8134 - val_binary_accuracy: 0.7924\n",
      "Epoch 201/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7579 - binary_accuracy: 0.8043 - val_loss: 0.8134 - val_binary_accuracy: 0.7926\n",
      "Epoch 202/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7675 - binary_accuracy: 0.7968 - val_loss: 0.8133 - val_binary_accuracy: 0.7925\n",
      "Epoch 203/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7670 - binary_accuracy: 0.7970 - val_loss: 0.8133 - val_binary_accuracy: 0.7925\n",
      "Epoch 204/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7401 - binary_accuracy: 0.8190 - val_loss: 0.8132 - val_binary_accuracy: 0.7926\n",
      "Epoch 205/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7563 - binary_accuracy: 0.8054 - val_loss: 0.8132 - val_binary_accuracy: 0.7925\n",
      "Epoch 206/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7434 - binary_accuracy: 0.8155 - val_loss: 0.8132 - val_binary_accuracy: 0.7925\n",
      "Epoch 207/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7534 - binary_accuracy: 0.8088 - val_loss: 0.8131 - val_binary_accuracy: 0.7926\n",
      "Epoch 208/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7733 - binary_accuracy: 0.7921 - val_loss: 0.8131 - val_binary_accuracy: 0.7926\n",
      "Epoch 209/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7702 - binary_accuracy: 0.7961 - val_loss: 0.8130 - val_binary_accuracy: 0.7925\n",
      "Epoch 210/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7571 - binary_accuracy: 0.8043 - val_loss: 0.8130 - val_binary_accuracy: 0.7926\n",
      "Epoch 211/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7537 - binary_accuracy: 0.8077 - val_loss: 0.8129 - val_binary_accuracy: 0.7925\n",
      "Epoch 212/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7524 - binary_accuracy: 0.8073 - val_loss: 0.8129 - val_binary_accuracy: 0.7926\n",
      "Epoch 213/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7628 - binary_accuracy: 0.8002 - val_loss: 0.8128 - val_binary_accuracy: 0.7925\n",
      "Epoch 214/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7463 - binary_accuracy: 0.8126 - val_loss: 0.8128 - val_binary_accuracy: 0.7925\n",
      "Epoch 215/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7692 - binary_accuracy: 0.7962 - val_loss: 0.8127 - val_binary_accuracy: 0.7925\n",
      "Epoch 216/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7668 - binary_accuracy: 0.7954 - val_loss: 0.8127 - val_binary_accuracy: 0.7925\n",
      "Epoch 217/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7502 - binary_accuracy: 0.8115 - val_loss: 0.8126 - val_binary_accuracy: 0.7925\n",
      "Epoch 218/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7713 - binary_accuracy: 0.7948 - val_loss: 0.8126 - val_binary_accuracy: 0.7925\n",
      "Epoch 219/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7683 - binary_accuracy: 0.7960 - val_loss: 0.8125 - val_binary_accuracy: 0.7926\n",
      "Epoch 220/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7729 - binary_accuracy: 0.7916 - val_loss: 0.8125 - val_binary_accuracy: 0.7925\n",
      "Epoch 221/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7529 - binary_accuracy: 0.8087 - val_loss: 0.8125 - val_binary_accuracy: 0.7925\n",
      "Epoch 222/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7742 - binary_accuracy: 0.7910 - val_loss: 0.8124 - val_binary_accuracy: 0.7925\n",
      "Epoch 223/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7975 - binary_accuracy: 0.7718 - val_loss: 0.8124 - val_binary_accuracy: 0.7926\n",
      "Epoch 224/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7710 - binary_accuracy: 0.7955 - val_loss: 0.8123 - val_binary_accuracy: 0.7926\n",
      "Epoch 225/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7615 - binary_accuracy: 0.8025 - val_loss: 0.8123 - val_binary_accuracy: 0.7926\n",
      "Epoch 226/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7593 - binary_accuracy: 0.8032 - val_loss: 0.8123 - val_binary_accuracy: 0.7926\n",
      "Epoch 227/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7690 - binary_accuracy: 0.7952 - val_loss: 0.8122 - val_binary_accuracy: 0.7926\n",
      "Epoch 228/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7611 - binary_accuracy: 0.8000 - val_loss: 0.8122 - val_binary_accuracy: 0.7925\n",
      "Epoch 229/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7700 - binary_accuracy: 0.7948 - val_loss: 0.8121 - val_binary_accuracy: 0.7925\n",
      "Epoch 230/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7516 - binary_accuracy: 0.8082 - val_loss: 0.8121 - val_binary_accuracy: 0.7926\n",
      "Epoch 231/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7663 - binary_accuracy: 0.7957 - val_loss: 0.8121 - val_binary_accuracy: 0.7925\n",
      "Epoch 232/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7443 - binary_accuracy: 0.8140 - val_loss: 0.8120 - val_binary_accuracy: 0.7926\n",
      "Epoch 233/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7621 - binary_accuracy: 0.8013 - val_loss: 0.8120 - val_binary_accuracy: 0.7926\n",
      "Epoch 234/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7476 - binary_accuracy: 0.8114 - val_loss: 0.8119 - val_binary_accuracy: 0.7926\n",
      "Epoch 235/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7578 - binary_accuracy: 0.8029 - val_loss: 0.8119 - val_binary_accuracy: 0.7926\n",
      "Epoch 236/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7604 - binary_accuracy: 0.8014 - val_loss: 0.8118 - val_binary_accuracy: 0.7925\n",
      "Epoch 237/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7698 - binary_accuracy: 0.7956 - val_loss: 0.8118 - val_binary_accuracy: 0.7926\n",
      "Epoch 238/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7774 - binary_accuracy: 0.7881 - val_loss: 0.8118 - val_binary_accuracy: 0.7926\n",
      "Epoch 239/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7585 - binary_accuracy: 0.8026 - val_loss: 0.8117 - val_binary_accuracy: 0.7926\n",
      "Epoch 240/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7584 - binary_accuracy: 0.8032 - val_loss: 0.8117 - val_binary_accuracy: 0.7926\n",
      "Epoch 241/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7551 - binary_accuracy: 0.8056 - val_loss: 0.8116 - val_binary_accuracy: 0.7925\n",
      "Epoch 242/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7554 - binary_accuracy: 0.8046 - val_loss: 0.8116 - val_binary_accuracy: 0.7925\n",
      "Epoch 243/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7690 - binary_accuracy: 0.7939 - val_loss: 0.8116 - val_binary_accuracy: 0.7925\n",
      "Epoch 244/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7567 - binary_accuracy: 0.8035 - val_loss: 0.8115 - val_binary_accuracy: 0.7925\n",
      "Epoch 245/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7574 - binary_accuracy: 0.8035 - val_loss: 0.8115 - val_binary_accuracy: 0.7925\n",
      "Epoch 246/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7623 - binary_accuracy: 0.7986 - val_loss: 0.8114 - val_binary_accuracy: 0.7925\n",
      "Epoch 247/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7435 - binary_accuracy: 0.8134 - val_loss: 0.8114 - val_binary_accuracy: 0.7925\n",
      "Epoch 248/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7801 - binary_accuracy: 0.7827 - val_loss: 0.8114 - val_binary_accuracy: 0.7924\n",
      "Epoch 249/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7658 - binary_accuracy: 0.7953 - val_loss: 0.8113 - val_binary_accuracy: 0.7924\n",
      "Epoch 250/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7705 - binary_accuracy: 0.7917 - val_loss: 0.8113 - val_binary_accuracy: 0.7925\n",
      "Epoch 251/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7563 - binary_accuracy: 0.8029 - val_loss: 0.8113 - val_binary_accuracy: 0.7926\n",
      "Epoch 252/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7459 - binary_accuracy: 0.8105 - val_loss: 0.8112 - val_binary_accuracy: 0.7926\n",
      "Epoch 253/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7841 - binary_accuracy: 0.7829 - val_loss: 0.8112 - val_binary_accuracy: 0.7926\n",
      "Epoch 254/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7625 - binary_accuracy: 0.7990 - val_loss: 0.8111 - val_binary_accuracy: 0.7926\n",
      "Epoch 255/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7592 - binary_accuracy: 0.8012 - val_loss: 0.8111 - val_binary_accuracy: 0.7926\n",
      "Epoch 256/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7653 - binary_accuracy: 0.7987 - val_loss: 0.8111 - val_binary_accuracy: 0.7926\n",
      "Epoch 257/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7410 - binary_accuracy: 0.8152 - val_loss: 0.8110 - val_binary_accuracy: 0.7925\n",
      "Epoch 258/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7505 - binary_accuracy: 0.8085 - val_loss: 0.8110 - val_binary_accuracy: 0.7926\n",
      "Epoch 259/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7696 - binary_accuracy: 0.7918 - val_loss: 0.8110 - val_binary_accuracy: 0.7925\n",
      "Epoch 260/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7801 - binary_accuracy: 0.7858 - val_loss: 0.8109 - val_binary_accuracy: 0.7924\n",
      "Epoch 261/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7517 - binary_accuracy: 0.8070 - val_loss: 0.8109 - val_binary_accuracy: 0.7926\n",
      "Epoch 262/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7703 - binary_accuracy: 0.7915 - val_loss: 0.8109 - val_binary_accuracy: 0.7926\n",
      "Epoch 263/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7617 - binary_accuracy: 0.7994 - val_loss: 0.8108 - val_binary_accuracy: 0.7925\n",
      "Epoch 264/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7756 - binary_accuracy: 0.7876 - val_loss: 0.8108 - val_binary_accuracy: 0.7925\n",
      "Epoch 265/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7701 - binary_accuracy: 0.7932 - val_loss: 0.8108 - val_binary_accuracy: 0.7924\n",
      "Epoch 266/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7512 - binary_accuracy: 0.8064 - val_loss: 0.8107 - val_binary_accuracy: 0.7924\n",
      "Epoch 267/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7509 - binary_accuracy: 0.8063 - val_loss: 0.8107 - val_binary_accuracy: 0.7924\n",
      "Epoch 268/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7527 - binary_accuracy: 0.8065 - val_loss: 0.8107 - val_binary_accuracy: 0.7926\n",
      "Epoch 269/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7713 - binary_accuracy: 0.7915 - val_loss: 0.8106 - val_binary_accuracy: 0.7925\n",
      "Epoch 270/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7564 - binary_accuracy: 0.8032 - val_loss: 0.8106 - val_binary_accuracy: 0.7923\n",
      "Epoch 271/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7584 - binary_accuracy: 0.8006 - val_loss: 0.8105 - val_binary_accuracy: 0.7924\n",
      "Epoch 272/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7549 - binary_accuracy: 0.8050 - val_loss: 0.8105 - val_binary_accuracy: 0.7924\n",
      "Epoch 273/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7693 - binary_accuracy: 0.7935 - val_loss: 0.8105 - val_binary_accuracy: 0.7924\n",
      "Epoch 274/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7542 - binary_accuracy: 0.8046 - val_loss: 0.8104 - val_binary_accuracy: 0.7924\n",
      "Epoch 275/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7572 - binary_accuracy: 0.8020 - val_loss: 0.8104 - val_binary_accuracy: 0.7924\n",
      "Epoch 276/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7430 - binary_accuracy: 0.8116 - val_loss: 0.8104 - val_binary_accuracy: 0.7924\n",
      "Epoch 277/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7577 - binary_accuracy: 0.8008 - val_loss: 0.8103 - val_binary_accuracy: 0.7924\n",
      "Epoch 278/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7683 - binary_accuracy: 0.7923 - val_loss: 0.8103 - val_binary_accuracy: 0.7925\n",
      "Epoch 279/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7634 - binary_accuracy: 0.7959 - val_loss: 0.8103 - val_binary_accuracy: 0.7924\n",
      "Epoch 280/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7775 - binary_accuracy: 0.7870 - val_loss: 0.8102 - val_binary_accuracy: 0.7924\n",
      "Epoch 281/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7478 - binary_accuracy: 0.8102 - val_loss: 0.8102 - val_binary_accuracy: 0.7925\n",
      "Epoch 282/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7605 - binary_accuracy: 0.7991 - val_loss: 0.8101 - val_binary_accuracy: 0.7924\n",
      "Epoch 283/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7736 - binary_accuracy: 0.7879 - val_loss: 0.8101 - val_binary_accuracy: 0.7924\n",
      "Epoch 284/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7668 - binary_accuracy: 0.7954 - val_loss: 0.8101 - val_binary_accuracy: 0.7924\n",
      "Epoch 285/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7486 - binary_accuracy: 0.8090 - val_loss: 0.8101 - val_binary_accuracy: 0.7925\n",
      "Epoch 286/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7460 - binary_accuracy: 0.8093 - val_loss: 0.8100 - val_binary_accuracy: 0.7924\n",
      "Epoch 287/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7391 - binary_accuracy: 0.8144 - val_loss: 0.8100 - val_binary_accuracy: 0.7924\n",
      "Epoch 288/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7581 - binary_accuracy: 0.8009 - val_loss: 0.8100 - val_binary_accuracy: 0.7924\n",
      "Epoch 289/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7632 - binary_accuracy: 0.7974 - val_loss: 0.8099 - val_binary_accuracy: 0.7923\n",
      "Epoch 290/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7626 - binary_accuracy: 0.7958 - val_loss: 0.8099 - val_binary_accuracy: 0.7924\n",
      "Epoch 291/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7538 - binary_accuracy: 0.8044 - val_loss: 0.8099 - val_binary_accuracy: 0.7924\n",
      "Epoch 292/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7377 - binary_accuracy: 0.8175 - val_loss: 0.8099 - val_binary_accuracy: 0.7923\n",
      "Epoch 293/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7436 - binary_accuracy: 0.8125 - val_loss: 0.8098 - val_binary_accuracy: 0.7925\n",
      "Epoch 294/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7417 - binary_accuracy: 0.8129 - val_loss: 0.8098 - val_binary_accuracy: 0.7923\n",
      "Epoch 295/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7659 - binary_accuracy: 0.7926 - val_loss: 0.8098 - val_binary_accuracy: 0.7922\n",
      "Epoch 296/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7426 - binary_accuracy: 0.8128 - val_loss: 0.8097 - val_binary_accuracy: 0.7925\n",
      "Epoch 297/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7709 - binary_accuracy: 0.7923 - val_loss: 0.8097 - val_binary_accuracy: 0.7923\n",
      "Epoch 298/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7430 - binary_accuracy: 0.8122 - val_loss: 0.8097 - val_binary_accuracy: 0.7924\n",
      "Epoch 299/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7540 - binary_accuracy: 0.8042 - val_loss: 0.8096 - val_binary_accuracy: 0.7924\n",
      "Epoch 300/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7434 - binary_accuracy: 0.8110 - val_loss: 0.8096 - val_binary_accuracy: 0.7924\n",
      "Epoch 301/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7650 - binary_accuracy: 0.7957 - val_loss: 0.8096 - val_binary_accuracy: 0.7924\n",
      "Epoch 302/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7538 - binary_accuracy: 0.8021 - val_loss: 0.8095 - val_binary_accuracy: 0.7923\n",
      "Epoch 303/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7505 - binary_accuracy: 0.8063 - val_loss: 0.8095 - val_binary_accuracy: 0.7923\n",
      "Epoch 304/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7451 - binary_accuracy: 0.8112 - val_loss: 0.8095 - val_binary_accuracy: 0.7924\n",
      "Epoch 305/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7689 - binary_accuracy: 0.7911 - val_loss: 0.8095 - val_binary_accuracy: 0.7923\n",
      "Epoch 306/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7626 - binary_accuracy: 0.7966 - val_loss: 0.8095 - val_binary_accuracy: 0.7922\n",
      "Epoch 307/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7479 - binary_accuracy: 0.8078 - val_loss: 0.8094 - val_binary_accuracy: 0.7923\n",
      "Epoch 308/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7512 - binary_accuracy: 0.8048 - val_loss: 0.8094 - val_binary_accuracy: 0.7922\n",
      "Epoch 309/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7476 - binary_accuracy: 0.8080 - val_loss: 0.8094 - val_binary_accuracy: 0.7923\n",
      "Epoch 310/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7534 - binary_accuracy: 0.8024 - val_loss: 0.8093 - val_binary_accuracy: 0.7923\n",
      "Epoch 311/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7630 - binary_accuracy: 0.7970 - val_loss: 0.8093 - val_binary_accuracy: 0.7924\n",
      "Epoch 312/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7558 - binary_accuracy: 0.8018 - val_loss: 0.8093 - val_binary_accuracy: 0.7922\n",
      "Epoch 313/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7529 - binary_accuracy: 0.8047 - val_loss: 0.8092 - val_binary_accuracy: 0.7922\n",
      "Epoch 314/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7605 - binary_accuracy: 0.7986 - val_loss: 0.8092 - val_binary_accuracy: 0.7922\n",
      "Epoch 315/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7601 - binary_accuracy: 0.7975 - val_loss: 0.8092 - val_binary_accuracy: 0.7922\n",
      "Epoch 316/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7434 - binary_accuracy: 0.8089 - val_loss: 0.8092 - val_binary_accuracy: 0.7923\n",
      "Epoch 317/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7670 - binary_accuracy: 0.7915 - val_loss: 0.8091 - val_binary_accuracy: 0.7922\n",
      "Epoch 318/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7555 - binary_accuracy: 0.8017 - val_loss: 0.8091 - val_binary_accuracy: 0.7922\n",
      "Epoch 319/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7516 - binary_accuracy: 0.8058 - val_loss: 0.8091 - val_binary_accuracy: 0.7922\n",
      "Epoch 320/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7746 - binary_accuracy: 0.7854 - val_loss: 0.8090 - val_binary_accuracy: 0.7922\n",
      "Epoch 321/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7627 - binary_accuracy: 0.7965 - val_loss: 0.8090 - val_binary_accuracy: 0.7922\n",
      "Epoch 322/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7486 - binary_accuracy: 0.8051 - val_loss: 0.8090 - val_binary_accuracy: 0.7922\n",
      "Epoch 323/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7459 - binary_accuracy: 0.8091 - val_loss: 0.8090 - val_binary_accuracy: 0.7922\n",
      "Epoch 324/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7407 - binary_accuracy: 0.8137 - val_loss: 0.8089 - val_binary_accuracy: 0.7923\n",
      "Epoch 325/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7644 - binary_accuracy: 0.7938 - val_loss: 0.8089 - val_binary_accuracy: 0.7922\n",
      "Epoch 326/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7463 - binary_accuracy: 0.8077 - val_loss: 0.8089 - val_binary_accuracy: 0.7922\n",
      "Epoch 327/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7564 - binary_accuracy: 0.8001 - val_loss: 0.8089 - val_binary_accuracy: 0.7922\n",
      "Epoch 328/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7636 - binary_accuracy: 0.7943 - val_loss: 0.8088 - val_binary_accuracy: 0.7922\n",
      "Epoch 329/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7269 - binary_accuracy: 0.8241 - val_loss: 0.8088 - val_binary_accuracy: 0.7922\n",
      "Epoch 330/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7683 - binary_accuracy: 0.7902 - val_loss: 0.8088 - val_binary_accuracy: 0.7922\n",
      "Epoch 331/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7456 - binary_accuracy: 0.8084 - val_loss: 0.8088 - val_binary_accuracy: 0.7922\n",
      "Epoch 332/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7528 - binary_accuracy: 0.8031 - val_loss: 0.8087 - val_binary_accuracy: 0.7922\n",
      "Epoch 333/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7641 - binary_accuracy: 0.7949 - val_loss: 0.8087 - val_binary_accuracy: 0.7922\n",
      "Epoch 334/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7509 - binary_accuracy: 0.8034 - val_loss: 0.8087 - val_binary_accuracy: 0.7922\n",
      "Epoch 335/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7481 - binary_accuracy: 0.8080 - val_loss: 0.8087 - val_binary_accuracy: 0.7922\n",
      "Epoch 336/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7643 - binary_accuracy: 0.7928 - val_loss: 0.8086 - val_binary_accuracy: 0.7921\n",
      "Epoch 337/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7580 - binary_accuracy: 0.7974 - val_loss: 0.8086 - val_binary_accuracy: 0.7922\n",
      "Epoch 338/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7642 - binary_accuracy: 0.7939 - val_loss: 0.8086 - val_binary_accuracy: 0.7922\n",
      "Epoch 339/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7651 - binary_accuracy: 0.7914 - val_loss: 0.8086 - val_binary_accuracy: 0.7922\n",
      "Epoch 340/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7435 - binary_accuracy: 0.8106 - val_loss: 0.8085 - val_binary_accuracy: 0.7922\n",
      "Epoch 341/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7694 - binary_accuracy: 0.7912 - val_loss: 0.8085 - val_binary_accuracy: 0.7922\n",
      "Epoch 342/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7416 - binary_accuracy: 0.8111 - val_loss: 0.8085 - val_binary_accuracy: 0.7922\n",
      "Epoch 343/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7447 - binary_accuracy: 0.8083 - val_loss: 0.8084 - val_binary_accuracy: 0.7922\n",
      "Epoch 344/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7472 - binary_accuracy: 0.8081 - val_loss: 0.8084 - val_binary_accuracy: 0.7921\n",
      "Epoch 345/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7382 - binary_accuracy: 0.8124 - val_loss: 0.8084 - val_binary_accuracy: 0.7922\n",
      "Epoch 346/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7665 - binary_accuracy: 0.7912 - val_loss: 0.8084 - val_binary_accuracy: 0.7921\n",
      "Epoch 347/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7715 - binary_accuracy: 0.7887 - val_loss: 0.8083 - val_binary_accuracy: 0.7920\n",
      "Epoch 348/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7668 - binary_accuracy: 0.7891 - val_loss: 0.8083 - val_binary_accuracy: 0.7922\n",
      "Epoch 349/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7636 - binary_accuracy: 0.7930 - val_loss: 0.8083 - val_binary_accuracy: 0.7922\n",
      "Epoch 350/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7534 - binary_accuracy: 0.8001 - val_loss: 0.8083 - val_binary_accuracy: 0.7920\n",
      "Epoch 351/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7524 - binary_accuracy: 0.8033 - val_loss: 0.8082 - val_binary_accuracy: 0.7921\n",
      "Epoch 352/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7410 - binary_accuracy: 0.8127 - val_loss: 0.8082 - val_binary_accuracy: 0.7921\n",
      "Epoch 353/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7508 - binary_accuracy: 0.8038 - val_loss: 0.8082 - val_binary_accuracy: 0.7921\n",
      "Epoch 354/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7529 - binary_accuracy: 0.8023 - val_loss: 0.8082 - val_binary_accuracy: 0.7921\n",
      "Epoch 355/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7540 - binary_accuracy: 0.8016 - val_loss: 0.8081 - val_binary_accuracy: 0.7922\n",
      "Epoch 356/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7421 - binary_accuracy: 0.8106 - val_loss: 0.8081 - val_binary_accuracy: 0.7922\n",
      "Epoch 357/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7294 - binary_accuracy: 0.8207 - val_loss: 0.8081 - val_binary_accuracy: 0.7922\n",
      "Epoch 358/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7542 - binary_accuracy: 0.8009 - val_loss: 0.8081 - val_binary_accuracy: 0.7920\n",
      "Epoch 359/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7649 - binary_accuracy: 0.7926 - val_loss: 0.8080 - val_binary_accuracy: 0.7920\n",
      "Epoch 360/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7713 - binary_accuracy: 0.7889 - val_loss: 0.8080 - val_binary_accuracy: 0.7921\n",
      "Epoch 361/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7610 - binary_accuracy: 0.7964 - val_loss: 0.8080 - val_binary_accuracy: 0.7921\n",
      "Epoch 362/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7288 - binary_accuracy: 0.8204 - val_loss: 0.8079 - val_binary_accuracy: 0.7922\n",
      "Epoch 363/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7373 - binary_accuracy: 0.8149 - val_loss: 0.8079 - val_binary_accuracy: 0.7922\n",
      "Epoch 364/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7472 - binary_accuracy: 0.8065 - val_loss: 0.8079 - val_binary_accuracy: 0.7922\n",
      "Epoch 365/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7528 - binary_accuracy: 0.8009 - val_loss: 0.8079 - val_binary_accuracy: 0.7921\n",
      "Epoch 366/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7465 - binary_accuracy: 0.8054 - val_loss: 0.8079 - val_binary_accuracy: 0.7922\n",
      "Epoch 367/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7534 - binary_accuracy: 0.8013 - val_loss: 0.8078 - val_binary_accuracy: 0.7922\n",
      "Epoch 368/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7622 - binary_accuracy: 0.7943 - val_loss: 0.8078 - val_binary_accuracy: 0.7921\n",
      "Epoch 369/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7547 - binary_accuracy: 0.8018 - val_loss: 0.8078 - val_binary_accuracy: 0.7922\n",
      "Epoch 370/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7610 - binary_accuracy: 0.7962 - val_loss: 0.8078 - val_binary_accuracy: 0.7921\n",
      "Epoch 371/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7456 - binary_accuracy: 0.8069 - val_loss: 0.8078 - val_binary_accuracy: 0.7921\n",
      "Epoch 372/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7416 - binary_accuracy: 0.8117 - val_loss: 0.8077 - val_binary_accuracy: 0.7921\n",
      "Epoch 373/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7536 - binary_accuracy: 0.8009 - val_loss: 0.8077 - val_binary_accuracy: 0.7921\n",
      "Epoch 374/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7570 - binary_accuracy: 0.7974 - val_loss: 0.8077 - val_binary_accuracy: 0.7921\n",
      "Epoch 375/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7466 - binary_accuracy: 0.8082 - val_loss: 0.8076 - val_binary_accuracy: 0.7919\n",
      "Epoch 376/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7617 - binary_accuracy: 0.7938 - val_loss: 0.8076 - val_binary_accuracy: 0.7920\n",
      "Epoch 377/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7561 - binary_accuracy: 0.7987 - val_loss: 0.8076 - val_binary_accuracy: 0.7920\n",
      "Epoch 378/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7506 - binary_accuracy: 0.8012 - val_loss: 0.8076 - val_binary_accuracy: 0.7919\n",
      "Epoch 379/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7565 - binary_accuracy: 0.7974 - val_loss: 0.8075 - val_binary_accuracy: 0.7920\n",
      "Epoch 380/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7536 - binary_accuracy: 0.8011 - val_loss: 0.8075 - val_binary_accuracy: 0.7920\n",
      "Epoch 381/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7415 - binary_accuracy: 0.8095 - val_loss: 0.8075 - val_binary_accuracy: 0.7920\n",
      "Epoch 382/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7584 - binary_accuracy: 0.7971 - val_loss: 0.8075 - val_binary_accuracy: 0.7920\n",
      "Epoch 383/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7339 - binary_accuracy: 0.8164 - val_loss: 0.8075 - val_binary_accuracy: 0.7920\n",
      "Epoch 384/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7413 - binary_accuracy: 0.8119 - val_loss: 0.8075 - val_binary_accuracy: 0.7919\n",
      "Epoch 385/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7458 - binary_accuracy: 0.8081 - val_loss: 0.8074 - val_binary_accuracy: 0.7919\n",
      "Epoch 386/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7561 - binary_accuracy: 0.8006 - val_loss: 0.8074 - val_binary_accuracy: 0.7921\n",
      "Epoch 387/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7540 - binary_accuracy: 0.7995 - val_loss: 0.8074 - val_binary_accuracy: 0.7920\n",
      "Epoch 388/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7396 - binary_accuracy: 0.8120 - val_loss: 0.8073 - val_binary_accuracy: 0.7920\n",
      "Epoch 389/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7531 - binary_accuracy: 0.8002 - val_loss: 0.8073 - val_binary_accuracy: 0.7920\n",
      "Epoch 390/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7382 - binary_accuracy: 0.8126 - val_loss: 0.8073 - val_binary_accuracy: 0.7919\n",
      "Epoch 391/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7397 - binary_accuracy: 0.8110 - val_loss: 0.8073 - val_binary_accuracy: 0.7919\n",
      "Epoch 392/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7657 - binary_accuracy: 0.7904 - val_loss: 0.8073 - val_binary_accuracy: 0.7919\n",
      "Epoch 393/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7593 - binary_accuracy: 0.7951 - val_loss: 0.8072 - val_binary_accuracy: 0.7920\n",
      "Epoch 394/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7464 - binary_accuracy: 0.8067 - val_loss: 0.8072 - val_binary_accuracy: 0.7920\n",
      "Epoch 395/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7647 - binary_accuracy: 0.7927 - val_loss: 0.8072 - val_binary_accuracy: 0.7920\n",
      "Epoch 396/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7313 - binary_accuracy: 0.8165 - val_loss: 0.8072 - val_binary_accuracy: 0.7920\n",
      "Epoch 397/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7377 - binary_accuracy: 0.8143 - val_loss: 0.8071 - val_binary_accuracy: 0.7921\n",
      "Epoch 398/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7678 - binary_accuracy: 0.7887 - val_loss: 0.8071 - val_binary_accuracy: 0.7921\n",
      "Epoch 399/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7230 - binary_accuracy: 0.8227 - val_loss: 0.8071 - val_binary_accuracy: 0.7920\n",
      "Epoch 400/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7519 - binary_accuracy: 0.8017 - val_loss: 0.8071 - val_binary_accuracy: 0.7920\n",
      "Epoch 401/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7535 - binary_accuracy: 0.7979 - val_loss: 0.8071 - val_binary_accuracy: 0.7919\n",
      "Epoch 402/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7638 - binary_accuracy: 0.7921 - val_loss: 0.8070 - val_binary_accuracy: 0.7920\n",
      "Epoch 403/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7582 - binary_accuracy: 0.7951 - val_loss: 0.8070 - val_binary_accuracy: 0.7919\n",
      "Epoch 404/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7585 - binary_accuracy: 0.7956 - val_loss: 0.8070 - val_binary_accuracy: 0.7919\n",
      "Epoch 405/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7351 - binary_accuracy: 0.8137 - val_loss: 0.8070 - val_binary_accuracy: 0.7919\n",
      "Epoch 406/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7369 - binary_accuracy: 0.8124 - val_loss: 0.8070 - val_binary_accuracy: 0.7921\n",
      "Epoch 407/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7557 - binary_accuracy: 0.7992 - val_loss: 0.8069 - val_binary_accuracy: 0.7920\n",
      "Epoch 408/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7601 - binary_accuracy: 0.7940 - val_loss: 0.8069 - val_binary_accuracy: 0.7920\n",
      "Epoch 409/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7401 - binary_accuracy: 0.8101 - val_loss: 0.8069 - val_binary_accuracy: 0.7919\n",
      "Epoch 410/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7602 - binary_accuracy: 0.7953 - val_loss: 0.8069 - val_binary_accuracy: 0.7920\n",
      "Epoch 411/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7554 - binary_accuracy: 0.7977 - val_loss: 0.8068 - val_binary_accuracy: 0.7920\n",
      "Epoch 412/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7493 - binary_accuracy: 0.8028 - val_loss: 0.8068 - val_binary_accuracy: 0.7920\n",
      "Epoch 413/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7527 - binary_accuracy: 0.7999 - val_loss: 0.8068 - val_binary_accuracy: 0.7919\n",
      "Epoch 414/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7361 - binary_accuracy: 0.8114 - val_loss: 0.8068 - val_binary_accuracy: 0.7919\n",
      "Epoch 415/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7649 - binary_accuracy: 0.7889 - val_loss: 0.8068 - val_binary_accuracy: 0.7919\n",
      "Epoch 416/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7650 - binary_accuracy: 0.7895 - val_loss: 0.8067 - val_binary_accuracy: 0.7920\n",
      "Epoch 417/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7478 - binary_accuracy: 0.8053 - val_loss: 0.8067 - val_binary_accuracy: 0.7919\n",
      "Epoch 418/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7834 - binary_accuracy: 0.7770 - val_loss: 0.8067 - val_binary_accuracy: 0.7922\n",
      "Epoch 419/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7307 - binary_accuracy: 0.8163 - val_loss: 0.8067 - val_binary_accuracy: 0.7920\n",
      "Epoch 420/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7606 - binary_accuracy: 0.7944 - val_loss: 0.8067 - val_binary_accuracy: 0.7920\n",
      "Epoch 421/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7464 - binary_accuracy: 0.8070 - val_loss: 0.8066 - val_binary_accuracy: 0.7922\n",
      "Epoch 422/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7638 - binary_accuracy: 0.7931 - val_loss: 0.8066 - val_binary_accuracy: 0.7921\n",
      "Epoch 423/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7492 - binary_accuracy: 0.8017 - val_loss: 0.8066 - val_binary_accuracy: 0.7921\n",
      "Epoch 424/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7366 - binary_accuracy: 0.8126 - val_loss: 0.8066 - val_binary_accuracy: 0.7921\n",
      "Epoch 425/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7503 - binary_accuracy: 0.8013 - val_loss: 0.8066 - val_binary_accuracy: 0.7920\n",
      "Epoch 426/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7480 - binary_accuracy: 0.8024 - val_loss: 0.8065 - val_binary_accuracy: 0.7919\n",
      "Epoch 427/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7814 - binary_accuracy: 0.7795 - val_loss: 0.8065 - val_binary_accuracy: 0.7919\n",
      "Epoch 428/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7559 - binary_accuracy: 0.7971 - val_loss: 0.8065 - val_binary_accuracy: 0.7921\n",
      "Epoch 429/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7384 - binary_accuracy: 0.8113 - val_loss: 0.8065 - val_binary_accuracy: 0.7921\n",
      "Epoch 430/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7564 - binary_accuracy: 0.7959 - val_loss: 0.8065 - val_binary_accuracy: 0.7922\n",
      "Epoch 431/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7568 - binary_accuracy: 0.7951 - val_loss: 0.8064 - val_binary_accuracy: 0.7921\n",
      "Epoch 432/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7486 - binary_accuracy: 0.8039 - val_loss: 0.8064 - val_binary_accuracy: 0.7921\n",
      "Epoch 433/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7620 - binary_accuracy: 0.7929 - val_loss: 0.8064 - val_binary_accuracy: 0.7921\n",
      "Epoch 434/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7346 - binary_accuracy: 0.8137 - val_loss: 0.8064 - val_binary_accuracy: 0.7920\n",
      "Epoch 435/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7347 - binary_accuracy: 0.8154 - val_loss: 0.8064 - val_binary_accuracy: 0.7921\n",
      "Epoch 436/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7411 - binary_accuracy: 0.8115 - val_loss: 0.8063 - val_binary_accuracy: 0.7921\n",
      "Epoch 437/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7620 - binary_accuracy: 0.7931 - val_loss: 0.8063 - val_binary_accuracy: 0.7922\n",
      "Epoch 438/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7568 - binary_accuracy: 0.7988 - val_loss: 0.8063 - val_binary_accuracy: 0.7922\n",
      "Epoch 439/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7440 - binary_accuracy: 0.8069 - val_loss: 0.8063 - val_binary_accuracy: 0.7921\n",
      "Epoch 440/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7528 - binary_accuracy: 0.7993 - val_loss: 0.8063 - val_binary_accuracy: 0.7922\n",
      "Epoch 441/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7564 - binary_accuracy: 0.7974 - val_loss: 0.8062 - val_binary_accuracy: 0.7921\n",
      "Epoch 442/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7748 - binary_accuracy: 0.7832 - val_loss: 0.8062 - val_binary_accuracy: 0.7921\n",
      "Epoch 443/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7508 - binary_accuracy: 0.8017 - val_loss: 0.8062 - val_binary_accuracy: 0.7922\n",
      "Epoch 444/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7594 - binary_accuracy: 0.7940 - val_loss: 0.8062 - val_binary_accuracy: 0.7922\n",
      "Epoch 445/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7493 - binary_accuracy: 0.8015 - val_loss: 0.8062 - val_binary_accuracy: 0.7921\n",
      "Epoch 446/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7414 - binary_accuracy: 0.8072 - val_loss: 0.8061 - val_binary_accuracy: 0.7921\n",
      "Epoch 447/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7365 - binary_accuracy: 0.8124 - val_loss: 0.8061 - val_binary_accuracy: 0.7923\n",
      "Epoch 448/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7262 - binary_accuracy: 0.8210 - val_loss: 0.8061 - val_binary_accuracy: 0.7923\n",
      "Epoch 449/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7630 - binary_accuracy: 0.7904 - val_loss: 0.8061 - val_binary_accuracy: 0.7923\n",
      "Epoch 450/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7518 - binary_accuracy: 0.8001 - val_loss: 0.8061 - val_binary_accuracy: 0.7923\n",
      "Epoch 451/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7364 - binary_accuracy: 0.8133 - val_loss: 0.8061 - val_binary_accuracy: 0.7923\n",
      "Epoch 452/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7653 - binary_accuracy: 0.7896 - val_loss: 0.8060 - val_binary_accuracy: 0.7923\n",
      "Epoch 453/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7550 - binary_accuracy: 0.7974 - val_loss: 0.8060 - val_binary_accuracy: 0.7923\n",
      "Epoch 454/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7959 - binary_accuracy: 0.7663 - val_loss: 0.8060 - val_binary_accuracy: 0.7923\n",
      "Epoch 455/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7529 - binary_accuracy: 0.7986 - val_loss: 0.8060 - val_binary_accuracy: 0.7923\n",
      "Epoch 456/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7434 - binary_accuracy: 0.8067 - val_loss: 0.8060 - val_binary_accuracy: 0.7922\n",
      "Epoch 457/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7327 - binary_accuracy: 0.8151 - val_loss: 0.8059 - val_binary_accuracy: 0.7922\n",
      "Epoch 458/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7635 - binary_accuracy: 0.7906 - val_loss: 0.8059 - val_binary_accuracy: 0.7923\n",
      "Epoch 459/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7662 - binary_accuracy: 0.7879 - val_loss: 0.8059 - val_binary_accuracy: 0.7922\n",
      "Epoch 460/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7499 - binary_accuracy: 0.8019 - val_loss: 0.8059 - val_binary_accuracy: 0.7923\n",
      "Epoch 461/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7429 - binary_accuracy: 0.8063 - val_loss: 0.8059 - val_binary_accuracy: 0.7923\n",
      "Epoch 462/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7228 - binary_accuracy: 0.8234 - val_loss: 0.8059 - val_binary_accuracy: 0.7923\n",
      "Epoch 463/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7317 - binary_accuracy: 0.8151 - val_loss: 0.8058 - val_binary_accuracy: 0.7923\n",
      "Epoch 464/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7473 - binary_accuracy: 0.8028 - val_loss: 0.8058 - val_binary_accuracy: 0.7923\n",
      "Epoch 465/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7445 - binary_accuracy: 0.8059 - val_loss: 0.8058 - val_binary_accuracy: 0.7922\n",
      "Epoch 466/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7461 - binary_accuracy: 0.8031 - val_loss: 0.8058 - val_binary_accuracy: 0.7923\n",
      "Epoch 467/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7444 - binary_accuracy: 0.8070 - val_loss: 0.8058 - val_binary_accuracy: 0.7922\n",
      "Epoch 468/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7563 - binary_accuracy: 0.7954 - val_loss: 0.8057 - val_binary_accuracy: 0.7922\n",
      "Epoch 469/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7423 - binary_accuracy: 0.8069 - val_loss: 0.8057 - val_binary_accuracy: 0.7922\n",
      "Epoch 470/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7539 - binary_accuracy: 0.7970 - val_loss: 0.8057 - val_binary_accuracy: 0.7923\n",
      "Epoch 471/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7581 - binary_accuracy: 0.7961 - val_loss: 0.8057 - val_binary_accuracy: 0.7923\n",
      "Epoch 472/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7535 - binary_accuracy: 0.7989 - val_loss: 0.8056 - val_binary_accuracy: 0.7923\n",
      "Epoch 473/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7438 - binary_accuracy: 0.8048 - val_loss: 0.8056 - val_binary_accuracy: 0.7923\n",
      "Epoch 474/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7399 - binary_accuracy: 0.8080 - val_loss: 0.8056 - val_binary_accuracy: 0.7921\n",
      "Epoch 475/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7515 - binary_accuracy: 0.7981 - val_loss: 0.8056 - val_binary_accuracy: 0.7922\n",
      "Epoch 476/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7303 - binary_accuracy: 0.8186 - val_loss: 0.8056 - val_binary_accuracy: 0.7922\n",
      "Epoch 477/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7757 - binary_accuracy: 0.7796 - val_loss: 0.8056 - val_binary_accuracy: 0.7922\n",
      "Epoch 478/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7459 - binary_accuracy: 0.8049 - val_loss: 0.8056 - val_binary_accuracy: 0.7922\n",
      "Epoch 479/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7543 - binary_accuracy: 0.7956 - val_loss: 0.8056 - val_binary_accuracy: 0.7922\n",
      "Epoch 480/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7393 - binary_accuracy: 0.8102 - val_loss: 0.8055 - val_binary_accuracy: 0.7922\n",
      "Epoch 481/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7351 - binary_accuracy: 0.8134 - val_loss: 0.8055 - val_binary_accuracy: 0.7922\n",
      "Epoch 482/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7275 - binary_accuracy: 0.8187 - val_loss: 0.8055 - val_binary_accuracy: 0.7922\n",
      "Epoch 483/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7478 - binary_accuracy: 0.8027 - val_loss: 0.8055 - val_binary_accuracy: 0.7922\n",
      "Epoch 484/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7484 - binary_accuracy: 0.8023 - val_loss: 0.8055 - val_binary_accuracy: 0.7921\n",
      "Epoch 485/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7413 - binary_accuracy: 0.8081 - val_loss: 0.8054 - val_binary_accuracy: 0.7922\n",
      "Epoch 486/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7492 - binary_accuracy: 0.8024 - val_loss: 0.8054 - val_binary_accuracy: 0.7922\n",
      "Epoch 487/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7146 - binary_accuracy: 0.8279 - val_loss: 0.8054 - val_binary_accuracy: 0.7922\n",
      "Epoch 488/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7350 - binary_accuracy: 0.8122 - val_loss: 0.8054 - val_binary_accuracy: 0.7922\n",
      "Epoch 489/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7374 - binary_accuracy: 0.8111 - val_loss: 0.8054 - val_binary_accuracy: 0.7922\n",
      "Epoch 490/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7438 - binary_accuracy: 0.8063 - val_loss: 0.8054 - val_binary_accuracy: 0.7922\n",
      "Epoch 491/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7459 - binary_accuracy: 0.8050 - val_loss: 0.8053 - val_binary_accuracy: 0.7922\n",
      "Epoch 492/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7529 - binary_accuracy: 0.7982 - val_loss: 0.8053 - val_binary_accuracy: 0.7922\n",
      "Epoch 493/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7516 - binary_accuracy: 0.7971 - val_loss: 0.8053 - val_binary_accuracy: 0.7922\n",
      "Epoch 494/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7355 - binary_accuracy: 0.8132 - val_loss: 0.8053 - val_binary_accuracy: 0.7922\n",
      "Epoch 495/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7382 - binary_accuracy: 0.8100 - val_loss: 0.8053 - val_binary_accuracy: 0.7922\n",
      "Epoch 496/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7338 - binary_accuracy: 0.8142 - val_loss: 0.8053 - val_binary_accuracy: 0.7922\n",
      "Epoch 497/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7414 - binary_accuracy: 0.8061 - val_loss: 0.8053 - val_binary_accuracy: 0.7922\n",
      "Epoch 498/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7681 - binary_accuracy: 0.7857 - val_loss: 0.8052 - val_binary_accuracy: 0.7922\n",
      "Epoch 499/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7606 - binary_accuracy: 0.7939 - val_loss: 0.8052 - val_binary_accuracy: 0.7922\n",
      "Epoch 500/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7407 - binary_accuracy: 0.8085 - val_loss: 0.8052 - val_binary_accuracy: 0.7922\n",
      "Epoch 501/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7381 - binary_accuracy: 0.8100 - val_loss: 0.8052 - val_binary_accuracy: 0.7921\n",
      "Epoch 502/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7493 - binary_accuracy: 0.8021 - val_loss: 0.8052 - val_binary_accuracy: 0.7921\n",
      "Epoch 503/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7525 - binary_accuracy: 0.7971 - val_loss: 0.8052 - val_binary_accuracy: 0.7922\n",
      "Epoch 504/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7396 - binary_accuracy: 0.8074 - val_loss: 0.8052 - val_binary_accuracy: 0.7922\n",
      "Epoch 505/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7538 - binary_accuracy: 0.7947 - val_loss: 0.8051 - val_binary_accuracy: 0.7921\n",
      "Epoch 506/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7347 - binary_accuracy: 0.8113 - val_loss: 0.8051 - val_binary_accuracy: 0.7921\n",
      "Epoch 507/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7542 - binary_accuracy: 0.7956 - val_loss: 0.8051 - val_binary_accuracy: 0.7922\n",
      "Epoch 508/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7543 - binary_accuracy: 0.7970 - val_loss: 0.8051 - val_binary_accuracy: 0.7921\n",
      "Epoch 509/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7294 - binary_accuracy: 0.8175 - val_loss: 0.8051 - val_binary_accuracy: 0.7922\n",
      "Epoch 510/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7486 - binary_accuracy: 0.8017 - val_loss: 0.8050 - val_binary_accuracy: 0.7922\n",
      "Epoch 511/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7633 - binary_accuracy: 0.7915 - val_loss: 0.8050 - val_binary_accuracy: 0.7922\n",
      "Epoch 512/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7383 - binary_accuracy: 0.8088 - val_loss: 0.8050 - val_binary_accuracy: 0.7922\n",
      "Epoch 513/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7510 - binary_accuracy: 0.8017 - val_loss: 0.8050 - val_binary_accuracy: 0.7921\n",
      "Epoch 514/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7376 - binary_accuracy: 0.8112 - val_loss: 0.8050 - val_binary_accuracy: 0.7922\n",
      "Epoch 515/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7556 - binary_accuracy: 0.7959 - val_loss: 0.8049 - val_binary_accuracy: 0.7921\n",
      "Epoch 516/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7481 - binary_accuracy: 0.8025 - val_loss: 0.8049 - val_binary_accuracy: 0.7921\n",
      "Epoch 517/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7425 - binary_accuracy: 0.8058 - val_loss: 0.8049 - val_binary_accuracy: 0.7921\n",
      "Epoch 518/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7600 - binary_accuracy: 0.7908 - val_loss: 0.8049 - val_binary_accuracy: 0.7921\n",
      "Epoch 519/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7243 - binary_accuracy: 0.8215 - val_loss: 0.8049 - val_binary_accuracy: 0.7921\n",
      "Epoch 520/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7514 - binary_accuracy: 0.7974 - val_loss: 0.8049 - val_binary_accuracy: 0.7921\n",
      "Epoch 521/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7555 - binary_accuracy: 0.7934 - val_loss: 0.8049 - val_binary_accuracy: 0.7922\n",
      "Epoch 522/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7566 - binary_accuracy: 0.7934 - val_loss: 0.8048 - val_binary_accuracy: 0.7922\n",
      "Epoch 523/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7548 - binary_accuracy: 0.7968 - val_loss: 0.8048 - val_binary_accuracy: 0.7920\n",
      "Epoch 524/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7266 - binary_accuracy: 0.8195 - val_loss: 0.8048 - val_binary_accuracy: 0.7921\n",
      "Epoch 525/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7636 - binary_accuracy: 0.7879 - val_loss: 0.8048 - val_binary_accuracy: 0.7920\n",
      "Epoch 526/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7685 - binary_accuracy: 0.7882 - val_loss: 0.8048 - val_binary_accuracy: 0.7920\n",
      "Epoch 527/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7584 - binary_accuracy: 0.7923 - val_loss: 0.8048 - val_binary_accuracy: 0.7920\n",
      "Epoch 528/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7526 - binary_accuracy: 0.7974 - val_loss: 0.8048 - val_binary_accuracy: 0.7920\n",
      "Epoch 529/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7355 - binary_accuracy: 0.8124 - val_loss: 0.8048 - val_binary_accuracy: 0.7921\n",
      "Epoch 530/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7347 - binary_accuracy: 0.8117 - val_loss: 0.8047 - val_binary_accuracy: 0.7920\n",
      "Epoch 531/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7570 - binary_accuracy: 0.7950 - val_loss: 0.8047 - val_binary_accuracy: 0.7920\n",
      "Epoch 532/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7528 - binary_accuracy: 0.7976 - val_loss: 0.8047 - val_binary_accuracy: 0.7920\n",
      "Epoch 533/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7439 - binary_accuracy: 0.8035 - val_loss: 0.8047 - val_binary_accuracy: 0.7920\n",
      "Epoch 534/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7343 - binary_accuracy: 0.8113 - val_loss: 0.8047 - val_binary_accuracy: 0.7920\n",
      "Epoch 535/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7483 - binary_accuracy: 0.7998 - val_loss: 0.8047 - val_binary_accuracy: 0.7920\n",
      "Epoch 536/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7392 - binary_accuracy: 0.8086 - val_loss: 0.8047 - val_binary_accuracy: 0.7921\n",
      "Epoch 537/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7439 - binary_accuracy: 0.8034 - val_loss: 0.8047 - val_binary_accuracy: 0.7920\n",
      "Epoch 538/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7585 - binary_accuracy: 0.7920 - val_loss: 0.8046 - val_binary_accuracy: 0.7920\n",
      "Epoch 539/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7341 - binary_accuracy: 0.8100 - val_loss: 0.8046 - val_binary_accuracy: 0.7921\n",
      "Epoch 540/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7519 - binary_accuracy: 0.7984 - val_loss: 0.8046 - val_binary_accuracy: 0.7920\n",
      "Epoch 541/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7517 - binary_accuracy: 0.7992 - val_loss: 0.8046 - val_binary_accuracy: 0.7921\n",
      "Epoch 542/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7379 - binary_accuracy: 0.8093 - val_loss: 0.8046 - val_binary_accuracy: 0.7921\n",
      "Epoch 543/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7484 - binary_accuracy: 0.8004 - val_loss: 0.8046 - val_binary_accuracy: 0.7922\n",
      "Epoch 544/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7503 - binary_accuracy: 0.7995 - val_loss: 0.8045 - val_binary_accuracy: 0.7921\n",
      "Epoch 545/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7612 - binary_accuracy: 0.7917 - val_loss: 0.8045 - val_binary_accuracy: 0.7920\n",
      "Epoch 546/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7526 - binary_accuracy: 0.7958 - val_loss: 0.8045 - val_binary_accuracy: 0.7920\n",
      "Epoch 547/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7704 - binary_accuracy: 0.7840 - val_loss: 0.8045 - val_binary_accuracy: 0.7920\n",
      "Epoch 548/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7267 - binary_accuracy: 0.8176 - val_loss: 0.8045 - val_binary_accuracy: 0.7920\n",
      "Epoch 549/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7352 - binary_accuracy: 0.8101 - val_loss: 0.8045 - val_binary_accuracy: 0.7920\n",
      "Epoch 550/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7379 - binary_accuracy: 0.8094 - val_loss: 0.8045 - val_binary_accuracy: 0.7920\n",
      "Epoch 551/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7376 - binary_accuracy: 0.8081 - val_loss: 0.8044 - val_binary_accuracy: 0.7921\n",
      "Epoch 552/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7629 - binary_accuracy: 0.7885 - val_loss: 0.8044 - val_binary_accuracy: 0.7921\n",
      "Epoch 553/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7554 - binary_accuracy: 0.7941 - val_loss: 0.8044 - val_binary_accuracy: 0.7921\n",
      "Epoch 554/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7363 - binary_accuracy: 0.8105 - val_loss: 0.8044 - val_binary_accuracy: 0.7921\n",
      "Epoch 555/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7347 - binary_accuracy: 0.8102 - val_loss: 0.8044 - val_binary_accuracy: 0.7920\n",
      "Epoch 556/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7571 - binary_accuracy: 0.7935 - val_loss: 0.8044 - val_binary_accuracy: 0.7920\n",
      "Epoch 557/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7417 - binary_accuracy: 0.8059 - val_loss: 0.8043 - val_binary_accuracy: 0.7921\n",
      "Epoch 558/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7380 - binary_accuracy: 0.8078 - val_loss: 0.8043 - val_binary_accuracy: 0.7920\n",
      "Epoch 559/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7459 - binary_accuracy: 0.8011 - val_loss: 0.8043 - val_binary_accuracy: 0.7919\n",
      "Epoch 560/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7299 - binary_accuracy: 0.8154 - val_loss: 0.8043 - val_binary_accuracy: 0.7920\n",
      "Epoch 561/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7453 - binary_accuracy: 0.8026 - val_loss: 0.8043 - val_binary_accuracy: 0.7921\n",
      "Epoch 562/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7456 - binary_accuracy: 0.8020 - val_loss: 0.8043 - val_binary_accuracy: 0.7920\n",
      "Epoch 563/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7167 - binary_accuracy: 0.8251 - val_loss: 0.8042 - val_binary_accuracy: 0.7920\n",
      "Epoch 564/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7378 - binary_accuracy: 0.8066 - val_loss: 0.8042 - val_binary_accuracy: 0.7920\n",
      "Epoch 565/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7501 - binary_accuracy: 0.7987 - val_loss: 0.8042 - val_binary_accuracy: 0.7920\n",
      "Epoch 566/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7617 - binary_accuracy: 0.7913 - val_loss: 0.8042 - val_binary_accuracy: 0.7921\n",
      "Epoch 567/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7405 - binary_accuracy: 0.8071 - val_loss: 0.8042 - val_binary_accuracy: 0.7920\n",
      "Epoch 568/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7424 - binary_accuracy: 0.8057 - val_loss: 0.8042 - val_binary_accuracy: 0.7920\n",
      "Epoch 569/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7215 - binary_accuracy: 0.8224 - val_loss: 0.8042 - val_binary_accuracy: 0.7920\n",
      "Epoch 570/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7504 - binary_accuracy: 0.7996 - val_loss: 0.8042 - val_binary_accuracy: 0.7920\n",
      "Epoch 571/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7800 - binary_accuracy: 0.7739 - val_loss: 0.8041 - val_binary_accuracy: 0.7920\n",
      "Epoch 572/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7509 - binary_accuracy: 0.7979 - val_loss: 0.8041 - val_binary_accuracy: 0.7920\n",
      "Epoch 573/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7494 - binary_accuracy: 0.7992 - val_loss: 0.8041 - val_binary_accuracy: 0.7920\n",
      "Epoch 574/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7176 - binary_accuracy: 0.8244 - val_loss: 0.8041 - val_binary_accuracy: 0.7920\n",
      "Epoch 575/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7420 - binary_accuracy: 0.8048 - val_loss: 0.8041 - val_binary_accuracy: 0.7920\n",
      "Epoch 576/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7534 - binary_accuracy: 0.7962 - val_loss: 0.8041 - val_binary_accuracy: 0.7920\n",
      "Epoch 577/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7625 - binary_accuracy: 0.7894 - val_loss: 0.8040 - val_binary_accuracy: 0.7920\n",
      "Epoch 578/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7607 - binary_accuracy: 0.7899 - val_loss: 0.8040 - val_binary_accuracy: 0.7919\n",
      "Epoch 579/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7362 - binary_accuracy: 0.8107 - val_loss: 0.8040 - val_binary_accuracy: 0.7919\n",
      "Epoch 580/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7470 - binary_accuracy: 0.8021 - val_loss: 0.8040 - val_binary_accuracy: 0.7919\n",
      "Epoch 581/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7557 - binary_accuracy: 0.7934 - val_loss: 0.8040 - val_binary_accuracy: 0.7920\n",
      "Epoch 582/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7630 - binary_accuracy: 0.7860 - val_loss: 0.8040 - val_binary_accuracy: 0.7919\n",
      "Epoch 583/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7291 - binary_accuracy: 0.8152 - val_loss: 0.8040 - val_binary_accuracy: 0.7919\n",
      "Epoch 584/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7742 - binary_accuracy: 0.7790 - val_loss: 0.8040 - val_binary_accuracy: 0.7919\n",
      "Epoch 585/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7450 - binary_accuracy: 0.8032 - val_loss: 0.8040 - val_binary_accuracy: 0.7919\n",
      "Epoch 586/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7332 - binary_accuracy: 0.8114 - val_loss: 0.8039 - val_binary_accuracy: 0.7920\n",
      "Epoch 587/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7508 - binary_accuracy: 0.7962 - val_loss: 0.8039 - val_binary_accuracy: 0.7920\n",
      "Epoch 588/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7584 - binary_accuracy: 0.7909 - val_loss: 0.8039 - val_binary_accuracy: 0.7920\n",
      "Epoch 589/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7393 - binary_accuracy: 0.8060 - val_loss: 0.8039 - val_binary_accuracy: 0.7920\n",
      "Epoch 590/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7411 - binary_accuracy: 0.8050 - val_loss: 0.8038 - val_binary_accuracy: 0.7920\n",
      "Epoch 591/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7427 - binary_accuracy: 0.8058 - val_loss: 0.8038 - val_binary_accuracy: 0.7920\n",
      "Epoch 592/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7568 - binary_accuracy: 0.7920 - val_loss: 0.8038 - val_binary_accuracy: 0.7920\n",
      "Epoch 593/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7528 - binary_accuracy: 0.7969 - val_loss: 0.8038 - val_binary_accuracy: 0.7920\n",
      "Epoch 594/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7405 - binary_accuracy: 0.8060 - val_loss: 0.8038 - val_binary_accuracy: 0.7920\n",
      "Epoch 595/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7262 - binary_accuracy: 0.8172 - val_loss: 0.8038 - val_binary_accuracy: 0.7920\n",
      "Epoch 596/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7519 - binary_accuracy: 0.7963 - val_loss: 0.8038 - val_binary_accuracy: 0.7920\n",
      "Epoch 597/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7423 - binary_accuracy: 0.8045 - val_loss: 0.8038 - val_binary_accuracy: 0.7920\n",
      "Epoch 598/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7489 - binary_accuracy: 0.7982 - val_loss: 0.8038 - val_binary_accuracy: 0.7920\n",
      "Epoch 599/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7371 - binary_accuracy: 0.8075 - val_loss: 0.8037 - val_binary_accuracy: 0.7920\n",
      "Epoch 600/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7442 - binary_accuracy: 0.8021 - val_loss: 0.8037 - val_binary_accuracy: 0.7919\n",
      "Epoch 601/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7551 - binary_accuracy: 0.7930 - val_loss: 0.8037 - val_binary_accuracy: 0.7919\n",
      "Epoch 602/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7485 - binary_accuracy: 0.8003 - val_loss: 0.8037 - val_binary_accuracy: 0.7920\n",
      "Epoch 603/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7328 - binary_accuracy: 0.8119 - val_loss: 0.8037 - val_binary_accuracy: 0.7920\n",
      "Epoch 604/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7422 - binary_accuracy: 0.8047 - val_loss: 0.8037 - val_binary_accuracy: 0.7919\n",
      "Epoch 605/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7439 - binary_accuracy: 0.8037 - val_loss: 0.8037 - val_binary_accuracy: 0.7919\n",
      "Epoch 606/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7384 - binary_accuracy: 0.8095 - val_loss: 0.8037 - val_binary_accuracy: 0.7919\n",
      "Epoch 607/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7297 - binary_accuracy: 0.8146 - val_loss: 0.8037 - val_binary_accuracy: 0.7919\n",
      "Epoch 608/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7595 - binary_accuracy: 0.7906 - val_loss: 0.8036 - val_binary_accuracy: 0.7919\n",
      "Epoch 609/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7362 - binary_accuracy: 0.8097 - val_loss: 0.8036 - val_binary_accuracy: 0.7919\n",
      "Epoch 610/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7281 - binary_accuracy: 0.8169 - val_loss: 0.8036 - val_binary_accuracy: 0.7919\n",
      "Epoch 611/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7571 - binary_accuracy: 0.7930 - val_loss: 0.8036 - val_binary_accuracy: 0.7919\n",
      "Epoch 612/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7141 - binary_accuracy: 0.8265 - val_loss: 0.8036 - val_binary_accuracy: 0.7919\n",
      "Epoch 613/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7224 - binary_accuracy: 0.8196 - val_loss: 0.8036 - val_binary_accuracy: 0.7919\n",
      "Epoch 614/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7692 - binary_accuracy: 0.7816 - val_loss: 0.8036 - val_binary_accuracy: 0.7919\n",
      "Epoch 615/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7508 - binary_accuracy: 0.7980 - val_loss: 0.8035 - val_binary_accuracy: 0.7918\n",
      "Epoch 616/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7486 - binary_accuracy: 0.7980 - val_loss: 0.8035 - val_binary_accuracy: 0.7918\n",
      "Epoch 617/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7368 - binary_accuracy: 0.8081 - val_loss: 0.8035 - val_binary_accuracy: 0.7918\n",
      "Epoch 618/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7280 - binary_accuracy: 0.8166 - val_loss: 0.8035 - val_binary_accuracy: 0.7918\n",
      "Epoch 619/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7335 - binary_accuracy: 0.8115 - val_loss: 0.8035 - val_binary_accuracy: 0.7918\n",
      "Epoch 620/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7387 - binary_accuracy: 0.8053 - val_loss: 0.8035 - val_binary_accuracy: 0.7919\n",
      "Epoch 621/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7502 - binary_accuracy: 0.7973 - val_loss: 0.8035 - val_binary_accuracy: 0.7919\n",
      "Epoch 622/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7427 - binary_accuracy: 0.8047 - val_loss: 0.8035 - val_binary_accuracy: 0.7919\n",
      "Epoch 623/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7268 - binary_accuracy: 0.8164 - val_loss: 0.8035 - val_binary_accuracy: 0.7918\n",
      "Epoch 624/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7364 - binary_accuracy: 0.8083 - val_loss: 0.8035 - val_binary_accuracy: 0.7919\n",
      "Epoch 625/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7481 - binary_accuracy: 0.7990 - val_loss: 0.8034 - val_binary_accuracy: 0.7918\n",
      "Epoch 626/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7400 - binary_accuracy: 0.8063 - val_loss: 0.8034 - val_binary_accuracy: 0.7918\n",
      "Epoch 627/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7522 - binary_accuracy: 0.7971 - val_loss: 0.8034 - val_binary_accuracy: 0.7918\n",
      "Epoch 628/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7577 - binary_accuracy: 0.7917 - val_loss: 0.8034 - val_binary_accuracy: 0.7918\n",
      "Epoch 629/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7491 - binary_accuracy: 0.7971 - val_loss: 0.8034 - val_binary_accuracy: 0.7918\n",
      "Epoch 630/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7388 - binary_accuracy: 0.8067 - val_loss: 0.8034 - val_binary_accuracy: 0.7918\n",
      "Epoch 631/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7486 - binary_accuracy: 0.7990 - val_loss: 0.8033 - val_binary_accuracy: 0.7919\n",
      "Epoch 632/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7466 - binary_accuracy: 0.7995 - val_loss: 0.8033 - val_binary_accuracy: 0.7919\n",
      "Epoch 633/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7366 - binary_accuracy: 0.8079 - val_loss: 0.8033 - val_binary_accuracy: 0.7919\n",
      "Epoch 634/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7374 - binary_accuracy: 0.8091 - val_loss: 0.8033 - val_binary_accuracy: 0.7919\n",
      "Epoch 635/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7486 - binary_accuracy: 0.7965 - val_loss: 0.8033 - val_binary_accuracy: 0.7920\n",
      "Epoch 636/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7440 - binary_accuracy: 0.8021 - val_loss: 0.8033 - val_binary_accuracy: 0.7919\n",
      "Epoch 637/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7383 - binary_accuracy: 0.8070 - val_loss: 0.8033 - val_binary_accuracy: 0.7919\n",
      "Epoch 638/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7395 - binary_accuracy: 0.8071 - val_loss: 0.8033 - val_binary_accuracy: 0.7919\n",
      "Epoch 639/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7446 - binary_accuracy: 0.8007 - val_loss: 0.8033 - val_binary_accuracy: 0.7919\n",
      "Epoch 640/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7737 - binary_accuracy: 0.7784 - val_loss: 0.8032 - val_binary_accuracy: 0.7919\n",
      "Epoch 641/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7520 - binary_accuracy: 0.7962 - val_loss: 0.8032 - val_binary_accuracy: 0.7919\n",
      "Epoch 642/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7352 - binary_accuracy: 0.8090 - val_loss: 0.8032 - val_binary_accuracy: 0.7919\n",
      "Epoch 643/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7517 - binary_accuracy: 0.7954 - val_loss: 0.8032 - val_binary_accuracy: 0.7919\n",
      "Epoch 644/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7291 - binary_accuracy: 0.8141 - val_loss: 0.8032 - val_binary_accuracy: 0.7919\n",
      "Epoch 645/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7379 - binary_accuracy: 0.8071 - val_loss: 0.8032 - val_binary_accuracy: 0.7919\n",
      "Epoch 646/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7383 - binary_accuracy: 0.8076 - val_loss: 0.8032 - val_binary_accuracy: 0.7919\n",
      "Epoch 647/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7664 - binary_accuracy: 0.7833 - val_loss: 0.8032 - val_binary_accuracy: 0.7919\n",
      "Epoch 648/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7386 - binary_accuracy: 0.8045 - val_loss: 0.8032 - val_binary_accuracy: 0.7919\n",
      "Epoch 649/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7201 - binary_accuracy: 0.8211 - val_loss: 0.8031 - val_binary_accuracy: 0.7918\n",
      "Epoch 650/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7390 - binary_accuracy: 0.8039 - val_loss: 0.8031 - val_binary_accuracy: 0.7917\n",
      "Epoch 651/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7304 - binary_accuracy: 0.8134 - val_loss: 0.8031 - val_binary_accuracy: 0.7917\n",
      "Epoch 652/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7496 - binary_accuracy: 0.7983 - val_loss: 0.8031 - val_binary_accuracy: 0.7917\n",
      "Epoch 653/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7520 - binary_accuracy: 0.7954 - val_loss: 0.8031 - val_binary_accuracy: 0.7917\n",
      "Epoch 654/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7567 - binary_accuracy: 0.7920 - val_loss: 0.8031 - val_binary_accuracy: 0.7919\n",
      "Epoch 655/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7123 - binary_accuracy: 0.8258 - val_loss: 0.8031 - val_binary_accuracy: 0.7919\n",
      "Epoch 656/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7557 - binary_accuracy: 0.7921 - val_loss: 0.8031 - val_binary_accuracy: 0.7918\n",
      "Epoch 657/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7441 - binary_accuracy: 0.8002 - val_loss: 0.8030 - val_binary_accuracy: 0.7918\n",
      "Epoch 658/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7378 - binary_accuracy: 0.8056 - val_loss: 0.8030 - val_binary_accuracy: 0.7917\n",
      "Epoch 659/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7473 - binary_accuracy: 0.8006 - val_loss: 0.8030 - val_binary_accuracy: 0.7918\n",
      "Epoch 660/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7575 - binary_accuracy: 0.7897 - val_loss: 0.8030 - val_binary_accuracy: 0.7918\n",
      "Epoch 661/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7675 - binary_accuracy: 0.7830 - val_loss: 0.8030 - val_binary_accuracy: 0.7918\n",
      "Epoch 662/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7434 - binary_accuracy: 0.8029 - val_loss: 0.8030 - val_binary_accuracy: 0.7919\n",
      "Epoch 663/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7531 - binary_accuracy: 0.7949 - val_loss: 0.8030 - val_binary_accuracy: 0.7919\n",
      "Epoch 664/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7266 - binary_accuracy: 0.8139 - val_loss: 0.8030 - val_binary_accuracy: 0.7919\n",
      "Epoch 665/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7473 - binary_accuracy: 0.7977 - val_loss: 0.8030 - val_binary_accuracy: 0.7919\n",
      "Epoch 666/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7386 - binary_accuracy: 0.8062 - val_loss: 0.8029 - val_binary_accuracy: 0.7919\n",
      "Epoch 667/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7284 - binary_accuracy: 0.8143 - val_loss: 0.8029 - val_binary_accuracy: 0.7917\n",
      "Epoch 668/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7407 - binary_accuracy: 0.8031 - val_loss: 0.8029 - val_binary_accuracy: 0.7918\n",
      "Epoch 669/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7325 - binary_accuracy: 0.8111 - val_loss: 0.8029 - val_binary_accuracy: 0.7919\n",
      "Epoch 670/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7329 - binary_accuracy: 0.8095 - val_loss: 0.8029 - val_binary_accuracy: 0.7918\n",
      "Epoch 671/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7436 - binary_accuracy: 0.8016 - val_loss: 0.8029 - val_binary_accuracy: 0.7918\n",
      "Epoch 672/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7366 - binary_accuracy: 0.8075 - val_loss: 0.8029 - val_binary_accuracy: 0.7918\n",
      "Epoch 673/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7359 - binary_accuracy: 0.8089 - val_loss: 0.8029 - val_binary_accuracy: 0.7918\n",
      "Epoch 674/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7190 - binary_accuracy: 0.8213 - val_loss: 0.8029 - val_binary_accuracy: 0.7918\n",
      "Epoch 675/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7433 - binary_accuracy: 0.8034 - val_loss: 0.8029 - val_binary_accuracy: 0.7918\n",
      "Epoch 676/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7232 - binary_accuracy: 0.8184 - val_loss: 0.8028 - val_binary_accuracy: 0.7918\n",
      "Epoch 677/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7213 - binary_accuracy: 0.8180 - val_loss: 0.8028 - val_binary_accuracy: 0.7918\n",
      "Epoch 678/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7484 - binary_accuracy: 0.7988 - val_loss: 0.8028 - val_binary_accuracy: 0.7918\n",
      "Epoch 679/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7270 - binary_accuracy: 0.8168 - val_loss: 0.8028 - val_binary_accuracy: 0.7918\n",
      "Epoch 680/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7414 - binary_accuracy: 0.8040 - val_loss: 0.8028 - val_binary_accuracy: 0.7918\n",
      "Epoch 681/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7475 - binary_accuracy: 0.7981 - val_loss: 0.8028 - val_binary_accuracy: 0.7918\n",
      "Epoch 682/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7378 - binary_accuracy: 0.8070 - val_loss: 0.8028 - val_binary_accuracy: 0.7918\n",
      "Epoch 683/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7347 - binary_accuracy: 0.8072 - val_loss: 0.8027 - val_binary_accuracy: 0.7918\n",
      "Epoch 684/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7344 - binary_accuracy: 0.8093 - val_loss: 0.8027 - val_binary_accuracy: 0.7918\n",
      "Epoch 685/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7270 - binary_accuracy: 0.8133 - val_loss: 0.8027 - val_binary_accuracy: 0.7918\n",
      "Epoch 686/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7309 - binary_accuracy: 0.8115 - val_loss: 0.8027 - val_binary_accuracy: 0.7918\n",
      "Epoch 687/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7603 - binary_accuracy: 0.7882 - val_loss: 0.8027 - val_binary_accuracy: 0.7918\n",
      "Epoch 688/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7389 - binary_accuracy: 0.8044 - val_loss: 0.8027 - val_binary_accuracy: 0.7918\n",
      "Epoch 689/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7547 - binary_accuracy: 0.7925 - val_loss: 0.8027 - val_binary_accuracy: 0.7918\n",
      "Epoch 690/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7189 - binary_accuracy: 0.8213 - val_loss: 0.8027 - val_binary_accuracy: 0.7918\n",
      "Epoch 691/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7384 - binary_accuracy: 0.8045 - val_loss: 0.8027 - val_binary_accuracy: 0.7918\n",
      "Epoch 692/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7500 - binary_accuracy: 0.7966 - val_loss: 0.8026 - val_binary_accuracy: 0.7918\n",
      "Epoch 693/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7459 - binary_accuracy: 0.7989 - val_loss: 0.8026 - val_binary_accuracy: 0.7919\n",
      "Epoch 694/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7432 - binary_accuracy: 0.8019 - val_loss: 0.8026 - val_binary_accuracy: 0.7918\n",
      "Epoch 695/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7274 - binary_accuracy: 0.8158 - val_loss: 0.8026 - val_binary_accuracy: 0.7919\n",
      "Epoch 696/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7317 - binary_accuracy: 0.8110 - val_loss: 0.8026 - val_binary_accuracy: 0.7918\n",
      "Epoch 697/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7442 - binary_accuracy: 0.8022 - val_loss: 0.8026 - val_binary_accuracy: 0.7918\n",
      "Epoch 698/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7391 - binary_accuracy: 0.8072 - val_loss: 0.8026 - val_binary_accuracy: 0.7918\n",
      "Epoch 699/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7353 - binary_accuracy: 0.8074 - val_loss: 0.8026 - val_binary_accuracy: 0.7918\n",
      "Epoch 700/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7216 - binary_accuracy: 0.8197 - val_loss: 0.8026 - val_binary_accuracy: 0.7918\n",
      "Epoch 701/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7342 - binary_accuracy: 0.8071 - val_loss: 0.8025 - val_binary_accuracy: 0.7918\n",
      "Epoch 702/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7507 - binary_accuracy: 0.7961 - val_loss: 0.8025 - val_binary_accuracy: 0.7918\n",
      "Epoch 703/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7508 - binary_accuracy: 0.7960 - val_loss: 0.8025 - val_binary_accuracy: 0.7918\n",
      "Epoch 704/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7418 - binary_accuracy: 0.8045 - val_loss: 0.8025 - val_binary_accuracy: 0.7918\n",
      "Epoch 705/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7430 - binary_accuracy: 0.8024 - val_loss: 0.8025 - val_binary_accuracy: 0.7918\n",
      "Epoch 706/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7274 - binary_accuracy: 0.8139 - val_loss: 0.8025 - val_binary_accuracy: 0.7918\n",
      "Epoch 707/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7403 - binary_accuracy: 0.8042 - val_loss: 0.8025 - val_binary_accuracy: 0.7918\n",
      "Epoch 708/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7302 - binary_accuracy: 0.8115 - val_loss: 0.8025 - val_binary_accuracy: 0.7918\n",
      "Epoch 709/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7411 - binary_accuracy: 0.8013 - val_loss: 0.8024 - val_binary_accuracy: 0.7918\n",
      "Epoch 710/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7416 - binary_accuracy: 0.8040 - val_loss: 0.8024 - val_binary_accuracy: 0.7918\n",
      "Epoch 711/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7476 - binary_accuracy: 0.7982 - val_loss: 0.8024 - val_binary_accuracy: 0.7918\n",
      "Epoch 712/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7517 - binary_accuracy: 0.7937 - val_loss: 0.8024 - val_binary_accuracy: 0.7918\n",
      "Epoch 713/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7461 - binary_accuracy: 0.7986 - val_loss: 0.8024 - val_binary_accuracy: 0.7918\n",
      "Epoch 714/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7420 - binary_accuracy: 0.8014 - val_loss: 0.8024 - val_binary_accuracy: 0.7918\n",
      "Epoch 715/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7413 - binary_accuracy: 0.8024 - val_loss: 0.8024 - val_binary_accuracy: 0.7918\n",
      "Epoch 716/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7357 - binary_accuracy: 0.8079 - val_loss: 0.8024 - val_binary_accuracy: 0.7918\n",
      "Epoch 717/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7324 - binary_accuracy: 0.8107 - val_loss: 0.8024 - val_binary_accuracy: 0.7918\n",
      "Epoch 718/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7416 - binary_accuracy: 0.8034 - val_loss: 0.8024 - val_binary_accuracy: 0.7918\n",
      "Epoch 719/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7351 - binary_accuracy: 0.8087 - val_loss: 0.8024 - val_binary_accuracy: 0.7919\n",
      "Epoch 720/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7443 - binary_accuracy: 0.8014 - val_loss: 0.8023 - val_binary_accuracy: 0.7918\n",
      "Epoch 721/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7304 - binary_accuracy: 0.8123 - val_loss: 0.8023 - val_binary_accuracy: 0.7918\n",
      "Epoch 722/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7346 - binary_accuracy: 0.8080 - val_loss: 0.8023 - val_binary_accuracy: 0.7918\n",
      "Epoch 723/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7404 - binary_accuracy: 0.8031 - val_loss: 0.8023 - val_binary_accuracy: 0.7918\n",
      "Epoch 724/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7145 - binary_accuracy: 0.8250 - val_loss: 0.8023 - val_binary_accuracy: 0.7918\n",
      "Epoch 725/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7393 - binary_accuracy: 0.8057 - val_loss: 0.8023 - val_binary_accuracy: 0.7918\n",
      "Epoch 726/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7402 - binary_accuracy: 0.8055 - val_loss: 0.8023 - val_binary_accuracy: 0.7918\n",
      "Epoch 727/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7451 - binary_accuracy: 0.7996 - val_loss: 0.8023 - val_binary_accuracy: 0.7918\n",
      "Epoch 728/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7341 - binary_accuracy: 0.8080 - val_loss: 0.8023 - val_binary_accuracy: 0.7918\n",
      "Epoch 729/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7290 - binary_accuracy: 0.8116 - val_loss: 0.8023 - val_binary_accuracy: 0.7918\n",
      "Epoch 730/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7503 - binary_accuracy: 0.7952 - val_loss: 0.8022 - val_binary_accuracy: 0.7918\n",
      "Epoch 731/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7512 - binary_accuracy: 0.7948 - val_loss: 0.8022 - val_binary_accuracy: 0.7918\n",
      "Epoch 732/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7188 - binary_accuracy: 0.8222 - val_loss: 0.8022 - val_binary_accuracy: 0.7918\n",
      "Epoch 733/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7386 - binary_accuracy: 0.8058 - val_loss: 0.8022 - val_binary_accuracy: 0.7918\n",
      "Epoch 734/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7296 - binary_accuracy: 0.8134 - val_loss: 0.8022 - val_binary_accuracy: 0.7918\n",
      "Epoch 735/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7436 - binary_accuracy: 0.8012 - val_loss: 0.8022 - val_binary_accuracy: 0.7918\n",
      "Epoch 736/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7350 - binary_accuracy: 0.8087 - val_loss: 0.8022 - val_binary_accuracy: 0.7918\n",
      "Epoch 737/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7262 - binary_accuracy: 0.8161 - val_loss: 0.8022 - val_binary_accuracy: 0.7918\n",
      "Epoch 738/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7429 - binary_accuracy: 0.8009 - val_loss: 0.8022 - val_binary_accuracy: 0.7918\n",
      "Epoch 739/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7661 - binary_accuracy: 0.7828 - val_loss: 0.8021 - val_binary_accuracy: 0.7918\n",
      "Epoch 740/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7278 - binary_accuracy: 0.8126 - val_loss: 0.8021 - val_binary_accuracy: 0.7918\n",
      "Epoch 741/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7471 - binary_accuracy: 0.7985 - val_loss: 0.8021 - val_binary_accuracy: 0.7918\n",
      "Epoch 742/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7514 - binary_accuracy: 0.7946 - val_loss: 0.8021 - val_binary_accuracy: 0.7918\n",
      "Epoch 743/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7454 - binary_accuracy: 0.7989 - val_loss: 0.8021 - val_binary_accuracy: 0.7918\n",
      "Epoch 744/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7351 - binary_accuracy: 0.8081 - val_loss: 0.8021 - val_binary_accuracy: 0.7919\n",
      "Epoch 745/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7331 - binary_accuracy: 0.8113 - val_loss: 0.8021 - val_binary_accuracy: 0.7918\n",
      "Epoch 746/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7315 - binary_accuracy: 0.8105 - val_loss: 0.8021 - val_binary_accuracy: 0.7918\n",
      "Epoch 747/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7269 - binary_accuracy: 0.8147 - val_loss: 0.8021 - val_binary_accuracy: 0.7918\n",
      "Epoch 748/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7521 - binary_accuracy: 0.7944 - val_loss: 0.8021 - val_binary_accuracy: 0.7918\n",
      "Epoch 749/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7112 - binary_accuracy: 0.8255 - val_loss: 0.8020 - val_binary_accuracy: 0.7918\n",
      "Epoch 750/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7491 - binary_accuracy: 0.7960 - val_loss: 0.8020 - val_binary_accuracy: 0.7918\n",
      "Epoch 751/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7233 - binary_accuracy: 0.8180 - val_loss: 0.8020 - val_binary_accuracy: 0.7918\n",
      "Epoch 752/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7311 - binary_accuracy: 0.8101 - val_loss: 0.8020 - val_binary_accuracy: 0.7918\n",
      "Epoch 753/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7302 - binary_accuracy: 0.8114 - val_loss: 0.8020 - val_binary_accuracy: 0.7918\n",
      "Epoch 754/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7399 - binary_accuracy: 0.8049 - val_loss: 0.8020 - val_binary_accuracy: 0.7918\n",
      "Epoch 755/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7540 - binary_accuracy: 0.7930 - val_loss: 0.8020 - val_binary_accuracy: 0.7918\n",
      "Epoch 756/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7611 - binary_accuracy: 0.7869 - val_loss: 0.8020 - val_binary_accuracy: 0.7918\n",
      "Epoch 757/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7415 - binary_accuracy: 0.8017 - val_loss: 0.8019 - val_binary_accuracy: 0.7918\n",
      "Epoch 758/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7437 - binary_accuracy: 0.8006 - val_loss: 0.8019 - val_binary_accuracy: 0.7918\n",
      "Epoch 759/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7358 - binary_accuracy: 0.8069 - val_loss: 0.8019 - val_binary_accuracy: 0.7919\n",
      "Epoch 760/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7344 - binary_accuracy: 0.8084 - val_loss: 0.8019 - val_binary_accuracy: 0.7919\n",
      "Epoch 761/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7377 - binary_accuracy: 0.8050 - val_loss: 0.8019 - val_binary_accuracy: 0.7918\n",
      "Epoch 762/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7470 - binary_accuracy: 0.7973 - val_loss: 0.8019 - val_binary_accuracy: 0.7919\n",
      "Epoch 763/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7338 - binary_accuracy: 0.8090 - val_loss: 0.8019 - val_binary_accuracy: 0.7918\n",
      "Epoch 764/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7295 - binary_accuracy: 0.8122 - val_loss: 0.8019 - val_binary_accuracy: 0.7918\n",
      "Epoch 765/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7335 - binary_accuracy: 0.8093 - val_loss: 0.8019 - val_binary_accuracy: 0.7918\n",
      "Epoch 766/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7474 - binary_accuracy: 0.7950 - val_loss: 0.8019 - val_binary_accuracy: 0.7918\n",
      "Epoch 767/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7482 - binary_accuracy: 0.7976 - val_loss: 0.8019 - val_binary_accuracy: 0.7918\n",
      "Epoch 768/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7416 - binary_accuracy: 0.8028 - val_loss: 0.8019 - val_binary_accuracy: 0.7918\n",
      "Epoch 769/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7404 - binary_accuracy: 0.8031 - val_loss: 0.8018 - val_binary_accuracy: 0.7918\n",
      "Epoch 770/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7271 - binary_accuracy: 0.8140 - val_loss: 0.8019 - val_binary_accuracy: 0.7918\n",
      "Epoch 771/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7218 - binary_accuracy: 0.8176 - val_loss: 0.8018 - val_binary_accuracy: 0.7918\n",
      "Epoch 772/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7262 - binary_accuracy: 0.8132 - val_loss: 0.8018 - val_binary_accuracy: 0.7918\n",
      "Epoch 773/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7280 - binary_accuracy: 0.8112 - val_loss: 0.8018 - val_binary_accuracy: 0.7918\n",
      "Epoch 774/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7379 - binary_accuracy: 0.8036 - val_loss: 0.8018 - val_binary_accuracy: 0.7918\n",
      "Epoch 775/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7337 - binary_accuracy: 0.8085 - val_loss: 0.8018 - val_binary_accuracy: 0.7918\n",
      "Epoch 776/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7540 - binary_accuracy: 0.7920 - val_loss: 0.8018 - val_binary_accuracy: 0.7918\n",
      "Epoch 777/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7474 - binary_accuracy: 0.7975 - val_loss: 0.8018 - val_binary_accuracy: 0.7919\n",
      "Epoch 778/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7271 - binary_accuracy: 0.8131 - val_loss: 0.8018 - val_binary_accuracy: 0.7918\n",
      "Epoch 779/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7606 - binary_accuracy: 0.7865 - val_loss: 0.8017 - val_binary_accuracy: 0.7919\n",
      "Epoch 780/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7515 - binary_accuracy: 0.7927 - val_loss: 0.8017 - val_binary_accuracy: 0.7919\n",
      "Epoch 781/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7272 - binary_accuracy: 0.8132 - val_loss: 0.8017 - val_binary_accuracy: 0.7918\n",
      "Epoch 782/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7372 - binary_accuracy: 0.8056 - val_loss: 0.8017 - val_binary_accuracy: 0.7919\n",
      "Epoch 783/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7507 - binary_accuracy: 0.7949 - val_loss: 0.8017 - val_binary_accuracy: 0.7918\n",
      "Epoch 784/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7276 - binary_accuracy: 0.8141 - val_loss: 0.8017 - val_binary_accuracy: 0.7918\n",
      "Epoch 785/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7151 - binary_accuracy: 0.8232 - val_loss: 0.8017 - val_binary_accuracy: 0.7919\n",
      "Epoch 786/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7260 - binary_accuracy: 0.8146 - val_loss: 0.8017 - val_binary_accuracy: 0.7919\n",
      "Epoch 787/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7473 - binary_accuracy: 0.7986 - val_loss: 0.8017 - val_binary_accuracy: 0.7919\n",
      "Epoch 788/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7363 - binary_accuracy: 0.8064 - val_loss: 0.8017 - val_binary_accuracy: 0.7917\n",
      "Epoch 789/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7299 - binary_accuracy: 0.8101 - val_loss: 0.8016 - val_binary_accuracy: 0.7919\n",
      "Epoch 790/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7300 - binary_accuracy: 0.8108 - val_loss: 0.8016 - val_binary_accuracy: 0.7919\n",
      "Epoch 791/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7542 - binary_accuracy: 0.7931 - val_loss: 0.8016 - val_binary_accuracy: 0.7919\n",
      "Epoch 792/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7416 - binary_accuracy: 0.8006 - val_loss: 0.8016 - val_binary_accuracy: 0.7919\n",
      "Epoch 793/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7408 - binary_accuracy: 0.8023 - val_loss: 0.8016 - val_binary_accuracy: 0.7919\n",
      "Epoch 794/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7531 - binary_accuracy: 0.7921 - val_loss: 0.8016 - val_binary_accuracy: 0.7919\n",
      "Epoch 795/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7408 - binary_accuracy: 0.8013 - val_loss: 0.8016 - val_binary_accuracy: 0.7919\n",
      "Epoch 796/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7426 - binary_accuracy: 0.8012 - val_loss: 0.8016 - val_binary_accuracy: 0.7919\n",
      "Epoch 797/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7461 - binary_accuracy: 0.7977 - val_loss: 0.8015 - val_binary_accuracy: 0.7919\n",
      "Epoch 798/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7694 - binary_accuracy: 0.7795 - val_loss: 0.8015 - val_binary_accuracy: 0.7919\n",
      "Epoch 799/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7232 - binary_accuracy: 0.8153 - val_loss: 0.8015 - val_binary_accuracy: 0.7919\n",
      "Epoch 800/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7321 - binary_accuracy: 0.8084 - val_loss: 0.8015 - val_binary_accuracy: 0.7919\n",
      "Epoch 801/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7454 - binary_accuracy: 0.7997 - val_loss: 0.8015 - val_binary_accuracy: 0.7918\n",
      "Epoch 802/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7240 - binary_accuracy: 0.8146 - val_loss: 0.8015 - val_binary_accuracy: 0.7917\n",
      "Epoch 803/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7519 - binary_accuracy: 0.7933 - val_loss: 0.8015 - val_binary_accuracy: 0.7917\n",
      "Epoch 804/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7233 - binary_accuracy: 0.8162 - val_loss: 0.8015 - val_binary_accuracy: 0.7917\n",
      "Epoch 805/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7338 - binary_accuracy: 0.8072 - val_loss: 0.8015 - val_binary_accuracy: 0.7918\n",
      "Epoch 806/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7461 - binary_accuracy: 0.7989 - val_loss: 0.8015 - val_binary_accuracy: 0.7919\n",
      "Epoch 807/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7441 - binary_accuracy: 0.7985 - val_loss: 0.8015 - val_binary_accuracy: 0.7918\n",
      "Epoch 808/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7677 - binary_accuracy: 0.7819 - val_loss: 0.8015 - val_binary_accuracy: 0.7918\n",
      "Epoch 809/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7258 - binary_accuracy: 0.8147 - val_loss: 0.8014 - val_binary_accuracy: 0.7918\n",
      "Epoch 810/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7316 - binary_accuracy: 0.8104 - val_loss: 0.8014 - val_binary_accuracy: 0.7919\n",
      "Epoch 811/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7641 - binary_accuracy: 0.7838 - val_loss: 0.8014 - val_binary_accuracy: 0.7918\n",
      "Epoch 812/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7374 - binary_accuracy: 0.8031 - val_loss: 0.8014 - val_binary_accuracy: 0.7917\n",
      "Epoch 813/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7546 - binary_accuracy: 0.7921 - val_loss: 0.8014 - val_binary_accuracy: 0.7917\n",
      "Epoch 814/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7390 - binary_accuracy: 0.8037 - val_loss: 0.8014 - val_binary_accuracy: 0.7918\n",
      "Epoch 815/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7309 - binary_accuracy: 0.8106 - val_loss: 0.8014 - val_binary_accuracy: 0.7917\n",
      "Epoch 816/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7489 - binary_accuracy: 0.7954 - val_loss: 0.8014 - val_binary_accuracy: 0.7918\n",
      "Epoch 817/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7203 - binary_accuracy: 0.8203 - val_loss: 0.8014 - val_binary_accuracy: 0.7917\n",
      "Epoch 818/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7285 - binary_accuracy: 0.8113 - val_loss: 0.8014 - val_binary_accuracy: 0.7917\n",
      "Epoch 819/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7450 - binary_accuracy: 0.7992 - val_loss: 0.8014 - val_binary_accuracy: 0.7917\n",
      "Epoch 820/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7457 - binary_accuracy: 0.7985 - val_loss: 0.8014 - val_binary_accuracy: 0.7917\n",
      "Epoch 821/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7328 - binary_accuracy: 0.8098 - val_loss: 0.8014 - val_binary_accuracy: 0.7917\n",
      "Epoch 822/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7426 - binary_accuracy: 0.8014 - val_loss: 0.8013 - val_binary_accuracy: 0.7917\n",
      "Epoch 823/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7318 - binary_accuracy: 0.8103 - val_loss: 0.8013 - val_binary_accuracy: 0.7917\n",
      "Epoch 824/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7516 - binary_accuracy: 0.7937 - val_loss: 0.8013 - val_binary_accuracy: 0.7918\n",
      "Epoch 825/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7575 - binary_accuracy: 0.7876 - val_loss: 0.8013 - val_binary_accuracy: 0.7918\n",
      "Epoch 826/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7447 - binary_accuracy: 0.7977 - val_loss: 0.8013 - val_binary_accuracy: 0.7917\n",
      "Epoch 827/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7381 - binary_accuracy: 0.8025 - val_loss: 0.8013 - val_binary_accuracy: 0.7917\n",
      "Epoch 828/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7256 - binary_accuracy: 0.8156 - val_loss: 0.8013 - val_binary_accuracy: 0.7917\n",
      "Epoch 829/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7500 - binary_accuracy: 0.7940 - val_loss: 0.8013 - val_binary_accuracy: 0.7917\n",
      "Epoch 830/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7477 - binary_accuracy: 0.7964 - val_loss: 0.8013 - val_binary_accuracy: 0.7917\n",
      "Epoch 831/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7311 - binary_accuracy: 0.8098 - val_loss: 0.8013 - val_binary_accuracy: 0.7917\n",
      "Epoch 832/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7517 - binary_accuracy: 0.7915 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 833/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7237 - binary_accuracy: 0.8148 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 834/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7392 - binary_accuracy: 0.8043 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 835/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7507 - binary_accuracy: 0.7940 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 836/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7505 - binary_accuracy: 0.7928 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 837/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7191 - binary_accuracy: 0.8185 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 838/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7265 - binary_accuracy: 0.8135 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 839/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7554 - binary_accuracy: 0.7903 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 840/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7363 - binary_accuracy: 0.8055 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 841/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7554 - binary_accuracy: 0.7914 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 842/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7382 - binary_accuracy: 0.8035 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 843/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7371 - binary_accuracy: 0.8045 - val_loss: 0.8011 - val_binary_accuracy: 0.7917\n",
      "Epoch 844/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7189 - binary_accuracy: 0.8190 - val_loss: 0.8011 - val_binary_accuracy: 0.7917\n",
      "Epoch 845/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7323 - binary_accuracy: 0.8093 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 846/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7607 - binary_accuracy: 0.7856 - val_loss: 0.8012 - val_binary_accuracy: 0.7917\n",
      "Epoch 847/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7552 - binary_accuracy: 0.7913 - val_loss: 0.8011 - val_binary_accuracy: 0.7917\n",
      "Epoch 848/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7427 - binary_accuracy: 0.7998 - val_loss: 0.8011 - val_binary_accuracy: 0.7917\n",
      "Epoch 849/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7421 - binary_accuracy: 0.8022 - val_loss: 0.8011 - val_binary_accuracy: 0.7917\n",
      "Epoch 850/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7407 - binary_accuracy: 0.8023 - val_loss: 0.8011 - val_binary_accuracy: 0.7917\n",
      "Epoch 851/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7209 - binary_accuracy: 0.8177 - val_loss: 0.8011 - val_binary_accuracy: 0.7917\n",
      "Epoch 852/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7363 - binary_accuracy: 0.8059 - val_loss: 0.8011 - val_binary_accuracy: 0.7917\n",
      "Epoch 853/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7651 - binary_accuracy: 0.7836 - val_loss: 0.8011 - val_binary_accuracy: 0.7917\n",
      "Epoch 854/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7331 - binary_accuracy: 0.8084 - val_loss: 0.8011 - val_binary_accuracy: 0.7917\n",
      "Epoch 855/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7257 - binary_accuracy: 0.8131 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 856/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7259 - binary_accuracy: 0.8139 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 857/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7460 - binary_accuracy: 0.7963 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 858/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7421 - binary_accuracy: 0.7996 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 859/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7292 - binary_accuracy: 0.8104 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 860/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7386 - binary_accuracy: 0.8034 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 861/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7185 - binary_accuracy: 0.8182 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 862/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7515 - binary_accuracy: 0.7914 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 863/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7184 - binary_accuracy: 0.8187 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 864/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7379 - binary_accuracy: 0.8046 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 865/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7322 - binary_accuracy: 0.8088 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 866/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7340 - binary_accuracy: 0.8069 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 867/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7329 - binary_accuracy: 0.8075 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 868/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7226 - binary_accuracy: 0.8144 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 869/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7468 - binary_accuracy: 0.7963 - val_loss: 0.8010 - val_binary_accuracy: 0.7917\n",
      "Epoch 870/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7309 - binary_accuracy: 0.8099 - val_loss: 0.8009 - val_binary_accuracy: 0.7917\n",
      "Epoch 871/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7300 - binary_accuracy: 0.8098 - val_loss: 0.8009 - val_binary_accuracy: 0.7917\n",
      "Epoch 872/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7285 - binary_accuracy: 0.8111 - val_loss: 0.8009 - val_binary_accuracy: 0.7917\n",
      "Epoch 873/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7215 - binary_accuracy: 0.8155 - val_loss: 0.8009 - val_binary_accuracy: 0.7917\n",
      "Epoch 874/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7563 - binary_accuracy: 0.7895 - val_loss: 0.8009 - val_binary_accuracy: 0.7917\n",
      "Epoch 875/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7296 - binary_accuracy: 0.8108 - val_loss: 0.8009 - val_binary_accuracy: 0.7917\n",
      "Epoch 876/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7253 - binary_accuracy: 0.8132 - val_loss: 0.8009 - val_binary_accuracy: 0.7917\n",
      "Epoch 877/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7433 - binary_accuracy: 0.7998 - val_loss: 0.8009 - val_binary_accuracy: 0.7917\n",
      "Epoch 878/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7183 - binary_accuracy: 0.8208 - val_loss: 0.8009 - val_binary_accuracy: 0.7917\n",
      "Epoch 879/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7419 - binary_accuracy: 0.8002 - val_loss: 0.8009 - val_binary_accuracy: 0.7917\n",
      "Epoch 880/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7346 - binary_accuracy: 0.8057 - val_loss: 0.8009 - val_binary_accuracy: 0.7917\n",
      "Epoch 881/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7263 - binary_accuracy: 0.8127 - val_loss: 0.8008 - val_binary_accuracy: 0.7917\n",
      "Epoch 882/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7293 - binary_accuracy: 0.8109 - val_loss: 0.8008 - val_binary_accuracy: 0.7917\n",
      "Epoch 883/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7328 - binary_accuracy: 0.8068 - val_loss: 0.8008 - val_binary_accuracy: 0.7917\n",
      "Epoch 884/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7462 - binary_accuracy: 0.7973 - val_loss: 0.8008 - val_binary_accuracy: 0.7917\n",
      "Epoch 885/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7383 - binary_accuracy: 0.8050 - val_loss: 0.8008 - val_binary_accuracy: 0.7917\n",
      "Epoch 886/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7391 - binary_accuracy: 0.8028 - val_loss: 0.8008 - val_binary_accuracy: 0.7917\n",
      "Epoch 887/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7374 - binary_accuracy: 0.8044 - val_loss: 0.8008 - val_binary_accuracy: 0.7917\n",
      "Epoch 888/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7323 - binary_accuracy: 0.8084 - val_loss: 0.8008 - val_binary_accuracy: 0.7917\n",
      "Epoch 889/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7494 - binary_accuracy: 0.7937 - val_loss: 0.8008 - val_binary_accuracy: 0.7917\n",
      "Epoch 890/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7415 - binary_accuracy: 0.8015 - val_loss: 0.8008 - val_binary_accuracy: 0.7917\n",
      "Epoch 891/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7420 - binary_accuracy: 0.8001 - val_loss: 0.8008 - val_binary_accuracy: 0.7918\n",
      "Epoch 892/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7356 - binary_accuracy: 0.8040 - val_loss: 0.8008 - val_binary_accuracy: 0.7918\n",
      "Epoch 893/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7585 - binary_accuracy: 0.7873 - val_loss: 0.8008 - val_binary_accuracy: 0.7918\n",
      "Epoch 894/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7251 - binary_accuracy: 0.8143 - val_loss: 0.8007 - val_binary_accuracy: 0.7918\n",
      "Epoch 895/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7440 - binary_accuracy: 0.8012 - val_loss: 0.8007 - val_binary_accuracy: 0.7918\n",
      "Epoch 896/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7359 - binary_accuracy: 0.8028 - val_loss: 0.8007 - val_binary_accuracy: 0.7919\n",
      "Epoch 897/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7293 - binary_accuracy: 0.8102 - val_loss: 0.8007 - val_binary_accuracy: 0.7918\n",
      "Epoch 898/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7259 - binary_accuracy: 0.8128 - val_loss: 0.8007 - val_binary_accuracy: 0.7919\n",
      "Epoch 899/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7205 - binary_accuracy: 0.8172 - val_loss: 0.8007 - val_binary_accuracy: 0.7918\n",
      "Epoch 900/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7444 - binary_accuracy: 0.7989 - val_loss: 0.8007 - val_binary_accuracy: 0.7918\n",
      "Epoch 901/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7367 - binary_accuracy: 0.8027 - val_loss: 0.8007 - val_binary_accuracy: 0.7918\n",
      "Epoch 902/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7389 - binary_accuracy: 0.8018 - val_loss: 0.8007 - val_binary_accuracy: 0.7919\n",
      "Epoch 903/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7330 - binary_accuracy: 0.8074 - val_loss: 0.8007 - val_binary_accuracy: 0.7918\n",
      "Epoch 904/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7441 - binary_accuracy: 0.7968 - val_loss: 0.8007 - val_binary_accuracy: 0.7918\n",
      "Epoch 905/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7442 - binary_accuracy: 0.7983 - val_loss: 0.8007 - val_binary_accuracy: 0.7917\n",
      "Epoch 906/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7436 - binary_accuracy: 0.7971 - val_loss: 0.8007 - val_binary_accuracy: 0.7918\n",
      "Epoch 907/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7293 - binary_accuracy: 0.8108 - val_loss: 0.8007 - val_binary_accuracy: 0.7918\n",
      "Epoch 908/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7358 - binary_accuracy: 0.8061 - val_loss: 0.8006 - val_binary_accuracy: 0.7918\n",
      "Epoch 909/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7253 - binary_accuracy: 0.8148 - val_loss: 0.8006 - val_binary_accuracy: 0.7918\n",
      "Epoch 910/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7389 - binary_accuracy: 0.8015 - val_loss: 0.8006 - val_binary_accuracy: 0.7918\n",
      "Epoch 911/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7451 - binary_accuracy: 0.7960 - val_loss: 0.8006 - val_binary_accuracy: 0.7919\n",
      "Epoch 912/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7381 - binary_accuracy: 0.8031 - val_loss: 0.8006 - val_binary_accuracy: 0.7919\n",
      "Epoch 913/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7354 - binary_accuracy: 0.8038 - val_loss: 0.8006 - val_binary_accuracy: 0.7919\n",
      "Epoch 914/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7554 - binary_accuracy: 0.7909 - val_loss: 0.8006 - val_binary_accuracy: 0.7919\n",
      "Epoch 915/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7474 - binary_accuracy: 0.7969 - val_loss: 0.8006 - val_binary_accuracy: 0.7918\n",
      "Epoch 916/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7326 - binary_accuracy: 0.8080 - val_loss: 0.8006 - val_binary_accuracy: 0.7918\n",
      "Epoch 917/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7316 - binary_accuracy: 0.8081 - val_loss: 0.8006 - val_binary_accuracy: 0.7918\n",
      "Epoch 918/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7428 - binary_accuracy: 0.7990 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 919/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7352 - binary_accuracy: 0.8049 - val_loss: 0.8005 - val_binary_accuracy: 0.7919\n",
      "Epoch 920/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7322 - binary_accuracy: 0.8053 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 921/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7260 - binary_accuracy: 0.8121 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 922/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7452 - binary_accuracy: 0.7981 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 923/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7668 - binary_accuracy: 0.7785 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 924/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7201 - binary_accuracy: 0.8162 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 925/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7212 - binary_accuracy: 0.8178 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 926/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7463 - binary_accuracy: 0.7954 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 927/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7402 - binary_accuracy: 0.8011 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 928/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7463 - binary_accuracy: 0.7959 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 929/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7474 - binary_accuracy: 0.7955 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 930/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7375 - binary_accuracy: 0.8018 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 931/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7377 - binary_accuracy: 0.8015 - val_loss: 0.8005 - val_binary_accuracy: 0.7918\n",
      "Epoch 932/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7288 - binary_accuracy: 0.8100 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 933/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7283 - binary_accuracy: 0.8102 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 934/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7355 - binary_accuracy: 0.8029 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 935/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7447 - binary_accuracy: 0.7962 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 936/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7339 - binary_accuracy: 0.8054 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 937/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7381 - binary_accuracy: 0.8024 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 938/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7355 - binary_accuracy: 0.8061 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 939/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7423 - binary_accuracy: 0.7997 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 940/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7474 - binary_accuracy: 0.7965 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 941/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7380 - binary_accuracy: 0.8018 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 942/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7355 - binary_accuracy: 0.8062 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 943/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7340 - binary_accuracy: 0.8044 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 944/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7221 - binary_accuracy: 0.8148 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 945/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7304 - binary_accuracy: 0.8079 - val_loss: 0.8004 - val_binary_accuracy: 0.7918\n",
      "Epoch 946/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7282 - binary_accuracy: 0.8121 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 947/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7451 - binary_accuracy: 0.7987 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 948/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7113 - binary_accuracy: 0.8251 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 949/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7623 - binary_accuracy: 0.7845 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 950/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7406 - binary_accuracy: 0.7996 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 951/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7522 - binary_accuracy: 0.7906 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 952/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7275 - binary_accuracy: 0.8112 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 953/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7172 - binary_accuracy: 0.8206 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 954/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7311 - binary_accuracy: 0.8084 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 955/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7377 - binary_accuracy: 0.8021 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 956/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7503 - binary_accuracy: 0.7938 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 957/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7175 - binary_accuracy: 0.8181 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 958/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7459 - binary_accuracy: 0.7958 - val_loss: 0.8002 - val_binary_accuracy: 0.7918\n",
      "Epoch 959/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7222 - binary_accuracy: 0.8160 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 960/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7230 - binary_accuracy: 0.8151 - val_loss: 0.8003 - val_binary_accuracy: 0.7918\n",
      "Epoch 961/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7259 - binary_accuracy: 0.8137 - val_loss: 0.8002 - val_binary_accuracy: 0.7918\n",
      "Epoch 962/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7499 - binary_accuracy: 0.7917 - val_loss: 0.8002 - val_binary_accuracy: 0.7919\n",
      "Epoch 963/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7337 - binary_accuracy: 0.8056 - val_loss: 0.8002 - val_binary_accuracy: 0.7918\n",
      "Epoch 964/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7387 - binary_accuracy: 0.8032 - val_loss: 0.8002 - val_binary_accuracy: 0.7918\n",
      "Epoch 965/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7356 - binary_accuracy: 0.8054 - val_loss: 0.8002 - val_binary_accuracy: 0.7918\n",
      "Epoch 966/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7299 - binary_accuracy: 0.8085 - val_loss: 0.8002 - val_binary_accuracy: 0.7918\n",
      "Epoch 967/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7281 - binary_accuracy: 0.8118 - val_loss: 0.8002 - val_binary_accuracy: 0.7918\n",
      "Epoch 968/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7331 - binary_accuracy: 0.8071 - val_loss: 0.8002 - val_binary_accuracy: 0.7918\n",
      "Epoch 969/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7379 - binary_accuracy: 0.8026 - val_loss: 0.8002 - val_binary_accuracy: 0.7918\n",
      "Epoch 970/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7506 - binary_accuracy: 0.7928 - val_loss: 0.8002 - val_binary_accuracy: 0.7917\n",
      "Epoch 971/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7261 - binary_accuracy: 0.8126 - val_loss: 0.8002 - val_binary_accuracy: 0.7917\n",
      "Epoch 972/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7247 - binary_accuracy: 0.8131 - val_loss: 0.8002 - val_binary_accuracy: 0.7917\n",
      "Epoch 973/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7298 - binary_accuracy: 0.8081 - val_loss: 0.8001 - val_binary_accuracy: 0.7917\n",
      "Epoch 974/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7500 - binary_accuracy: 0.7918 - val_loss: 0.8001 - val_binary_accuracy: 0.7918\n",
      "Epoch 975/1000\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7263 - binary_accuracy: 0.8107 - val_loss: 0.8001 - val_binary_accuracy: 0.7918\n",
      "Epoch 976/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7301 - binary_accuracy: 0.8094 - val_loss: 0.8001 - val_binary_accuracy: 0.7919\n",
      "Epoch 977/1000\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7444 - binary_accuracy: 0.7979 - val_loss: 0.8001 - val_binary_accuracy: 0.7919\n",
      "Epoch 978/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7421 - binary_accuracy: 0.7983 - val_loss: 0.8001 - val_binary_accuracy: 0.7917\n",
      "Epoch 979/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7339 - binary_accuracy: 0.8065 - val_loss: 0.8001 - val_binary_accuracy: 0.7918\n",
      "Epoch 980/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7320 - binary_accuracy: 0.8067 - val_loss: 0.8001 - val_binary_accuracy: 0.7919\n",
      "Epoch 981/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7371 - binary_accuracy: 0.8023 - val_loss: 0.8001 - val_binary_accuracy: 0.7917\n",
      "Epoch 982/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7458 - binary_accuracy: 0.7963 - val_loss: 0.8001 - val_binary_accuracy: 0.7916\n",
      "Epoch 983/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7313 - binary_accuracy: 0.8093 - val_loss: 0.8001 - val_binary_accuracy: 0.7917\n",
      "Epoch 984/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7307 - binary_accuracy: 0.8113 - val_loss: 0.8001 - val_binary_accuracy: 0.7918\n",
      "Epoch 985/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7264 - binary_accuracy: 0.8128 - val_loss: 0.8001 - val_binary_accuracy: 0.7917\n",
      "Epoch 986/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7258 - binary_accuracy: 0.8138 - val_loss: 0.8001 - val_binary_accuracy: 0.7917\n",
      "Epoch 987/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7335 - binary_accuracy: 0.8061 - val_loss: 0.8000 - val_binary_accuracy: 0.7918\n",
      "Epoch 988/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7343 - binary_accuracy: 0.8047 - val_loss: 0.8000 - val_binary_accuracy: 0.7917\n",
      "Epoch 989/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7294 - binary_accuracy: 0.8109 - val_loss: 0.8000 - val_binary_accuracy: 0.7917\n",
      "Epoch 990/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7321 - binary_accuracy: 0.8056 - val_loss: 0.8000 - val_binary_accuracy: 0.7917\n",
      "Epoch 991/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7226 - binary_accuracy: 0.8143 - val_loss: 0.8000 - val_binary_accuracy: 0.7917\n",
      "Epoch 992/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7311 - binary_accuracy: 0.8075 - val_loss: 0.8000 - val_binary_accuracy: 0.7917\n",
      "Epoch 993/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7413 - binary_accuracy: 0.8006 - val_loss: 0.8000 - val_binary_accuracy: 0.7917\n",
      "Epoch 994/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7165 - binary_accuracy: 0.8190 - val_loss: 0.8000 - val_binary_accuracy: 0.7918\n",
      "Epoch 995/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7240 - binary_accuracy: 0.8124 - val_loss: 0.8000 - val_binary_accuracy: 0.7918\n",
      "Epoch 996/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7541 - binary_accuracy: 0.7911 - val_loss: 0.8000 - val_binary_accuracy: 0.7917\n",
      "Epoch 997/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7359 - binary_accuracy: 0.8024 - val_loss: 0.8000 - val_binary_accuracy: 0.7917\n",
      "Epoch 998/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7404 - binary_accuracy: 0.8002 - val_loss: 0.8000 - val_binary_accuracy: 0.7918\n",
      "Epoch 999/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7228 - binary_accuracy: 0.8125 - val_loss: 0.8000 - val_binary_accuracy: 0.7918\n",
      "Epoch 1000/1000\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7181 - binary_accuracy: 0.8190 - val_loss: 0.8000 - val_binary_accuracy: 0.7918\n"
     ]
    }
   ],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history2 = FNN_MFCC_n_pt.fit(X_train, y_train, epochs=1000, verbose=1, validation_split=0.3, callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5832e029-7fd2-4d3f-8cc6-7bdf93be5aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23499edd-0fe7-4444-845d-6981d3452d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step - loss: 0.7991 - binary_accuracy: 0.7930\n",
      "Train Accuracy: 0.8039\n",
      "Test Accuracy: 0.7930\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the network\n",
    "train_accuracy = history2.history[\"binary_accuracy\"][-1]\n",
    "result = FNN_MFCC_n_pt.evaluate(X_test,y_test, verbose=1)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {result[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "380ec533-e096-4611-b5d0-8c82e09a54b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 20, 512)           50176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 20, 512)           2048      \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 20, 128)           65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 20, 128)           512       \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 20, 32)            4128      \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 20, 1)             33        \n",
      "=================================================================\n",
      "Total params: 122,561\n",
      "Trainable params: 121,281\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "FNN_MFCC_n_pt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9bfeaf97-ae9e-49d2-9408-256b926f364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/jmd/Documents/BOOTCAMP/Capstone/neural_nets/FFN_MFCC_no_patient/assets\n"
     ]
    }
   ],
   "source": [
    "#saving model\n",
    "FNN_MFCC_n_pt.save('/Users/jmd/Documents/BOOTCAMP/Capstone/neural_nets/FFN_MFCC_no_patient')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae70820-08e9-4c41-9f9e-1e28fcd78e7b",
   "metadata": {},
   "source": [
    "### MFCC w/ Patient Info: FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e9f3df2f-2ebe-433a-a8bc-ca93f876291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('/Users/jmd/Documents/BOOTCAMP/Capstone/arrays/MFCCs_withPatient.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "da948b7a-6e70-48a2-9199-ea14be8ed4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f8edf7fe-1679-486b-bc50-705ca5cc9a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2104, 30, 97)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "767e9cfe-d2ab-42cf-9b7c-3455051fc331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new sequential model\n",
    "FNN_MFCC_y_pt = keras.Sequential()\n",
    "\n",
    "# Declare the hidden layers\n",
    "FNN_MFCC_y_pt.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"))\n",
    "#model.add(layers.Dropout(0.4))\n",
    "FNN_MFCC_y_pt.add(layers.BatchNormalization())  \n",
    "\n",
    "FNN_MFCC_y_pt.add(layers.Dense(128, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"))\n",
    "#model.add(layers.Dropout(0.4))\n",
    "FNN_MFCC_y_pt.add(layers.BatchNormalization())  \n",
    "\n",
    "FNN_MFCC_y_pt.add(layers.Dense(32, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"))\n",
    "#model.add(layers.Dropout(0.4))\n",
    "\n",
    "# Declare the output layer\n",
    "FNN_MFCC_y_pt.add(layers.Dense(1, kernel_regularizer=regularizers.l2(0.001), activation=\"sigmoid\"))\n",
    "\n",
    "#declaring learning rate schedule\n",
    "lr_schedule = keras.optimizers.schedules.InverseTimeDecay(0.001, decay_steps=1.0, decay_rate=0.1)\n",
    "\n",
    "\n",
    "FNN_MFCC_y_pt.compile(\n",
    "    # Optimizer\n",
    "    optimizer=keras.optimizers.Adam(lr_schedule),  \n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    # Metric used to evaluate model\n",
    "    metrics=[keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3108728b-dfef-4ddc-aa38-eccc49c82e2e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.9659 - binary_accuracy: 0.7666 - val_loss: 1.0043 - val_binary_accuracy: 0.7430\n",
      "Epoch 2/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.9005 - binary_accuracy: 0.7934 - val_loss: 0.9253 - val_binary_accuracy: 0.7876\n",
      "Epoch 3/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8668 - binary_accuracy: 0.8079 - val_loss: 0.9072 - val_binary_accuracy: 0.7870\n",
      "Epoch 4/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8761 - binary_accuracy: 0.7947 - val_loss: 0.8882 - val_binary_accuracy: 0.7948\n",
      "Epoch 5/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8576 - binary_accuracy: 0.8021 - val_loss: 0.8772 - val_binary_accuracy: 0.7967\n",
      "Epoch 6/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8571 - binary_accuracy: 0.7999 - val_loss: 0.8690 - val_binary_accuracy: 0.7975\n",
      "Epoch 7/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8825 - binary_accuracy: 0.7762 - val_loss: 0.8637 - val_binary_accuracy: 0.7981\n",
      "Epoch 8/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8348 - binary_accuracy: 0.8093 - val_loss: 0.8608 - val_binary_accuracy: 0.7979\n",
      "Epoch 9/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8582 - binary_accuracy: 0.7892 - val_loss: 0.8575 - val_binary_accuracy: 0.7980\n",
      "Epoch 10/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8517 - binary_accuracy: 0.7917 - val_loss: 0.8550 - val_binary_accuracy: 0.7980\n",
      "Epoch 11/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8567 - binary_accuracy: 0.7853 - val_loss: 0.8530 - val_binary_accuracy: 0.7977\n",
      "Epoch 12/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8451 - binary_accuracy: 0.7928 - val_loss: 0.8513 - val_binary_accuracy: 0.7979\n",
      "Epoch 13/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.8457 - binary_accuracy: 0.7903 - val_loss: 0.8494 - val_binary_accuracy: 0.7978\n",
      "Epoch 14/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8174 - binary_accuracy: 0.8100 - val_loss: 0.8480 - val_binary_accuracy: 0.7978\n",
      "Epoch 15/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8218 - binary_accuracy: 0.8053 - val_loss: 0.8463 - val_binary_accuracy: 0.7976\n",
      "Epoch 16/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8309 - binary_accuracy: 0.7973 - val_loss: 0.8452 - val_binary_accuracy: 0.7976\n",
      "Epoch 17/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8428 - binary_accuracy: 0.7872 - val_loss: 0.8437 - val_binary_accuracy: 0.7976\n",
      "Epoch 18/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8160 - binary_accuracy: 0.8064 - val_loss: 0.8426 - val_binary_accuracy: 0.7974\n",
      "Epoch 19/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8301 - binary_accuracy: 0.7941 - val_loss: 0.8415 - val_binary_accuracy: 0.7976\n",
      "Epoch 20/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8389 - binary_accuracy: 0.7866 - val_loss: 0.8403 - val_binary_accuracy: 0.7977\n",
      "Epoch 21/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8433 - binary_accuracy: 0.7814 - val_loss: 0.8396 - val_binary_accuracy: 0.7974\n",
      "Epoch 22/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7993 - binary_accuracy: 0.8145 - val_loss: 0.8387 - val_binary_accuracy: 0.7978\n",
      "Epoch 23/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8123 - binary_accuracy: 0.8027 - val_loss: 0.8377 - val_binary_accuracy: 0.7976\n",
      "Epoch 24/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8309 - binary_accuracy: 0.7885 - val_loss: 0.8367 - val_binary_accuracy: 0.7977\n",
      "Epoch 25/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8279 - binary_accuracy: 0.7905 - val_loss: 0.8359 - val_binary_accuracy: 0.7975\n",
      "Epoch 26/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8298 - binary_accuracy: 0.7887 - val_loss: 0.8350 - val_binary_accuracy: 0.7976\n",
      "Epoch 27/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8097 - binary_accuracy: 0.8024 - val_loss: 0.8344 - val_binary_accuracy: 0.7974\n",
      "Epoch 28/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8063 - binary_accuracy: 0.8042 - val_loss: 0.8336 - val_binary_accuracy: 0.7975\n",
      "Epoch 29/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8376 - binary_accuracy: 0.7790 - val_loss: 0.8330 - val_binary_accuracy: 0.7975\n",
      "Epoch 30/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8212 - binary_accuracy: 0.7923 - val_loss: 0.8323 - val_binary_accuracy: 0.7974\n",
      "Epoch 31/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8138 - binary_accuracy: 0.7965 - val_loss: 0.8317 - val_binary_accuracy: 0.7974\n",
      "Epoch 32/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8043 - binary_accuracy: 0.8029 - val_loss: 0.8310 - val_binary_accuracy: 0.7975\n",
      "Epoch 33/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7933 - binary_accuracy: 0.8111 - val_loss: 0.8305 - val_binary_accuracy: 0.7976\n",
      "Epoch 34/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8351 - binary_accuracy: 0.7791 - val_loss: 0.8299 - val_binary_accuracy: 0.7974\n",
      "Epoch 35/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8254 - binary_accuracy: 0.7855 - val_loss: 0.8293 - val_binary_accuracy: 0.7975\n",
      "Epoch 36/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7894 - binary_accuracy: 0.8120 - val_loss: 0.8288 - val_binary_accuracy: 0.7975\n",
      "Epoch 37/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8090 - binary_accuracy: 0.7975 - val_loss: 0.8283 - val_binary_accuracy: 0.7976\n",
      "Epoch 38/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8277 - binary_accuracy: 0.7830 - val_loss: 0.8279 - val_binary_accuracy: 0.7975\n",
      "Epoch 39/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8142 - binary_accuracy: 0.7915 - val_loss: 0.8273 - val_binary_accuracy: 0.7976\n",
      "Epoch 40/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.8029 - binary_accuracy: 0.8002 - val_loss: 0.8268 - val_binary_accuracy: 0.7976\n",
      "Epoch 41/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8001 - binary_accuracy: 0.8025 - val_loss: 0.8265 - val_binary_accuracy: 0.7975\n",
      "Epoch 42/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8015 - binary_accuracy: 0.8009 - val_loss: 0.8259 - val_binary_accuracy: 0.7975\n",
      "Epoch 43/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8168 - binary_accuracy: 0.7882 - val_loss: 0.8255 - val_binary_accuracy: 0.7975\n",
      "Epoch 44/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8055 - binary_accuracy: 0.7972 - val_loss: 0.8250 - val_binary_accuracy: 0.7976\n",
      "Epoch 45/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8117 - binary_accuracy: 0.7916 - val_loss: 0.8247 - val_binary_accuracy: 0.7974\n",
      "Epoch 46/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8159 - binary_accuracy: 0.7870 - val_loss: 0.8243 - val_binary_accuracy: 0.7973\n",
      "Epoch 47/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7860 - binary_accuracy: 0.8106 - val_loss: 0.8239 - val_binary_accuracy: 0.7973\n",
      "Epoch 48/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8092 - binary_accuracy: 0.7926 - val_loss: 0.8236 - val_binary_accuracy: 0.7974\n",
      "Epoch 49/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7915 - binary_accuracy: 0.8053 - val_loss: 0.8231 - val_binary_accuracy: 0.7974\n",
      "Epoch 50/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7949 - binary_accuracy: 0.8035 - val_loss: 0.8228 - val_binary_accuracy: 0.7974\n",
      "Epoch 51/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7820 - binary_accuracy: 0.8122 - val_loss: 0.8224 - val_binary_accuracy: 0.7974\n",
      "Epoch 52/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7976 - binary_accuracy: 0.7994 - val_loss: 0.8221 - val_binary_accuracy: 0.7975\n",
      "Epoch 53/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8108 - binary_accuracy: 0.7895 - val_loss: 0.8218 - val_binary_accuracy: 0.7974\n",
      "Epoch 54/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7911 - binary_accuracy: 0.8056 - val_loss: 0.8214 - val_binary_accuracy: 0.7973\n",
      "Epoch 55/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8102 - binary_accuracy: 0.7894 - val_loss: 0.8211 - val_binary_accuracy: 0.7973\n",
      "Epoch 56/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7991 - binary_accuracy: 0.7970 - val_loss: 0.8208 - val_binary_accuracy: 0.7973\n",
      "Epoch 57/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8259 - binary_accuracy: 0.7762 - val_loss: 0.8205 - val_binary_accuracy: 0.7973\n",
      "Epoch 58/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7922 - binary_accuracy: 0.8014 - val_loss: 0.8202 - val_binary_accuracy: 0.7974\n",
      "Epoch 59/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7949 - binary_accuracy: 0.7988 - val_loss: 0.8200 - val_binary_accuracy: 0.7973\n",
      "Epoch 60/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8075 - binary_accuracy: 0.7884 - val_loss: 0.8196 - val_binary_accuracy: 0.7972\n",
      "Epoch 61/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7870 - binary_accuracy: 0.8044 - val_loss: 0.8194 - val_binary_accuracy: 0.7973\n",
      "Epoch 62/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.8040 - binary_accuracy: 0.7913 - val_loss: 0.8191 - val_binary_accuracy: 0.7973\n",
      "Epoch 63/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7956 - binary_accuracy: 0.7978 - val_loss: 0.8188 - val_binary_accuracy: 0.7974\n",
      "Epoch 64/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7914 - binary_accuracy: 0.7998 - val_loss: 0.8185 - val_binary_accuracy: 0.7972\n",
      "Epoch 65/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7928 - binary_accuracy: 0.7990 - val_loss: 0.8183 - val_binary_accuracy: 0.7973\n",
      "Epoch 66/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7846 - binary_accuracy: 0.8053 - val_loss: 0.8180 - val_binary_accuracy: 0.7973\n",
      "Epoch 67/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8110 - binary_accuracy: 0.7848 - val_loss: 0.8178 - val_binary_accuracy: 0.7972\n",
      "Epoch 68/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7822 - binary_accuracy: 0.8064 - val_loss: 0.8176 - val_binary_accuracy: 0.7973\n",
      "Epoch 69/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7947 - binary_accuracy: 0.7979 - val_loss: 0.8173 - val_binary_accuracy: 0.7972\n",
      "Epoch 70/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7977 - binary_accuracy: 0.7941 - val_loss: 0.8171 - val_binary_accuracy: 0.7971\n",
      "Epoch 71/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7934 - binary_accuracy: 0.7976 - val_loss: 0.8169 - val_binary_accuracy: 0.7972\n",
      "Epoch 72/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8023 - binary_accuracy: 0.7894 - val_loss: 0.8166 - val_binary_accuracy: 0.7972\n",
      "Epoch 73/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7975 - binary_accuracy: 0.7935 - val_loss: 0.8164 - val_binary_accuracy: 0.7972\n",
      "Epoch 74/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8095 - binary_accuracy: 0.7839 - val_loss: 0.8162 - val_binary_accuracy: 0.7973\n",
      "Epoch 75/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8047 - binary_accuracy: 0.7873 - val_loss: 0.8159 - val_binary_accuracy: 0.7972\n",
      "Epoch 76/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7898 - binary_accuracy: 0.7998 - val_loss: 0.8157 - val_binary_accuracy: 0.7970\n",
      "Epoch 77/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7958 - binary_accuracy: 0.7930 - val_loss: 0.8155 - val_binary_accuracy: 0.7971\n",
      "Epoch 78/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7849 - binary_accuracy: 0.8027 - val_loss: 0.8153 - val_binary_accuracy: 0.7971\n",
      "Epoch 79/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7971 - binary_accuracy: 0.7937 - val_loss: 0.8151 - val_binary_accuracy: 0.7971\n",
      "Epoch 80/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7759 - binary_accuracy: 0.8089 - val_loss: 0.8149 - val_binary_accuracy: 0.7970\n",
      "Epoch 81/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8062 - binary_accuracy: 0.7859 - val_loss: 0.8147 - val_binary_accuracy: 0.7972\n",
      "Epoch 82/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7826 - binary_accuracy: 0.8034 - val_loss: 0.8145 - val_binary_accuracy: 0.7971\n",
      "Epoch 83/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7716 - binary_accuracy: 0.8121 - val_loss: 0.8143 - val_binary_accuracy: 0.7970\n",
      "Epoch 84/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7903 - binary_accuracy: 0.7984 - val_loss: 0.8141 - val_binary_accuracy: 0.7972\n",
      "Epoch 85/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8062 - binary_accuracy: 0.7834 - val_loss: 0.8139 - val_binary_accuracy: 0.7972\n",
      "Epoch 86/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7848 - binary_accuracy: 0.8011 - val_loss: 0.8137 - val_binary_accuracy: 0.7972\n",
      "Epoch 87/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7947 - binary_accuracy: 0.7939 - val_loss: 0.8136 - val_binary_accuracy: 0.7972\n",
      "Epoch 88/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7766 - binary_accuracy: 0.8079 - val_loss: 0.8134 - val_binary_accuracy: 0.7972\n",
      "Epoch 89/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7869 - binary_accuracy: 0.7984 - val_loss: 0.8132 - val_binary_accuracy: 0.7972\n",
      "Epoch 90/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7699 - binary_accuracy: 0.8111 - val_loss: 0.8130 - val_binary_accuracy: 0.7972\n",
      "Epoch 91/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7763 - binary_accuracy: 0.8061 - val_loss: 0.8128 - val_binary_accuracy: 0.7972\n",
      "Epoch 92/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8060 - binary_accuracy: 0.7823 - val_loss: 0.8127 - val_binary_accuracy: 0.7971\n",
      "Epoch 93/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7887 - binary_accuracy: 0.7965 - val_loss: 0.8125 - val_binary_accuracy: 0.7972\n",
      "Epoch 94/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7885 - binary_accuracy: 0.7965 - val_loss: 0.8123 - val_binary_accuracy: 0.7972\n",
      "Epoch 95/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7768 - binary_accuracy: 0.8063 - val_loss: 0.8122 - val_binary_accuracy: 0.7972\n",
      "Epoch 96/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8036 - binary_accuracy: 0.7848 - val_loss: 0.8120 - val_binary_accuracy: 0.7972\n",
      "Epoch 97/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.8053 - binary_accuracy: 0.7839 - val_loss: 0.8118 - val_binary_accuracy: 0.7972\n",
      "Epoch 98/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7974 - binary_accuracy: 0.7898 - val_loss: 0.8117 - val_binary_accuracy: 0.7972\n",
      "Epoch 99/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8167 - binary_accuracy: 0.7746 - val_loss: 0.8115 - val_binary_accuracy: 0.7971\n",
      "Epoch 100/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7877 - binary_accuracy: 0.7960 - val_loss: 0.8114 - val_binary_accuracy: 0.7972\n",
      "Epoch 101/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7751 - binary_accuracy: 0.8057 - val_loss: 0.8112 - val_binary_accuracy: 0.7971\n",
      "Epoch 102/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7955 - binary_accuracy: 0.7908 - val_loss: 0.8111 - val_binary_accuracy: 0.7971\n",
      "Epoch 103/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7845 - binary_accuracy: 0.7990 - val_loss: 0.8109 - val_binary_accuracy: 0.7970\n",
      "Epoch 104/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8065 - binary_accuracy: 0.7803 - val_loss: 0.8108 - val_binary_accuracy: 0.7971\n",
      "Epoch 105/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7931 - binary_accuracy: 0.7917 - val_loss: 0.8107 - val_binary_accuracy: 0.7972\n",
      "Epoch 106/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7939 - binary_accuracy: 0.7900 - val_loss: 0.8105 - val_binary_accuracy: 0.7970\n",
      "Epoch 107/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7914 - binary_accuracy: 0.7929 - val_loss: 0.8104 - val_binary_accuracy: 0.7971\n",
      "Epoch 108/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7666 - binary_accuracy: 0.8109 - val_loss: 0.8103 - val_binary_accuracy: 0.7970\n",
      "Epoch 109/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7820 - binary_accuracy: 0.7996 - val_loss: 0.8101 - val_binary_accuracy: 0.7971\n",
      "Epoch 110/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7702 - binary_accuracy: 0.8091 - val_loss: 0.8100 - val_binary_accuracy: 0.7970\n",
      "Epoch 111/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7880 - binary_accuracy: 0.7944 - val_loss: 0.8099 - val_binary_accuracy: 0.7970\n",
      "Epoch 112/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7768 - binary_accuracy: 0.8028 - val_loss: 0.8097 - val_binary_accuracy: 0.7971\n",
      "Epoch 113/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7759 - binary_accuracy: 0.8036 - val_loss: 0.8096 - val_binary_accuracy: 0.7972\n",
      "Epoch 114/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7851 - binary_accuracy: 0.7950 - val_loss: 0.8095 - val_binary_accuracy: 0.7972\n",
      "Epoch 115/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7765 - binary_accuracy: 0.8027 - val_loss: 0.8093 - val_binary_accuracy: 0.7972\n",
      "Epoch 116/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7586 - binary_accuracy: 0.8166 - val_loss: 0.8092 - val_binary_accuracy: 0.7972\n",
      "Epoch 117/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7860 - binary_accuracy: 0.7946 - val_loss: 0.8091 - val_binary_accuracy: 0.7970\n",
      "Epoch 118/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7814 - binary_accuracy: 0.7979 - val_loss: 0.8090 - val_binary_accuracy: 0.7970\n",
      "Epoch 119/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7765 - binary_accuracy: 0.8021 - val_loss: 0.8089 - val_binary_accuracy: 0.7970\n",
      "Epoch 120/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7844 - binary_accuracy: 0.7966 - val_loss: 0.8087 - val_binary_accuracy: 0.7970\n",
      "Epoch 121/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7774 - binary_accuracy: 0.8011 - val_loss: 0.8086 - val_binary_accuracy: 0.7970\n",
      "Epoch 122/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7914 - binary_accuracy: 0.7905 - val_loss: 0.8085 - val_binary_accuracy: 0.7970\n",
      "Epoch 123/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7757 - binary_accuracy: 0.8016 - val_loss: 0.8084 - val_binary_accuracy: 0.7970\n",
      "Epoch 124/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7672 - binary_accuracy: 0.8088 - val_loss: 0.8083 - val_binary_accuracy: 0.7970\n",
      "Epoch 125/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7739 - binary_accuracy: 0.8027 - val_loss: 0.8082 - val_binary_accuracy: 0.7969\n",
      "Epoch 126/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7964 - binary_accuracy: 0.7866 - val_loss: 0.8081 - val_binary_accuracy: 0.7969\n",
      "Epoch 127/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7622 - binary_accuracy: 0.8119 - val_loss: 0.8079 - val_binary_accuracy: 0.7970\n",
      "Epoch 128/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7841 - binary_accuracy: 0.7956 - val_loss: 0.8079 - val_binary_accuracy: 0.7969\n",
      "Epoch 129/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7863 - binary_accuracy: 0.7931 - val_loss: 0.8077 - val_binary_accuracy: 0.7970\n",
      "Epoch 130/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7831 - binary_accuracy: 0.7972 - val_loss: 0.8076 - val_binary_accuracy: 0.7970\n",
      "Epoch 131/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7858 - binary_accuracy: 0.7936 - val_loss: 0.8075 - val_binary_accuracy: 0.7970\n",
      "Epoch 132/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7589 - binary_accuracy: 0.8140 - val_loss: 0.8074 - val_binary_accuracy: 0.7969\n",
      "Epoch 133/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7833 - binary_accuracy: 0.7956 - val_loss: 0.8073 - val_binary_accuracy: 0.7969\n",
      "Epoch 134/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7925 - binary_accuracy: 0.7876 - val_loss: 0.8072 - val_binary_accuracy: 0.7970\n",
      "Epoch 135/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7939 - binary_accuracy: 0.7868 - val_loss: 0.8071 - val_binary_accuracy: 0.7969\n",
      "Epoch 136/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7718 - binary_accuracy: 0.8031 - val_loss: 0.8070 - val_binary_accuracy: 0.7970\n",
      "Epoch 137/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7835 - binary_accuracy: 0.7951 - val_loss: 0.8069 - val_binary_accuracy: 0.7969\n",
      "Epoch 138/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7901 - binary_accuracy: 0.7907 - val_loss: 0.8068 - val_binary_accuracy: 0.7969\n",
      "Epoch 139/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7581 - binary_accuracy: 0.8137 - val_loss: 0.8067 - val_binary_accuracy: 0.7970\n",
      "Epoch 140/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7914 - binary_accuracy: 0.7884 - val_loss: 0.8066 - val_binary_accuracy: 0.7969\n",
      "Epoch 141/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7799 - binary_accuracy: 0.7965 - val_loss: 0.8065 - val_binary_accuracy: 0.7969\n",
      "Epoch 142/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7740 - binary_accuracy: 0.8023 - val_loss: 0.8064 - val_binary_accuracy: 0.7968\n",
      "Epoch 143/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7538 - binary_accuracy: 0.8167 - val_loss: 0.8063 - val_binary_accuracy: 0.7969\n",
      "Epoch 144/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7932 - binary_accuracy: 0.7876 - val_loss: 0.8062 - val_binary_accuracy: 0.7968\n",
      "Epoch 145/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7666 - binary_accuracy: 0.8066 - val_loss: 0.8061 - val_binary_accuracy: 0.7968\n",
      "Epoch 146/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7833 - binary_accuracy: 0.7948 - val_loss: 0.8060 - val_binary_accuracy: 0.7968\n",
      "Epoch 147/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7818 - binary_accuracy: 0.7948 - val_loss: 0.8059 - val_binary_accuracy: 0.7970\n",
      "Epoch 148/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7678 - binary_accuracy: 0.8061 - val_loss: 0.8058 - val_binary_accuracy: 0.7969\n",
      "Epoch 149/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7860 - binary_accuracy: 0.7924 - val_loss: 0.8058 - val_binary_accuracy: 0.7969\n",
      "Epoch 150/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7781 - binary_accuracy: 0.7975 - val_loss: 0.8057 - val_binary_accuracy: 0.7970\n",
      "Epoch 151/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7480 - binary_accuracy: 0.8211 - val_loss: 0.8056 - val_binary_accuracy: 0.7970\n",
      "Epoch 152/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7843 - binary_accuracy: 0.7934 - val_loss: 0.8055 - val_binary_accuracy: 0.7969\n",
      "Epoch 153/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7731 - binary_accuracy: 0.8011 - val_loss: 0.8054 - val_binary_accuracy: 0.7969\n",
      "Epoch 154/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7773 - binary_accuracy: 0.7975 - val_loss: 0.8053 - val_binary_accuracy: 0.7970\n",
      "Epoch 155/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7597 - binary_accuracy: 0.8110 - val_loss: 0.8052 - val_binary_accuracy: 0.7969\n",
      "Epoch 156/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7711 - binary_accuracy: 0.8036 - val_loss: 0.8051 - val_binary_accuracy: 0.7968\n",
      "Epoch 157/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7757 - binary_accuracy: 0.7987 - val_loss: 0.8051 - val_binary_accuracy: 0.7969\n",
      "Epoch 158/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7703 - binary_accuracy: 0.8040 - val_loss: 0.8050 - val_binary_accuracy: 0.7969\n",
      "Epoch 159/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7668 - binary_accuracy: 0.8051 - val_loss: 0.8049 - val_binary_accuracy: 0.7969\n",
      "Epoch 160/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7784 - binary_accuracy: 0.7960 - val_loss: 0.8048 - val_binary_accuracy: 0.7968\n",
      "Epoch 161/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7591 - binary_accuracy: 0.8120 - val_loss: 0.8047 - val_binary_accuracy: 0.7969\n",
      "Epoch 162/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7753 - binary_accuracy: 0.7982 - val_loss: 0.8046 - val_binary_accuracy: 0.7969\n",
      "Epoch 163/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7774 - binary_accuracy: 0.7951 - val_loss: 0.8046 - val_binary_accuracy: 0.7969\n",
      "Epoch 164/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7767 - binary_accuracy: 0.7972 - val_loss: 0.8045 - val_binary_accuracy: 0.7968\n",
      "Epoch 165/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7709 - binary_accuracy: 0.8027 - val_loss: 0.8044 - val_binary_accuracy: 0.7969\n",
      "Epoch 166/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7648 - binary_accuracy: 0.8070 - val_loss: 0.8043 - val_binary_accuracy: 0.7968\n",
      "Epoch 167/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7878 - binary_accuracy: 0.7890 - val_loss: 0.8042 - val_binary_accuracy: 0.7967\n",
      "Epoch 168/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7729 - binary_accuracy: 0.8003 - val_loss: 0.8041 - val_binary_accuracy: 0.7969\n",
      "Epoch 169/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7749 - binary_accuracy: 0.7992 - val_loss: 0.8041 - val_binary_accuracy: 0.7969\n",
      "Epoch 170/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7788 - binary_accuracy: 0.7949 - val_loss: 0.8040 - val_binary_accuracy: 0.7969\n",
      "Epoch 171/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7758 - binary_accuracy: 0.7997 - val_loss: 0.8039 - val_binary_accuracy: 0.7968\n",
      "Epoch 172/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7543 - binary_accuracy: 0.8142 - val_loss: 0.8038 - val_binary_accuracy: 0.7969\n",
      "Epoch 173/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7737 - binary_accuracy: 0.7990 - val_loss: 0.8038 - val_binary_accuracy: 0.7968\n",
      "Epoch 174/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7851 - binary_accuracy: 0.7909 - val_loss: 0.8037 - val_binary_accuracy: 0.7969\n",
      "Epoch 175/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7678 - binary_accuracy: 0.8040 - val_loss: 0.8037 - val_binary_accuracy: 0.7969\n",
      "Epoch 176/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7789 - binary_accuracy: 0.7950 - val_loss: 0.8036 - val_binary_accuracy: 0.7969\n",
      "Epoch 177/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7660 - binary_accuracy: 0.8039 - val_loss: 0.8035 - val_binary_accuracy: 0.7969\n",
      "Epoch 178/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7706 - binary_accuracy: 0.8011 - val_loss: 0.8034 - val_binary_accuracy: 0.7969\n",
      "Epoch 179/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7647 - binary_accuracy: 0.8059 - val_loss: 0.8034 - val_binary_accuracy: 0.7968\n",
      "Epoch 180/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7858 - binary_accuracy: 0.7896 - val_loss: 0.8033 - val_binary_accuracy: 0.7968\n",
      "Epoch 181/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7864 - binary_accuracy: 0.7885 - val_loss: 0.8032 - val_binary_accuracy: 0.7968\n",
      "Epoch 182/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7818 - binary_accuracy: 0.7924 - val_loss: 0.8032 - val_binary_accuracy: 0.7968\n",
      "Epoch 183/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7626 - binary_accuracy: 0.8068 - val_loss: 0.8031 - val_binary_accuracy: 0.7968\n",
      "Epoch 184/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7325 - binary_accuracy: 0.8302 - val_loss: 0.8030 - val_binary_accuracy: 0.7968\n",
      "Epoch 185/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7616 - binary_accuracy: 0.8077 - val_loss: 0.8029 - val_binary_accuracy: 0.7968\n",
      "Epoch 186/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7721 - binary_accuracy: 0.7995 - val_loss: 0.8029 - val_binary_accuracy: 0.7968\n",
      "Epoch 187/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7680 - binary_accuracy: 0.8021 - val_loss: 0.8028 - val_binary_accuracy: 0.7968\n",
      "Epoch 188/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7483 - binary_accuracy: 0.8176 - val_loss: 0.8027 - val_binary_accuracy: 0.7968\n",
      "Epoch 189/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7894 - binary_accuracy: 0.7861 - val_loss: 0.8027 - val_binary_accuracy: 0.7968\n",
      "Epoch 190/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7799 - binary_accuracy: 0.7918 - val_loss: 0.8026 - val_binary_accuracy: 0.7968\n",
      "Epoch 191/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7826 - binary_accuracy: 0.7902 - val_loss: 0.8025 - val_binary_accuracy: 0.7968\n",
      "Epoch 192/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7902 - binary_accuracy: 0.7850 - val_loss: 0.8025 - val_binary_accuracy: 0.7968\n",
      "Epoch 193/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7671 - binary_accuracy: 0.8023 - val_loss: 0.8024 - val_binary_accuracy: 0.7968\n",
      "Epoch 194/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7694 - binary_accuracy: 0.8002 - val_loss: 0.8024 - val_binary_accuracy: 0.7968\n",
      "Epoch 195/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7727 - binary_accuracy: 0.7985 - val_loss: 0.8023 - val_binary_accuracy: 0.7967\n",
      "Epoch 196/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7457 - binary_accuracy: 0.8195 - val_loss: 0.8022 - val_binary_accuracy: 0.7967\n",
      "Epoch 197/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7676 - binary_accuracy: 0.8011 - val_loss: 0.8021 - val_binary_accuracy: 0.7967\n",
      "Epoch 198/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7962 - binary_accuracy: 0.7801 - val_loss: 0.8021 - val_binary_accuracy: 0.7968\n",
      "Epoch 199/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7751 - binary_accuracy: 0.7955 - val_loss: 0.8020 - val_binary_accuracy: 0.7968\n",
      "Epoch 200/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7604 - binary_accuracy: 0.8064 - val_loss: 0.8019 - val_binary_accuracy: 0.7967\n",
      "Epoch 201/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7774 - binary_accuracy: 0.7949 - val_loss: 0.8019 - val_binary_accuracy: 0.7968\n",
      "Epoch 202/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7666 - binary_accuracy: 0.8028 - val_loss: 0.8018 - val_binary_accuracy: 0.7968\n",
      "Epoch 203/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7548 - binary_accuracy: 0.8112 - val_loss: 0.8018 - val_binary_accuracy: 0.7967\n",
      "Epoch 204/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7520 - binary_accuracy: 0.8127 - val_loss: 0.8017 - val_binary_accuracy: 0.7969\n",
      "Epoch 205/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7857 - binary_accuracy: 0.7880 - val_loss: 0.8017 - val_binary_accuracy: 0.7967\n",
      "Epoch 206/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7675 - binary_accuracy: 0.8003 - val_loss: 0.8016 - val_binary_accuracy: 0.7968\n",
      "Epoch 207/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7828 - binary_accuracy: 0.7883 - val_loss: 0.8015 - val_binary_accuracy: 0.7968\n",
      "Epoch 208/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8117 - binary_accuracy: 0.7678 - val_loss: 0.8015 - val_binary_accuracy: 0.7968\n",
      "Epoch 209/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7657 - binary_accuracy: 0.8023 - val_loss: 0.8014 - val_binary_accuracy: 0.7968\n",
      "Epoch 210/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7865 - binary_accuracy: 0.7862 - val_loss: 0.8014 - val_binary_accuracy: 0.7968\n",
      "Epoch 211/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7602 - binary_accuracy: 0.8071 - val_loss: 0.8013 - val_binary_accuracy: 0.7968\n",
      "Epoch 212/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7743 - binary_accuracy: 0.7955 - val_loss: 0.8013 - val_binary_accuracy: 0.7967\n",
      "Epoch 213/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7562 - binary_accuracy: 0.8102 - val_loss: 0.8012 - val_binary_accuracy: 0.7968\n",
      "Epoch 214/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7797 - binary_accuracy: 0.7925 - val_loss: 0.8011 - val_binary_accuracy: 0.7968\n",
      "Epoch 215/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7539 - binary_accuracy: 0.8106 - val_loss: 0.8011 - val_binary_accuracy: 0.7968\n",
      "Epoch 216/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7894 - binary_accuracy: 0.7849 - val_loss: 0.8010 - val_binary_accuracy: 0.7967\n",
      "Epoch 217/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7662 - binary_accuracy: 0.8019 - val_loss: 0.8009 - val_binary_accuracy: 0.7968\n",
      "Epoch 218/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7707 - binary_accuracy: 0.7987 - val_loss: 0.8009 - val_binary_accuracy: 0.7968\n",
      "Epoch 219/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7537 - binary_accuracy: 0.8114 - val_loss: 0.8008 - val_binary_accuracy: 0.7968\n",
      "Epoch 220/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7565 - binary_accuracy: 0.8088 - val_loss: 0.8008 - val_binary_accuracy: 0.7968\n",
      "Epoch 221/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7894 - binary_accuracy: 0.7839 - val_loss: 0.8007 - val_binary_accuracy: 0.7968\n",
      "Epoch 222/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7743 - binary_accuracy: 0.7958 - val_loss: 0.8007 - val_binary_accuracy: 0.7967\n",
      "Epoch 223/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7661 - binary_accuracy: 0.8032 - val_loss: 0.8006 - val_binary_accuracy: 0.7967\n",
      "Epoch 224/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7575 - binary_accuracy: 0.8091 - val_loss: 0.8006 - val_binary_accuracy: 0.7967\n",
      "Epoch 225/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7780 - binary_accuracy: 0.7923 - val_loss: 0.8005 - val_binary_accuracy: 0.7967\n",
      "Epoch 226/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7602 - binary_accuracy: 0.8060 - val_loss: 0.8005 - val_binary_accuracy: 0.7968\n",
      "Epoch 227/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7804 - binary_accuracy: 0.7899 - val_loss: 0.8004 - val_binary_accuracy: 0.7967\n",
      "Epoch 228/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7547 - binary_accuracy: 0.8102 - val_loss: 0.8003 - val_binary_accuracy: 0.7967\n",
      "Epoch 229/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7797 - binary_accuracy: 0.7913 - val_loss: 0.8003 - val_binary_accuracy: 0.7968\n",
      "Epoch 230/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7534 - binary_accuracy: 0.8115 - val_loss: 0.8003 - val_binary_accuracy: 0.7967\n",
      "Epoch 231/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7823 - binary_accuracy: 0.7886 - val_loss: 0.8002 - val_binary_accuracy: 0.7967\n",
      "Epoch 232/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7738 - binary_accuracy: 0.7952 - val_loss: 0.8001 - val_binary_accuracy: 0.7967\n",
      "Epoch 233/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7748 - binary_accuracy: 0.7943 - val_loss: 0.8001 - val_binary_accuracy: 0.7967\n",
      "Epoch 234/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7730 - binary_accuracy: 0.7963 - val_loss: 0.8000 - val_binary_accuracy: 0.7966\n",
      "Epoch 235/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7475 - binary_accuracy: 0.8164 - val_loss: 0.8000 - val_binary_accuracy: 0.7967\n",
      "Epoch 236/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7523 - binary_accuracy: 0.8108 - val_loss: 0.7999 - val_binary_accuracy: 0.7966\n",
      "Epoch 237/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7538 - binary_accuracy: 0.8102 - val_loss: 0.7999 - val_binary_accuracy: 0.7967\n",
      "Epoch 238/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7825 - binary_accuracy: 0.7885 - val_loss: 0.7999 - val_binary_accuracy: 0.7967\n",
      "Epoch 239/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7598 - binary_accuracy: 0.8052 - val_loss: 0.7998 - val_binary_accuracy: 0.7967\n",
      "Epoch 240/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7654 - binary_accuracy: 0.8010 - val_loss: 0.7997 - val_binary_accuracy: 0.7966\n",
      "Epoch 241/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7838 - binary_accuracy: 0.7877 - val_loss: 0.7997 - val_binary_accuracy: 0.7966\n",
      "Epoch 242/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7520 - binary_accuracy: 0.8113 - val_loss: 0.7996 - val_binary_accuracy: 0.7967\n",
      "Epoch 243/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7841 - binary_accuracy: 0.7889 - val_loss: 0.7996 - val_binary_accuracy: 0.7967\n",
      "Epoch 244/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7586 - binary_accuracy: 0.8058 - val_loss: 0.7995 - val_binary_accuracy: 0.7967\n",
      "Epoch 245/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7799 - binary_accuracy: 0.7888 - val_loss: 0.7995 - val_binary_accuracy: 0.7967\n",
      "Epoch 246/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7841 - binary_accuracy: 0.7853 - val_loss: 0.7995 - val_binary_accuracy: 0.7967\n",
      "Epoch 247/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7826 - binary_accuracy: 0.7868 - val_loss: 0.7994 - val_binary_accuracy: 0.7967\n",
      "Epoch 248/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7746 - binary_accuracy: 0.7937 - val_loss: 0.7993 - val_binary_accuracy: 0.7967\n",
      "Epoch 249/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7794 - binary_accuracy: 0.7902 - val_loss: 0.7993 - val_binary_accuracy: 0.7967\n",
      "Epoch 250/1000\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.7614 - binary_accuracy: 0.8027 - val_loss: 0.7992 - val_binary_accuracy: 0.7967\n",
      "Epoch 251/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7602 - binary_accuracy: 0.8046 - val_loss: 0.7992 - val_binary_accuracy: 0.7967\n",
      "Epoch 252/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7667 - binary_accuracy: 0.7988 - val_loss: 0.7992 - val_binary_accuracy: 0.7967\n",
      "Epoch 253/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8023 - binary_accuracy: 0.7707 - val_loss: 0.7991 - val_binary_accuracy: 0.7967\n",
      "Epoch 254/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7715 - binary_accuracy: 0.7950 - val_loss: 0.7991 - val_binary_accuracy: 0.7967\n",
      "Epoch 255/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7751 - binary_accuracy: 0.7925 - val_loss: 0.7990 - val_binary_accuracy: 0.7967\n",
      "Epoch 256/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7602 - binary_accuracy: 0.8054 - val_loss: 0.7990 - val_binary_accuracy: 0.7967\n",
      "Epoch 257/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7642 - binary_accuracy: 0.8018 - val_loss: 0.7989 - val_binary_accuracy: 0.7967\n",
      "Epoch 258/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7620 - binary_accuracy: 0.8028 - val_loss: 0.7989 - val_binary_accuracy: 0.7967\n",
      "Epoch 259/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7773 - binary_accuracy: 0.7908 - val_loss: 0.7988 - val_binary_accuracy: 0.7967\n",
      "Epoch 260/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7757 - binary_accuracy: 0.7913 - val_loss: 0.7988 - val_binary_accuracy: 0.7967\n",
      "Epoch 261/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7877 - binary_accuracy: 0.7822 - val_loss: 0.7988 - val_binary_accuracy: 0.7967\n",
      "Epoch 262/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7361 - binary_accuracy: 0.8226 - val_loss: 0.7987 - val_binary_accuracy: 0.7967\n",
      "Epoch 263/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7812 - binary_accuracy: 0.7880 - val_loss: 0.7986 - val_binary_accuracy: 0.7967\n",
      "Epoch 264/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7794 - binary_accuracy: 0.7881 - val_loss: 0.7986 - val_binary_accuracy: 0.7967\n",
      "Epoch 265/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7517 - binary_accuracy: 0.8115 - val_loss: 0.7985 - val_binary_accuracy: 0.7967\n",
      "Epoch 266/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7749 - binary_accuracy: 0.7927 - val_loss: 0.7985 - val_binary_accuracy: 0.7966\n",
      "Epoch 267/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7663 - binary_accuracy: 0.7991 - val_loss: 0.7985 - val_binary_accuracy: 0.7967\n",
      "Epoch 268/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7814 - binary_accuracy: 0.7862 - val_loss: 0.7984 - val_binary_accuracy: 0.7967\n",
      "Epoch 269/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7615 - binary_accuracy: 0.8029 - val_loss: 0.7984 - val_binary_accuracy: 0.7967\n",
      "Epoch 270/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7740 - binary_accuracy: 0.7934 - val_loss: 0.7983 - val_binary_accuracy: 0.7967\n",
      "Epoch 271/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7589 - binary_accuracy: 0.8044 - val_loss: 0.7983 - val_binary_accuracy: 0.7967\n",
      "Epoch 272/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7327 - binary_accuracy: 0.8258 - val_loss: 0.7982 - val_binary_accuracy: 0.7967\n",
      "Epoch 273/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7658 - binary_accuracy: 0.7985 - val_loss: 0.7982 - val_binary_accuracy: 0.7967\n",
      "Epoch 274/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7777 - binary_accuracy: 0.7898 - val_loss: 0.7981 - val_binary_accuracy: 0.7967\n",
      "Epoch 275/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7546 - binary_accuracy: 0.8071 - val_loss: 0.7981 - val_binary_accuracy: 0.7967\n",
      "Epoch 276/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7640 - binary_accuracy: 0.8011 - val_loss: 0.7981 - val_binary_accuracy: 0.7967\n",
      "Epoch 277/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7807 - binary_accuracy: 0.7876 - val_loss: 0.7980 - val_binary_accuracy: 0.7967\n",
      "Epoch 278/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7658 - binary_accuracy: 0.7975 - val_loss: 0.7980 - val_binary_accuracy: 0.7966\n",
      "Epoch 279/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7699 - binary_accuracy: 0.7972 - val_loss: 0.7979 - val_binary_accuracy: 0.7966\n",
      "Epoch 280/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7683 - binary_accuracy: 0.7968 - val_loss: 0.7979 - val_binary_accuracy: 0.7965\n",
      "Epoch 281/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7678 - binary_accuracy: 0.7979 - val_loss: 0.7979 - val_binary_accuracy: 0.7966\n",
      "Epoch 282/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7859 - binary_accuracy: 0.7833 - val_loss: 0.7978 - val_binary_accuracy: 0.7965\n",
      "Epoch 283/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7736 - binary_accuracy: 0.7927 - val_loss: 0.7978 - val_binary_accuracy: 0.7965\n",
      "Epoch 284/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7735 - binary_accuracy: 0.7927 - val_loss: 0.7977 - val_binary_accuracy: 0.7966\n",
      "Epoch 285/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7557 - binary_accuracy: 0.8073 - val_loss: 0.7977 - val_binary_accuracy: 0.7966\n",
      "Epoch 286/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7734 - binary_accuracy: 0.7926 - val_loss: 0.7977 - val_binary_accuracy: 0.7966\n",
      "Epoch 287/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7656 - binary_accuracy: 0.7990 - val_loss: 0.7976 - val_binary_accuracy: 0.7965\n",
      "Epoch 288/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7878 - binary_accuracy: 0.7819 - val_loss: 0.7976 - val_binary_accuracy: 0.7966\n",
      "Epoch 289/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7529 - binary_accuracy: 0.8079 - val_loss: 0.7975 - val_binary_accuracy: 0.7966\n",
      "Epoch 290/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7699 - binary_accuracy: 0.7960 - val_loss: 0.7975 - val_binary_accuracy: 0.7966\n",
      "Epoch 291/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7831 - binary_accuracy: 0.7850 - val_loss: 0.7975 - val_binary_accuracy: 0.7965\n",
      "Epoch 292/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7561 - binary_accuracy: 0.8051 - val_loss: 0.7974 - val_binary_accuracy: 0.7966\n",
      "Epoch 293/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7732 - binary_accuracy: 0.7924 - val_loss: 0.7974 - val_binary_accuracy: 0.7966\n",
      "Epoch 294/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7617 - binary_accuracy: 0.8021 - val_loss: 0.7973 - val_binary_accuracy: 0.7965\n",
      "Epoch 295/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7401 - binary_accuracy: 0.8183 - val_loss: 0.7973 - val_binary_accuracy: 0.7966\n",
      "Epoch 296/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7749 - binary_accuracy: 0.7905 - val_loss: 0.7973 - val_binary_accuracy: 0.7967\n",
      "Epoch 297/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7968 - binary_accuracy: 0.7745 - val_loss: 0.7972 - val_binary_accuracy: 0.7965\n",
      "Epoch 298/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7767 - binary_accuracy: 0.7894 - val_loss: 0.7972 - val_binary_accuracy: 0.7966\n",
      "Epoch 299/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7514 - binary_accuracy: 0.8096 - val_loss: 0.7971 - val_binary_accuracy: 0.7966\n",
      "Epoch 300/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7814 - binary_accuracy: 0.7863 - val_loss: 0.7971 - val_binary_accuracy: 0.7966\n",
      "Epoch 301/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7633 - binary_accuracy: 0.7998 - val_loss: 0.7971 - val_binary_accuracy: 0.7966\n",
      "Epoch 302/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7729 - binary_accuracy: 0.7930 - val_loss: 0.7971 - val_binary_accuracy: 0.7965\n",
      "Epoch 303/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7655 - binary_accuracy: 0.7984 - val_loss: 0.7970 - val_binary_accuracy: 0.7965\n",
      "Epoch 304/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7399 - binary_accuracy: 0.8180 - val_loss: 0.7970 - val_binary_accuracy: 0.7966\n",
      "Epoch 305/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7595 - binary_accuracy: 0.8022 - val_loss: 0.7970 - val_binary_accuracy: 0.7966\n",
      "Epoch 306/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7526 - binary_accuracy: 0.8078 - val_loss: 0.7969 - val_binary_accuracy: 0.7966\n",
      "Epoch 307/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7931 - binary_accuracy: 0.7771 - val_loss: 0.7969 - val_binary_accuracy: 0.7966\n",
      "Epoch 308/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7644 - binary_accuracy: 0.7986 - val_loss: 0.7968 - val_binary_accuracy: 0.7966\n",
      "Epoch 309/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7608 - binary_accuracy: 0.8014 - val_loss: 0.7968 - val_binary_accuracy: 0.7966\n",
      "Epoch 310/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7618 - binary_accuracy: 0.7999 - val_loss: 0.7967 - val_binary_accuracy: 0.7966\n",
      "Epoch 311/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7496 - binary_accuracy: 0.8101 - val_loss: 0.7967 - val_binary_accuracy: 0.7966\n",
      "Epoch 312/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7666 - binary_accuracy: 0.7969 - val_loss: 0.7967 - val_binary_accuracy: 0.7966\n",
      "Epoch 313/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7630 - binary_accuracy: 0.8001 - val_loss: 0.7966 - val_binary_accuracy: 0.7967\n",
      "Epoch 314/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7600 - binary_accuracy: 0.8014 - val_loss: 0.7966 - val_binary_accuracy: 0.7966\n",
      "Epoch 315/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7868 - binary_accuracy: 0.7828 - val_loss: 0.7966 - val_binary_accuracy: 0.7965\n",
      "Epoch 316/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7753 - binary_accuracy: 0.7893 - val_loss: 0.7965 - val_binary_accuracy: 0.7966\n",
      "Epoch 317/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7643 - binary_accuracy: 0.7983 - val_loss: 0.7965 - val_binary_accuracy: 0.7966\n",
      "Epoch 318/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7494 - binary_accuracy: 0.8103 - val_loss: 0.7964 - val_binary_accuracy: 0.7966\n",
      "Epoch 319/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7540 - binary_accuracy: 0.8063 - val_loss: 0.7964 - val_binary_accuracy: 0.7966\n",
      "Epoch 320/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7572 - binary_accuracy: 0.8040 - val_loss: 0.7964 - val_binary_accuracy: 0.7966\n",
      "Epoch 321/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7753 - binary_accuracy: 0.7897 - val_loss: 0.7964 - val_binary_accuracy: 0.7966\n",
      "Epoch 322/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7620 - binary_accuracy: 0.7998 - val_loss: 0.7963 - val_binary_accuracy: 0.7965\n",
      "Epoch 323/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7555 - binary_accuracy: 0.8048 - val_loss: 0.7963 - val_binary_accuracy: 0.7966\n",
      "Epoch 324/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7623 - binary_accuracy: 0.7991 - val_loss: 0.7963 - val_binary_accuracy: 0.7965\n",
      "Epoch 325/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7362 - binary_accuracy: 0.8203 - val_loss: 0.7962 - val_binary_accuracy: 0.7964\n",
      "Epoch 326/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7792 - binary_accuracy: 0.7871 - val_loss: 0.7962 - val_binary_accuracy: 0.7963\n",
      "Epoch 327/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7331 - binary_accuracy: 0.8224 - val_loss: 0.7962 - val_binary_accuracy: 0.7963\n",
      "Epoch 328/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7624 - binary_accuracy: 0.7994 - val_loss: 0.7961 - val_binary_accuracy: 0.7965\n",
      "Epoch 329/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7622 - binary_accuracy: 0.7989 - val_loss: 0.7961 - val_binary_accuracy: 0.7964\n",
      "Epoch 330/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7674 - binary_accuracy: 0.7950 - val_loss: 0.7961 - val_binary_accuracy: 0.7963\n",
      "Epoch 331/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7559 - binary_accuracy: 0.8049 - val_loss: 0.7960 - val_binary_accuracy: 0.7963\n",
      "Epoch 332/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7794 - binary_accuracy: 0.7861 - val_loss: 0.7960 - val_binary_accuracy: 0.7964\n",
      "Epoch 333/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7681 - binary_accuracy: 0.7954 - val_loss: 0.7960 - val_binary_accuracy: 0.7964\n",
      "Epoch 334/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7813 - binary_accuracy: 0.7844 - val_loss: 0.7959 - val_binary_accuracy: 0.7964\n",
      "Epoch 335/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7640 - binary_accuracy: 0.7978 - val_loss: 0.7959 - val_binary_accuracy: 0.7963\n",
      "Epoch 336/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7763 - binary_accuracy: 0.7889 - val_loss: 0.7958 - val_binary_accuracy: 0.7964\n",
      "Epoch 337/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7919 - binary_accuracy: 0.7753 - val_loss: 0.7958 - val_binary_accuracy: 0.7964\n",
      "Epoch 338/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7931 - binary_accuracy: 0.7754 - val_loss: 0.7958 - val_binary_accuracy: 0.7964\n",
      "Epoch 339/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7651 - binary_accuracy: 0.7969 - val_loss: 0.7957 - val_binary_accuracy: 0.7964\n",
      "Epoch 340/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7247 - binary_accuracy: 0.8276 - val_loss: 0.7957 - val_binary_accuracy: 0.7964\n",
      "Epoch 341/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7760 - binary_accuracy: 0.7884 - val_loss: 0.7957 - val_binary_accuracy: 0.7964\n",
      "Epoch 342/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7724 - binary_accuracy: 0.7906 - val_loss: 0.7956 - val_binary_accuracy: 0.7964\n",
      "Epoch 343/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7548 - binary_accuracy: 0.8043 - val_loss: 0.7956 - val_binary_accuracy: 0.7964\n",
      "Epoch 344/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7229 - binary_accuracy: 0.8288 - val_loss: 0.7956 - val_binary_accuracy: 0.7964\n",
      "Epoch 345/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7513 - binary_accuracy: 0.8072 - val_loss: 0.7955 - val_binary_accuracy: 0.7964\n",
      "Epoch 346/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7455 - binary_accuracy: 0.8118 - val_loss: 0.7955 - val_binary_accuracy: 0.7964\n",
      "Epoch 347/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7666 - binary_accuracy: 0.7950 - val_loss: 0.7955 - val_binary_accuracy: 0.7964\n",
      "Epoch 348/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7580 - binary_accuracy: 0.8025 - val_loss: 0.7954 - val_binary_accuracy: 0.7964\n",
      "Epoch 349/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7502 - binary_accuracy: 0.8093 - val_loss: 0.7954 - val_binary_accuracy: 0.7964\n",
      "Epoch 350/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7629 - binary_accuracy: 0.7977 - val_loss: 0.7954 - val_binary_accuracy: 0.7964\n",
      "Epoch 351/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7738 - binary_accuracy: 0.7881 - val_loss: 0.7954 - val_binary_accuracy: 0.7963\n",
      "Epoch 352/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7693 - binary_accuracy: 0.7931 - val_loss: 0.7953 - val_binary_accuracy: 0.7964\n",
      "Epoch 353/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7702 - binary_accuracy: 0.7927 - val_loss: 0.7953 - val_binary_accuracy: 0.7964\n",
      "Epoch 354/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7598 - binary_accuracy: 0.8011 - val_loss: 0.7953 - val_binary_accuracy: 0.7964\n",
      "Epoch 355/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7653 - binary_accuracy: 0.7957 - val_loss: 0.7952 - val_binary_accuracy: 0.7964\n",
      "Epoch 356/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7506 - binary_accuracy: 0.8076 - val_loss: 0.7952 - val_binary_accuracy: 0.7965\n",
      "Epoch 357/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7566 - binary_accuracy: 0.8027 - val_loss: 0.7952 - val_binary_accuracy: 0.7964\n",
      "Epoch 358/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7607 - binary_accuracy: 0.8009 - val_loss: 0.7951 - val_binary_accuracy: 0.7965\n",
      "Epoch 359/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7755 - binary_accuracy: 0.7890 - val_loss: 0.7951 - val_binary_accuracy: 0.7965\n",
      "Epoch 360/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7505 - binary_accuracy: 0.8078 - val_loss: 0.7951 - val_binary_accuracy: 0.7964\n",
      "Epoch 361/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7488 - binary_accuracy: 0.8091 - val_loss: 0.7950 - val_binary_accuracy: 0.7964\n",
      "Epoch 362/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7602 - binary_accuracy: 0.8005 - val_loss: 0.7950 - val_binary_accuracy: 0.7965\n",
      "Epoch 363/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7666 - binary_accuracy: 0.7954 - val_loss: 0.7950 - val_binary_accuracy: 0.7964\n",
      "Epoch 364/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7646 - binary_accuracy: 0.7971 - val_loss: 0.7949 - val_binary_accuracy: 0.7964\n",
      "Epoch 365/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7477 - binary_accuracy: 0.8095 - val_loss: 0.7949 - val_binary_accuracy: 0.7965\n",
      "Epoch 366/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7629 - binary_accuracy: 0.7974 - val_loss: 0.7949 - val_binary_accuracy: 0.7965\n",
      "Epoch 367/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7560 - binary_accuracy: 0.8033 - val_loss: 0.7949 - val_binary_accuracy: 0.7964\n",
      "Epoch 368/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7651 - binary_accuracy: 0.7954 - val_loss: 0.7948 - val_binary_accuracy: 0.7963\n",
      "Epoch 369/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7664 - binary_accuracy: 0.7944 - val_loss: 0.7948 - val_binary_accuracy: 0.7964\n",
      "Epoch 370/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7536 - binary_accuracy: 0.8042 - val_loss: 0.7948 - val_binary_accuracy: 0.7964\n",
      "Epoch 371/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7452 - binary_accuracy: 0.8102 - val_loss: 0.7947 - val_binary_accuracy: 0.7964\n",
      "Epoch 372/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7456 - binary_accuracy: 0.8100 - val_loss: 0.7947 - val_binary_accuracy: 0.7964\n",
      "Epoch 373/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7584 - binary_accuracy: 0.8015 - val_loss: 0.7947 - val_binary_accuracy: 0.7965\n",
      "Epoch 374/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7647 - binary_accuracy: 0.7965 - val_loss: 0.7947 - val_binary_accuracy: 0.7964\n",
      "Epoch 375/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7898 - binary_accuracy: 0.7779 - val_loss: 0.7946 - val_binary_accuracy: 0.7964\n",
      "Epoch 376/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7685 - binary_accuracy: 0.7929 - val_loss: 0.7946 - val_binary_accuracy: 0.7964\n",
      "Epoch 377/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7590 - binary_accuracy: 0.8007 - val_loss: 0.7946 - val_binary_accuracy: 0.7964\n",
      "Epoch 378/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7560 - binary_accuracy: 0.8029 - val_loss: 0.7945 - val_binary_accuracy: 0.7964\n",
      "Epoch 379/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7568 - binary_accuracy: 0.8020 - val_loss: 0.7945 - val_binary_accuracy: 0.7964\n",
      "Epoch 380/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7449 - binary_accuracy: 0.8110 - val_loss: 0.7944 - val_binary_accuracy: 0.7963\n",
      "Epoch 381/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7579 - binary_accuracy: 0.8015 - val_loss: 0.7944 - val_binary_accuracy: 0.7963\n",
      "Epoch 382/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7581 - binary_accuracy: 0.8002 - val_loss: 0.7944 - val_binary_accuracy: 0.7963\n",
      "Epoch 383/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7738 - binary_accuracy: 0.7888 - val_loss: 0.7944 - val_binary_accuracy: 0.7964\n",
      "Epoch 384/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7718 - binary_accuracy: 0.7901 - val_loss: 0.7943 - val_binary_accuracy: 0.7964\n",
      "Epoch 385/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7673 - binary_accuracy: 0.7941 - val_loss: 0.7943 - val_binary_accuracy: 0.7963\n",
      "Epoch 386/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7534 - binary_accuracy: 0.8048 - val_loss: 0.7943 - val_binary_accuracy: 0.7964\n",
      "Epoch 387/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7486 - binary_accuracy: 0.8074 - val_loss: 0.7943 - val_binary_accuracy: 0.7964\n",
      "Epoch 388/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7485 - binary_accuracy: 0.8081 - val_loss: 0.7942 - val_binary_accuracy: 0.7965\n",
      "Epoch 389/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7415 - binary_accuracy: 0.8141 - val_loss: 0.7942 - val_binary_accuracy: 0.7964\n",
      "Epoch 390/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7475 - binary_accuracy: 0.8091 - val_loss: 0.7942 - val_binary_accuracy: 0.7965\n",
      "Epoch 391/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7892 - binary_accuracy: 0.7766 - val_loss: 0.7942 - val_binary_accuracy: 0.7963\n",
      "Epoch 392/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7671 - binary_accuracy: 0.7944 - val_loss: 0.7941 - val_binary_accuracy: 0.7963\n",
      "Epoch 393/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7538 - binary_accuracy: 0.8043 - val_loss: 0.7941 - val_binary_accuracy: 0.7964\n",
      "Epoch 394/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7677 - binary_accuracy: 0.7921 - val_loss: 0.7941 - val_binary_accuracy: 0.7963\n",
      "Epoch 395/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7592 - binary_accuracy: 0.7994 - val_loss: 0.7940 - val_binary_accuracy: 0.7963\n",
      "Epoch 396/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7415 - binary_accuracy: 0.8136 - val_loss: 0.7940 - val_binary_accuracy: 0.7964\n",
      "Epoch 397/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7562 - binary_accuracy: 0.8011 - val_loss: 0.7940 - val_binary_accuracy: 0.7963\n",
      "Epoch 398/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7888 - binary_accuracy: 0.7760 - val_loss: 0.7940 - val_binary_accuracy: 0.7963\n",
      "Epoch 399/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7860 - binary_accuracy: 0.7790 - val_loss: 0.7940 - val_binary_accuracy: 0.7963\n",
      "Epoch 400/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7461 - binary_accuracy: 0.8093 - val_loss: 0.7939 - val_binary_accuracy: 0.7963\n",
      "Epoch 401/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7489 - binary_accuracy: 0.8067 - val_loss: 0.7939 - val_binary_accuracy: 0.7963\n",
      "Epoch 402/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7390 - binary_accuracy: 0.8162 - val_loss: 0.7939 - val_binary_accuracy: 0.7963\n",
      "Epoch 403/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7615 - binary_accuracy: 0.7974 - val_loss: 0.7938 - val_binary_accuracy: 0.7963\n",
      "Epoch 404/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7723 - binary_accuracy: 0.7892 - val_loss: 0.7938 - val_binary_accuracy: 0.7963\n",
      "Epoch 405/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7580 - binary_accuracy: 0.8006 - val_loss: 0.7938 - val_binary_accuracy: 0.7963\n",
      "Epoch 406/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7429 - binary_accuracy: 0.8119 - val_loss: 0.7937 - val_binary_accuracy: 0.7963\n",
      "Epoch 407/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7557 - binary_accuracy: 0.8011 - val_loss: 0.7937 - val_binary_accuracy: 0.7963\n",
      "Epoch 408/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7462 - binary_accuracy: 0.8095 - val_loss: 0.7937 - val_binary_accuracy: 0.7963\n",
      "Epoch 409/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7632 - binary_accuracy: 0.7963 - val_loss: 0.7936 - val_binary_accuracy: 0.7964\n",
      "Epoch 410/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7527 - binary_accuracy: 0.8029 - val_loss: 0.7936 - val_binary_accuracy: 0.7964\n",
      "Epoch 411/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7522 - binary_accuracy: 0.8030 - val_loss: 0.7936 - val_binary_accuracy: 0.7963\n",
      "Epoch 412/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7531 - binary_accuracy: 0.8026 - val_loss: 0.7936 - val_binary_accuracy: 0.7963\n",
      "Epoch 413/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7299 - binary_accuracy: 0.8215 - val_loss: 0.7936 - val_binary_accuracy: 0.7963\n",
      "Epoch 414/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7655 - binary_accuracy: 0.7944 - val_loss: 0.7936 - val_binary_accuracy: 0.7963\n",
      "Epoch 415/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7605 - binary_accuracy: 0.7979 - val_loss: 0.7935 - val_binary_accuracy: 0.7963\n",
      "Epoch 416/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7421 - binary_accuracy: 0.8115 - val_loss: 0.7935 - val_binary_accuracy: 0.7964\n",
      "Epoch 417/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7657 - binary_accuracy: 0.7935 - val_loss: 0.7935 - val_binary_accuracy: 0.7963\n",
      "Epoch 418/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7606 - binary_accuracy: 0.7973 - val_loss: 0.7934 - val_binary_accuracy: 0.7963\n",
      "Epoch 419/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7519 - binary_accuracy: 0.8034 - val_loss: 0.7934 - val_binary_accuracy: 0.7963\n",
      "Epoch 420/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7642 - binary_accuracy: 0.7955 - val_loss: 0.7934 - val_binary_accuracy: 0.7964\n",
      "Epoch 421/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7457 - binary_accuracy: 0.8093 - val_loss: 0.7934 - val_binary_accuracy: 0.7964\n",
      "Epoch 422/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7552 - binary_accuracy: 0.8021 - val_loss: 0.7933 - val_binary_accuracy: 0.7964\n",
      "Epoch 423/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7810 - binary_accuracy: 0.7818 - val_loss: 0.7933 - val_binary_accuracy: 0.7963\n",
      "Epoch 424/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7625 - binary_accuracy: 0.7974 - val_loss: 0.7933 - val_binary_accuracy: 0.7964\n",
      "Epoch 425/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7611 - binary_accuracy: 0.7968 - val_loss: 0.7933 - val_binary_accuracy: 0.7963\n",
      "Epoch 426/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7676 - binary_accuracy: 0.7908 - val_loss: 0.7932 - val_binary_accuracy: 0.7963\n",
      "Epoch 427/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7749 - binary_accuracy: 0.7859 - val_loss: 0.7932 - val_binary_accuracy: 0.7963\n",
      "Epoch 428/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7697 - binary_accuracy: 0.7906 - val_loss: 0.7932 - val_binary_accuracy: 0.7964\n",
      "Epoch 429/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7891 - binary_accuracy: 0.7749 - val_loss: 0.7932 - val_binary_accuracy: 0.7963\n",
      "Epoch 430/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7585 - binary_accuracy: 0.8002 - val_loss: 0.7931 - val_binary_accuracy: 0.7963\n",
      "Epoch 431/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7662 - binary_accuracy: 0.7942 - val_loss: 0.7931 - val_binary_accuracy: 0.7963\n",
      "Epoch 432/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7697 - binary_accuracy: 0.7894 - val_loss: 0.7931 - val_binary_accuracy: 0.7963\n",
      "Epoch 433/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7794 - binary_accuracy: 0.7828 - val_loss: 0.7931 - val_binary_accuracy: 0.7963\n",
      "Epoch 434/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7530 - binary_accuracy: 0.8032 - val_loss: 0.7930 - val_binary_accuracy: 0.7963\n",
      "Epoch 435/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7630 - binary_accuracy: 0.7951 - val_loss: 0.7930 - val_binary_accuracy: 0.7963\n",
      "Epoch 436/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7651 - binary_accuracy: 0.7939 - val_loss: 0.7930 - val_binary_accuracy: 0.7963\n",
      "Epoch 437/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7524 - binary_accuracy: 0.8039 - val_loss: 0.7929 - val_binary_accuracy: 0.7963\n",
      "Epoch 438/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7463 - binary_accuracy: 0.8087 - val_loss: 0.7929 - val_binary_accuracy: 0.7963\n",
      "Epoch 439/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.7622 - binary_accuracy: 0.7957 - val_loss: 0.7929 - val_binary_accuracy: 0.7963\n",
      "Epoch 440/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7507 - binary_accuracy: 0.8051 - val_loss: 0.7929 - val_binary_accuracy: 0.7963\n",
      "Epoch 441/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7700 - binary_accuracy: 0.7895 - val_loss: 0.7929 - val_binary_accuracy: 0.7963\n",
      "Epoch 442/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7501 - binary_accuracy: 0.8049 - val_loss: 0.7928 - val_binary_accuracy: 0.7963\n",
      "Epoch 443/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7761 - binary_accuracy: 0.7855 - val_loss: 0.7928 - val_binary_accuracy: 0.7963\n",
      "Epoch 444/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7396 - binary_accuracy: 0.8139 - val_loss: 0.7928 - val_binary_accuracy: 0.7963\n",
      "Epoch 445/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7614 - binary_accuracy: 0.7961 - val_loss: 0.7928 - val_binary_accuracy: 0.7963\n",
      "Epoch 446/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7407 - binary_accuracy: 0.8115 - val_loss: 0.7927 - val_binary_accuracy: 0.7963\n",
      "Epoch 447/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7532 - binary_accuracy: 0.8031 - val_loss: 0.7927 - val_binary_accuracy: 0.7963\n",
      "Epoch 448/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7676 - binary_accuracy: 0.7925 - val_loss: 0.7927 - val_binary_accuracy: 0.7963\n",
      "Epoch 449/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7625 - binary_accuracy: 0.7956 - val_loss: 0.7927 - val_binary_accuracy: 0.7963\n",
      "Epoch 450/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7693 - binary_accuracy: 0.7907 - val_loss: 0.7926 - val_binary_accuracy: 0.7963\n",
      "Epoch 451/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7709 - binary_accuracy: 0.7892 - val_loss: 0.7926 - val_binary_accuracy: 0.7963\n",
      "Epoch 452/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7633 - binary_accuracy: 0.7939 - val_loss: 0.7926 - val_binary_accuracy: 0.7963\n",
      "Epoch 453/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7510 - binary_accuracy: 0.8053 - val_loss: 0.7926 - val_binary_accuracy: 0.7962\n",
      "Epoch 454/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7650 - binary_accuracy: 0.7938 - val_loss: 0.7926 - val_binary_accuracy: 0.7963\n",
      "Epoch 455/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7810 - binary_accuracy: 0.7814 - val_loss: 0.7925 - val_binary_accuracy: 0.7963\n",
      "Epoch 456/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7333 - binary_accuracy: 0.8180 - val_loss: 0.7925 - val_binary_accuracy: 0.7963\n",
      "Epoch 457/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7784 - binary_accuracy: 0.7830 - val_loss: 0.7925 - val_binary_accuracy: 0.7963\n",
      "Epoch 458/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7549 - binary_accuracy: 0.8013 - val_loss: 0.7925 - val_binary_accuracy: 0.7963\n",
      "Epoch 459/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7654 - binary_accuracy: 0.7927 - val_loss: 0.7925 - val_binary_accuracy: 0.7963\n",
      "Epoch 460/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7660 - binary_accuracy: 0.7920 - val_loss: 0.7924 - val_binary_accuracy: 0.7963\n",
      "Epoch 461/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7535 - binary_accuracy: 0.8015 - val_loss: 0.7924 - val_binary_accuracy: 0.7963\n",
      "Epoch 462/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7769 - binary_accuracy: 0.7834 - val_loss: 0.7924 - val_binary_accuracy: 0.7963\n",
      "Epoch 463/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7662 - binary_accuracy: 0.7922 - val_loss: 0.7924 - val_binary_accuracy: 0.7963\n",
      "Epoch 464/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7421 - binary_accuracy: 0.8105 - val_loss: 0.7923 - val_binary_accuracy: 0.7963\n",
      "Epoch 465/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7618 - binary_accuracy: 0.7945 - val_loss: 0.7923 - val_binary_accuracy: 0.7964\n",
      "Epoch 466/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7505 - binary_accuracy: 0.8044 - val_loss: 0.7923 - val_binary_accuracy: 0.7964\n",
      "Epoch 467/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7548 - binary_accuracy: 0.8013 - val_loss: 0.7923 - val_binary_accuracy: 0.7963\n",
      "Epoch 468/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7794 - binary_accuracy: 0.7817 - val_loss: 0.7923 - val_binary_accuracy: 0.7963\n",
      "Epoch 469/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7590 - binary_accuracy: 0.7973 - val_loss: 0.7922 - val_binary_accuracy: 0.7963\n",
      "Epoch 470/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7324 - binary_accuracy: 0.8184 - val_loss: 0.7922 - val_binary_accuracy: 0.7963\n",
      "Epoch 471/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7556 - binary_accuracy: 0.8008 - val_loss: 0.7922 - val_binary_accuracy: 0.7963\n",
      "Epoch 472/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7546 - binary_accuracy: 0.8009 - val_loss: 0.7922 - val_binary_accuracy: 0.7963\n",
      "Epoch 473/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7610 - binary_accuracy: 0.7956 - val_loss: 0.7922 - val_binary_accuracy: 0.7963\n",
      "Epoch 474/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7444 - binary_accuracy: 0.8088 - val_loss: 0.7921 - val_binary_accuracy: 0.7963\n",
      "Epoch 475/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7543 - binary_accuracy: 0.8013 - val_loss: 0.7921 - val_binary_accuracy: 0.7963\n",
      "Epoch 476/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7645 - binary_accuracy: 0.7929 - val_loss: 0.7921 - val_binary_accuracy: 0.7963\n",
      "Epoch 477/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7511 - binary_accuracy: 0.8048 - val_loss: 0.7921 - val_binary_accuracy: 0.7963\n",
      "Epoch 478/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7651 - binary_accuracy: 0.7926 - val_loss: 0.7921 - val_binary_accuracy: 0.7962\n",
      "Epoch 479/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7464 - binary_accuracy: 0.8072 - val_loss: 0.7920 - val_binary_accuracy: 0.7963\n",
      "Epoch 480/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7632 - binary_accuracy: 0.7943 - val_loss: 0.7920 - val_binary_accuracy: 0.7963\n",
      "Epoch 481/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7409 - binary_accuracy: 0.8130 - val_loss: 0.7920 - val_binary_accuracy: 0.7962\n",
      "Epoch 482/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7350 - binary_accuracy: 0.8157 - val_loss: 0.7920 - val_binary_accuracy: 0.7962\n",
      "Epoch 483/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7688 - binary_accuracy: 0.7904 - val_loss: 0.7919 - val_binary_accuracy: 0.7962\n",
      "Epoch 484/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7540 - binary_accuracy: 0.8009 - val_loss: 0.7919 - val_binary_accuracy: 0.7963\n",
      "Epoch 485/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7551 - binary_accuracy: 0.8002 - val_loss: 0.7919 - val_binary_accuracy: 0.7962\n",
      "Epoch 486/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7769 - binary_accuracy: 0.7825 - val_loss: 0.7919 - val_binary_accuracy: 0.7963\n",
      "Epoch 487/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7438 - binary_accuracy: 0.8092 - val_loss: 0.7918 - val_binary_accuracy: 0.7962\n",
      "Epoch 488/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7610 - binary_accuracy: 0.7952 - val_loss: 0.7918 - val_binary_accuracy: 0.7962\n",
      "Epoch 489/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7676 - binary_accuracy: 0.7894 - val_loss: 0.7918 - val_binary_accuracy: 0.7962\n",
      "Epoch 490/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7407 - binary_accuracy: 0.8108 - val_loss: 0.7918 - val_binary_accuracy: 0.7962\n",
      "Epoch 491/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7551 - binary_accuracy: 0.8007 - val_loss: 0.7918 - val_binary_accuracy: 0.7962\n",
      "Epoch 492/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7347 - binary_accuracy: 0.8154 - val_loss: 0.7917 - val_binary_accuracy: 0.7962\n",
      "Epoch 493/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7922 - binary_accuracy: 0.7720 - val_loss: 0.7917 - val_binary_accuracy: 0.7962\n",
      "Epoch 494/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7515 - binary_accuracy: 0.8035 - val_loss: 0.7917 - val_binary_accuracy: 0.7962\n",
      "Epoch 495/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7610 - binary_accuracy: 0.7965 - val_loss: 0.7917 - val_binary_accuracy: 0.7962\n",
      "Epoch 496/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7731 - binary_accuracy: 0.7857 - val_loss: 0.7917 - val_binary_accuracy: 0.7962\n",
      "Epoch 497/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7459 - binary_accuracy: 0.8064 - val_loss: 0.7917 - val_binary_accuracy: 0.7962\n",
      "Epoch 498/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7666 - binary_accuracy: 0.7911 - val_loss: 0.7916 - val_binary_accuracy: 0.7963\n",
      "Epoch 499/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7676 - binary_accuracy: 0.7917 - val_loss: 0.7916 - val_binary_accuracy: 0.7963\n",
      "Epoch 500/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7626 - binary_accuracy: 0.7931 - val_loss: 0.7916 - val_binary_accuracy: 0.7963\n",
      "Epoch 501/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7483 - binary_accuracy: 0.8041 - val_loss: 0.7916 - val_binary_accuracy: 0.7962\n",
      "Epoch 502/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7460 - binary_accuracy: 0.8074 - val_loss: 0.7915 - val_binary_accuracy: 0.7962\n",
      "Epoch 503/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7518 - binary_accuracy: 0.8021 - val_loss: 0.7915 - val_binary_accuracy: 0.7963\n",
      "Epoch 504/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7620 - binary_accuracy: 0.7947 - val_loss: 0.7915 - val_binary_accuracy: 0.7962\n",
      "Epoch 505/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7593 - binary_accuracy: 0.7972 - val_loss: 0.7915 - val_binary_accuracy: 0.7963\n",
      "Epoch 506/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7480 - binary_accuracy: 0.8049 - val_loss: 0.7915 - val_binary_accuracy: 0.7962\n",
      "Epoch 507/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7407 - binary_accuracy: 0.8119 - val_loss: 0.7915 - val_binary_accuracy: 0.7962\n",
      "Epoch 508/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7717 - binary_accuracy: 0.7872 - val_loss: 0.7914 - val_binary_accuracy: 0.7961\n",
      "Epoch 509/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7450 - binary_accuracy: 0.8070 - val_loss: 0.7914 - val_binary_accuracy: 0.7962\n",
      "Epoch 510/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7372 - binary_accuracy: 0.8130 - val_loss: 0.7914 - val_binary_accuracy: 0.7961\n",
      "Epoch 511/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7552 - binary_accuracy: 0.7998 - val_loss: 0.7914 - val_binary_accuracy: 0.7962\n",
      "Epoch 512/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7746 - binary_accuracy: 0.7842 - val_loss: 0.7913 - val_binary_accuracy: 0.7961\n",
      "Epoch 513/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7767 - binary_accuracy: 0.7831 - val_loss: 0.7913 - val_binary_accuracy: 0.7961\n",
      "Epoch 514/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7605 - binary_accuracy: 0.7953 - val_loss: 0.7913 - val_binary_accuracy: 0.7961\n",
      "Epoch 515/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7491 - binary_accuracy: 0.8042 - val_loss: 0.7913 - val_binary_accuracy: 0.7961\n",
      "Epoch 516/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7295 - binary_accuracy: 0.8189 - val_loss: 0.7913 - val_binary_accuracy: 0.7961\n",
      "Epoch 517/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7787 - binary_accuracy: 0.7816 - val_loss: 0.7913 - val_binary_accuracy: 0.7961\n",
      "Epoch 518/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7561 - binary_accuracy: 0.7999 - val_loss: 0.7912 - val_binary_accuracy: 0.7961\n",
      "Epoch 519/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7678 - binary_accuracy: 0.7895 - val_loss: 0.7912 - val_binary_accuracy: 0.7961\n",
      "Epoch 520/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7724 - binary_accuracy: 0.7864 - val_loss: 0.7912 - val_binary_accuracy: 0.7961\n",
      "Epoch 521/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7517 - binary_accuracy: 0.8021 - val_loss: 0.7912 - val_binary_accuracy: 0.7961\n",
      "Epoch 522/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7571 - binary_accuracy: 0.7979 - val_loss: 0.7911 - val_binary_accuracy: 0.7961\n",
      "Epoch 523/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7613 - binary_accuracy: 0.7941 - val_loss: 0.7911 - val_binary_accuracy: 0.7961\n",
      "Epoch 524/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7516 - binary_accuracy: 0.8026 - val_loss: 0.7911 - val_binary_accuracy: 0.7960\n",
      "Epoch 525/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7486 - binary_accuracy: 0.8056 - val_loss: 0.7911 - val_binary_accuracy: 0.7960\n",
      "Epoch 526/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7673 - binary_accuracy: 0.7902 - val_loss: 0.7911 - val_binary_accuracy: 0.7960\n",
      "Epoch 527/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7555 - binary_accuracy: 0.7993 - val_loss: 0.7911 - val_binary_accuracy: 0.7960\n",
      "Epoch 528/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7515 - binary_accuracy: 0.8030 - val_loss: 0.7910 - val_binary_accuracy: 0.7960\n",
      "Epoch 529/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7488 - binary_accuracy: 0.8044 - val_loss: 0.7910 - val_binary_accuracy: 0.7960\n",
      "Epoch 530/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7479 - binary_accuracy: 0.8041 - val_loss: 0.7910 - val_binary_accuracy: 0.7960\n",
      "Epoch 531/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7669 - binary_accuracy: 0.7902 - val_loss: 0.7910 - val_binary_accuracy: 0.7960\n",
      "Epoch 532/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7438 - binary_accuracy: 0.8091 - val_loss: 0.7910 - val_binary_accuracy: 0.7961\n",
      "Epoch 533/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7528 - binary_accuracy: 0.8008 - val_loss: 0.7909 - val_binary_accuracy: 0.7961\n",
      "Epoch 534/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7411 - binary_accuracy: 0.8099 - val_loss: 0.7909 - val_binary_accuracy: 0.7960\n",
      "Epoch 535/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7535 - binary_accuracy: 0.7998 - val_loss: 0.7909 - val_binary_accuracy: 0.7960\n",
      "Epoch 536/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7566 - binary_accuracy: 0.7987 - val_loss: 0.7909 - val_binary_accuracy: 0.7960\n",
      "Epoch 537/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7531 - binary_accuracy: 0.8006 - val_loss: 0.7909 - val_binary_accuracy: 0.7960\n",
      "Epoch 538/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7435 - binary_accuracy: 0.8077 - val_loss: 0.7909 - val_binary_accuracy: 0.7960\n",
      "Epoch 539/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7392 - binary_accuracy: 0.8130 - val_loss: 0.7908 - val_binary_accuracy: 0.7960\n",
      "Epoch 540/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7547 - binary_accuracy: 0.7986 - val_loss: 0.7908 - val_binary_accuracy: 0.7960\n",
      "Epoch 541/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7635 - binary_accuracy: 0.7917 - val_loss: 0.7908 - val_binary_accuracy: 0.7960\n",
      "Epoch 542/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7718 - binary_accuracy: 0.7854 - val_loss: 0.7908 - val_binary_accuracy: 0.7960\n",
      "Epoch 543/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7647 - binary_accuracy: 0.7907 - val_loss: 0.7908 - val_binary_accuracy: 0.7960\n",
      "Epoch 544/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7622 - binary_accuracy: 0.7953 - val_loss: 0.7907 - val_binary_accuracy: 0.7960\n",
      "Epoch 545/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7538 - binary_accuracy: 0.7998 - val_loss: 0.7907 - val_binary_accuracy: 0.7961\n",
      "Epoch 546/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7460 - binary_accuracy: 0.8061 - val_loss: 0.7907 - val_binary_accuracy: 0.7960\n",
      "Epoch 547/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7272 - binary_accuracy: 0.8203 - val_loss: 0.7907 - val_binary_accuracy: 0.7960\n",
      "Epoch 548/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7735 - binary_accuracy: 0.7844 - val_loss: 0.7907 - val_binary_accuracy: 0.7960\n",
      "Epoch 549/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7585 - binary_accuracy: 0.7955 - val_loss: 0.7906 - val_binary_accuracy: 0.7960\n",
      "Epoch 550/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7286 - binary_accuracy: 0.8199 - val_loss: 0.7906 - val_binary_accuracy: 0.7960\n",
      "Epoch 551/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7581 - binary_accuracy: 0.7967 - val_loss: 0.7906 - val_binary_accuracy: 0.7961\n",
      "Epoch 552/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7600 - binary_accuracy: 0.7954 - val_loss: 0.7906 - val_binary_accuracy: 0.7960\n",
      "Epoch 553/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7559 - binary_accuracy: 0.7983 - val_loss: 0.7906 - val_binary_accuracy: 0.7960\n",
      "Epoch 554/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7550 - binary_accuracy: 0.7983 - val_loss: 0.7906 - val_binary_accuracy: 0.7959\n",
      "Epoch 555/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7612 - binary_accuracy: 0.7938 - val_loss: 0.7905 - val_binary_accuracy: 0.7960\n",
      "Epoch 556/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7473 - binary_accuracy: 0.8056 - val_loss: 0.7905 - val_binary_accuracy: 0.7960\n",
      "Epoch 557/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7672 - binary_accuracy: 0.7895 - val_loss: 0.7905 - val_binary_accuracy: 0.7960\n",
      "Epoch 558/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7549 - binary_accuracy: 0.7990 - val_loss: 0.7905 - val_binary_accuracy: 0.7960\n",
      "Epoch 559/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7538 - binary_accuracy: 0.7990 - val_loss: 0.7905 - val_binary_accuracy: 0.7960\n",
      "Epoch 560/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7413 - binary_accuracy: 0.8089 - val_loss: 0.7905 - val_binary_accuracy: 0.7960\n",
      "Epoch 561/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7450 - binary_accuracy: 0.8058 - val_loss: 0.7905 - val_binary_accuracy: 0.7960\n",
      "Epoch 562/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7486 - binary_accuracy: 0.8041 - val_loss: 0.7904 - val_binary_accuracy: 0.7960\n",
      "Epoch 563/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7454 - binary_accuracy: 0.8060 - val_loss: 0.7904 - val_binary_accuracy: 0.7960\n",
      "Epoch 564/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7719 - binary_accuracy: 0.7864 - val_loss: 0.7904 - val_binary_accuracy: 0.7960\n",
      "Epoch 565/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7560 - binary_accuracy: 0.7974 - val_loss: 0.7904 - val_binary_accuracy: 0.7960\n",
      "Epoch 566/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7453 - binary_accuracy: 0.8066 - val_loss: 0.7904 - val_binary_accuracy: 0.7960\n",
      "Epoch 567/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7566 - binary_accuracy: 0.7982 - val_loss: 0.7904 - val_binary_accuracy: 0.7960\n",
      "Epoch 568/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7414 - binary_accuracy: 0.8097 - val_loss: 0.7903 - val_binary_accuracy: 0.7960\n",
      "Epoch 569/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7444 - binary_accuracy: 0.8060 - val_loss: 0.7903 - val_binary_accuracy: 0.7960\n",
      "Epoch 570/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7517 - binary_accuracy: 0.8016 - val_loss: 0.7903 - val_binary_accuracy: 0.7960\n",
      "Epoch 571/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7375 - binary_accuracy: 0.8122 - val_loss: 0.7903 - val_binary_accuracy: 0.7960\n",
      "Epoch 572/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7613 - binary_accuracy: 0.7938 - val_loss: 0.7903 - val_binary_accuracy: 0.7959\n",
      "Epoch 573/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7486 - binary_accuracy: 0.8020 - val_loss: 0.7902 - val_binary_accuracy: 0.7960\n",
      "Epoch 574/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7600 - binary_accuracy: 0.7943 - val_loss: 0.7902 - val_binary_accuracy: 0.7960\n",
      "Epoch 575/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7614 - binary_accuracy: 0.7934 - val_loss: 0.7902 - val_binary_accuracy: 0.7960\n",
      "Epoch 576/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7490 - binary_accuracy: 0.8038 - val_loss: 0.7902 - val_binary_accuracy: 0.7960\n",
      "Epoch 577/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7635 - binary_accuracy: 0.7929 - val_loss: 0.7902 - val_binary_accuracy: 0.7960\n",
      "Epoch 578/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7416 - binary_accuracy: 0.8085 - val_loss: 0.7902 - val_binary_accuracy: 0.7960\n",
      "Epoch 579/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7821 - binary_accuracy: 0.7784 - val_loss: 0.7901 - val_binary_accuracy: 0.7959\n",
      "Epoch 580/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7513 - binary_accuracy: 0.8017 - val_loss: 0.7901 - val_binary_accuracy: 0.7960\n",
      "Epoch 581/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7490 - binary_accuracy: 0.8024 - val_loss: 0.7901 - val_binary_accuracy: 0.7961\n",
      "Epoch 582/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7443 - binary_accuracy: 0.8055 - val_loss: 0.7901 - val_binary_accuracy: 0.7961\n",
      "Epoch 583/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7306 - binary_accuracy: 0.8170 - val_loss: 0.7901 - val_binary_accuracy: 0.7960\n",
      "Epoch 584/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7430 - binary_accuracy: 0.8073 - val_loss: 0.7900 - val_binary_accuracy: 0.7960\n",
      "Epoch 585/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7573 - binary_accuracy: 0.7966 - val_loss: 0.7900 - val_binary_accuracy: 0.7959\n",
      "Epoch 586/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7343 - binary_accuracy: 0.8148 - val_loss: 0.7900 - val_binary_accuracy: 0.7959\n",
      "Epoch 587/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7565 - binary_accuracy: 0.7960 - val_loss: 0.7900 - val_binary_accuracy: 0.7960\n",
      "Epoch 588/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7500 - binary_accuracy: 0.8030 - val_loss: 0.7900 - val_binary_accuracy: 0.7960\n",
      "Epoch 589/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7336 - binary_accuracy: 0.8142 - val_loss: 0.7900 - val_binary_accuracy: 0.7960\n",
      "Epoch 590/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7467 - binary_accuracy: 0.8045 - val_loss: 0.7899 - val_binary_accuracy: 0.7960\n",
      "Epoch 591/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7508 - binary_accuracy: 0.8012 - val_loss: 0.7899 - val_binary_accuracy: 0.7960\n",
      "Epoch 592/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7424 - binary_accuracy: 0.8075 - val_loss: 0.7899 - val_binary_accuracy: 0.7960\n",
      "Epoch 593/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7522 - binary_accuracy: 0.8008 - val_loss: 0.7899 - val_binary_accuracy: 0.7960\n",
      "Epoch 594/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7592 - binary_accuracy: 0.7946 - val_loss: 0.7899 - val_binary_accuracy: 0.7960\n",
      "Epoch 595/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7454 - binary_accuracy: 0.8051 - val_loss: 0.7899 - val_binary_accuracy: 0.7960\n",
      "Epoch 596/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7344 - binary_accuracy: 0.8126 - val_loss: 0.7899 - val_binary_accuracy: 0.7960\n",
      "Epoch 597/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7529 - binary_accuracy: 0.7987 - val_loss: 0.7899 - val_binary_accuracy: 0.7960\n",
      "Epoch 598/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7526 - binary_accuracy: 0.8000 - val_loss: 0.7898 - val_binary_accuracy: 0.7960\n",
      "Epoch 599/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7375 - binary_accuracy: 0.8127 - val_loss: 0.7898 - val_binary_accuracy: 0.7960\n",
      "Epoch 600/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7706 - binary_accuracy: 0.7857 - val_loss: 0.7898 - val_binary_accuracy: 0.7960\n",
      "Epoch 601/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7686 - binary_accuracy: 0.7873 - val_loss: 0.7898 - val_binary_accuracy: 0.7960\n",
      "Epoch 602/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7488 - binary_accuracy: 0.8026 - val_loss: 0.7898 - val_binary_accuracy: 0.7960\n",
      "Epoch 603/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7818 - binary_accuracy: 0.7762 - val_loss: 0.7898 - val_binary_accuracy: 0.7960\n",
      "Epoch 604/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7582 - binary_accuracy: 0.7954 - val_loss: 0.7897 - val_binary_accuracy: 0.7960\n",
      "Epoch 605/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7591 - binary_accuracy: 0.7947 - val_loss: 0.7897 - val_binary_accuracy: 0.7960\n",
      "Epoch 606/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7505 - binary_accuracy: 0.8012 - val_loss: 0.7897 - val_binary_accuracy: 0.7960\n",
      "Epoch 607/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7719 - binary_accuracy: 0.7864 - val_loss: 0.7897 - val_binary_accuracy: 0.7960\n",
      "Epoch 608/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7680 - binary_accuracy: 0.7876 - val_loss: 0.7897 - val_binary_accuracy: 0.7960\n",
      "Epoch 609/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7576 - binary_accuracy: 0.7959 - val_loss: 0.7897 - val_binary_accuracy: 0.7960\n",
      "Epoch 610/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7614 - binary_accuracy: 0.7931 - val_loss: 0.7896 - val_binary_accuracy: 0.7960\n",
      "Epoch 611/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7285 - binary_accuracy: 0.8175 - val_loss: 0.7896 - val_binary_accuracy: 0.7960\n",
      "Epoch 612/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7298 - binary_accuracy: 0.8170 - val_loss: 0.7896 - val_binary_accuracy: 0.7960\n",
      "Epoch 613/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7564 - binary_accuracy: 0.7958 - val_loss: 0.7896 - val_binary_accuracy: 0.7960\n",
      "Epoch 614/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7532 - binary_accuracy: 0.7995 - val_loss: 0.7896 - val_binary_accuracy: 0.7960\n",
      "Epoch 615/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7582 - binary_accuracy: 0.7950 - val_loss: 0.7896 - val_binary_accuracy: 0.7960\n",
      "Epoch 616/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7434 - binary_accuracy: 0.8070 - val_loss: 0.7896 - val_binary_accuracy: 0.7960\n",
      "Epoch 617/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7592 - binary_accuracy: 0.7954 - val_loss: 0.7895 - val_binary_accuracy: 0.7960\n",
      "Epoch 618/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7547 - binary_accuracy: 0.7969 - val_loss: 0.7895 - val_binary_accuracy: 0.7960\n",
      "Epoch 619/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7585 - binary_accuracy: 0.7956 - val_loss: 0.7895 - val_binary_accuracy: 0.7960\n",
      "Epoch 620/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7485 - binary_accuracy: 0.8026 - val_loss: 0.7895 - val_binary_accuracy: 0.7960\n",
      "Epoch 621/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7463 - binary_accuracy: 0.8036 - val_loss: 0.7895 - val_binary_accuracy: 0.7960\n",
      "Epoch 622/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7690 - binary_accuracy: 0.7873 - val_loss: 0.7895 - val_binary_accuracy: 0.7960\n",
      "Epoch 623/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7359 - binary_accuracy: 0.8140 - val_loss: 0.7894 - val_binary_accuracy: 0.7960\n",
      "Epoch 624/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7473 - binary_accuracy: 0.8034 - val_loss: 0.7894 - val_binary_accuracy: 0.7960\n",
      "Epoch 625/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7619 - binary_accuracy: 0.7936 - val_loss: 0.7894 - val_binary_accuracy: 0.7960\n",
      "Epoch 626/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7313 - binary_accuracy: 0.8153 - val_loss: 0.7894 - val_binary_accuracy: 0.7960\n",
      "Epoch 627/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7557 - binary_accuracy: 0.7972 - val_loss: 0.7894 - val_binary_accuracy: 0.7960\n",
      "Epoch 628/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7353 - binary_accuracy: 0.8138 - val_loss: 0.7893 - val_binary_accuracy: 0.7960\n",
      "Epoch 629/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7521 - binary_accuracy: 0.7993 - val_loss: 0.7893 - val_binary_accuracy: 0.7960\n",
      "Epoch 630/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7480 - binary_accuracy: 0.8020 - val_loss: 0.7893 - val_binary_accuracy: 0.7960\n",
      "Epoch 631/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7243 - binary_accuracy: 0.8217 - val_loss: 0.7893 - val_binary_accuracy: 0.7960\n",
      "Epoch 632/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7694 - binary_accuracy: 0.7857 - val_loss: 0.7893 - val_binary_accuracy: 0.7960\n",
      "Epoch 633/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7699 - binary_accuracy: 0.7849 - val_loss: 0.7893 - val_binary_accuracy: 0.7960\n",
      "Epoch 634/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7661 - binary_accuracy: 0.7883 - val_loss: 0.7893 - val_binary_accuracy: 0.7960\n",
      "Epoch 635/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7315 - binary_accuracy: 0.8160 - val_loss: 0.7892 - val_binary_accuracy: 0.7960\n",
      "Epoch 636/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7570 - binary_accuracy: 0.7954 - val_loss: 0.7892 - val_binary_accuracy: 0.7960\n",
      "Epoch 637/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7411 - binary_accuracy: 0.8074 - val_loss: 0.7892 - val_binary_accuracy: 0.7960\n",
      "Epoch 638/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7349 - binary_accuracy: 0.8121 - val_loss: 0.7892 - val_binary_accuracy: 0.7960\n",
      "Epoch 639/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7822 - binary_accuracy: 0.7759 - val_loss: 0.7892 - val_binary_accuracy: 0.7960\n",
      "Epoch 640/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7527 - binary_accuracy: 0.7992 - val_loss: 0.7892 - val_binary_accuracy: 0.7960\n",
      "Epoch 641/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7495 - binary_accuracy: 0.8023 - val_loss: 0.7892 - val_binary_accuracy: 0.7960\n",
      "Epoch 642/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7488 - binary_accuracy: 0.8032 - val_loss: 0.7891 - val_binary_accuracy: 0.7960\n",
      "Epoch 643/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7485 - binary_accuracy: 0.8023 - val_loss: 0.7891 - val_binary_accuracy: 0.7960\n",
      "Epoch 644/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7603 - binary_accuracy: 0.7925 - val_loss: 0.7891 - val_binary_accuracy: 0.7960\n",
      "Epoch 645/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7550 - binary_accuracy: 0.7961 - val_loss: 0.7891 - val_binary_accuracy: 0.7960\n",
      "Epoch 646/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7545 - binary_accuracy: 0.7975 - val_loss: 0.7891 - val_binary_accuracy: 0.7960\n",
      "Epoch 647/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7501 - binary_accuracy: 0.8006 - val_loss: 0.7891 - val_binary_accuracy: 0.7960\n",
      "Epoch 648/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7551 - binary_accuracy: 0.7967 - val_loss: 0.7890 - val_binary_accuracy: 0.7960\n",
      "Epoch 649/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7374 - binary_accuracy: 0.8108 - val_loss: 0.7890 - val_binary_accuracy: 0.7960\n",
      "Epoch 650/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7415 - binary_accuracy: 0.8084 - val_loss: 0.7890 - val_binary_accuracy: 0.7960\n",
      "Epoch 651/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7773 - binary_accuracy: 0.7798 - val_loss: 0.7890 - val_binary_accuracy: 0.7960\n",
      "Epoch 652/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.7637 - binary_accuracy: 0.7902 - val_loss: 0.7890 - val_binary_accuracy: 0.7960\n",
      "Epoch 653/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7371 - binary_accuracy: 0.8102 - val_loss: 0.7890 - val_binary_accuracy: 0.7960\n",
      "Epoch 654/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7517 - binary_accuracy: 0.7990 - val_loss: 0.7890 - val_binary_accuracy: 0.7960\n",
      "Epoch 655/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7340 - binary_accuracy: 0.8130 - val_loss: 0.7890 - val_binary_accuracy: 0.7960\n",
      "Epoch 656/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7618 - binary_accuracy: 0.7913 - val_loss: 0.7889 - val_binary_accuracy: 0.7960\n",
      "Epoch 657/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7643 - binary_accuracy: 0.7894 - val_loss: 0.7889 - val_binary_accuracy: 0.7960\n",
      "Epoch 658/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7553 - binary_accuracy: 0.7962 - val_loss: 0.7889 - val_binary_accuracy: 0.7960\n",
      "Epoch 659/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7533 - binary_accuracy: 0.7978 - val_loss: 0.7889 - val_binary_accuracy: 0.7960\n",
      "Epoch 660/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7467 - binary_accuracy: 0.8033 - val_loss: 0.7889 - val_binary_accuracy: 0.7960\n",
      "Epoch 661/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7301 - binary_accuracy: 0.8163 - val_loss: 0.7889 - val_binary_accuracy: 0.7960\n",
      "Epoch 662/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7362 - binary_accuracy: 0.8107 - val_loss: 0.7888 - val_binary_accuracy: 0.7959\n",
      "Epoch 663/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7476 - binary_accuracy: 0.8016 - val_loss: 0.7888 - val_binary_accuracy: 0.7960\n",
      "Epoch 664/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7406 - binary_accuracy: 0.8074 - val_loss: 0.7888 - val_binary_accuracy: 0.7960\n",
      "Epoch 665/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7679 - binary_accuracy: 0.7869 - val_loss: 0.7888 - val_binary_accuracy: 0.7960\n",
      "Epoch 666/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7405 - binary_accuracy: 0.8090 - val_loss: 0.7888 - val_binary_accuracy: 0.7960\n",
      "Epoch 667/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7359 - binary_accuracy: 0.8118 - val_loss: 0.7888 - val_binary_accuracy: 0.7960\n",
      "Epoch 668/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7644 - binary_accuracy: 0.7904 - val_loss: 0.7888 - val_binary_accuracy: 0.7960\n",
      "Epoch 669/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7645 - binary_accuracy: 0.7897 - val_loss: 0.7887 - val_binary_accuracy: 0.7960\n",
      "Epoch 670/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7446 - binary_accuracy: 0.8050 - val_loss: 0.7887 - val_binary_accuracy: 0.7960\n",
      "Epoch 671/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7412 - binary_accuracy: 0.8084 - val_loss: 0.7887 - val_binary_accuracy: 0.7960\n",
      "Epoch 672/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7420 - binary_accuracy: 0.8064 - val_loss: 0.7887 - val_binary_accuracy: 0.7960\n",
      "Epoch 673/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7676 - binary_accuracy: 0.7862 - val_loss: 0.7887 - val_binary_accuracy: 0.7959\n",
      "Epoch 674/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7532 - binary_accuracy: 0.7977 - val_loss: 0.7887 - val_binary_accuracy: 0.7959\n",
      "Epoch 675/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7577 - binary_accuracy: 0.7945 - val_loss: 0.7887 - val_binary_accuracy: 0.7960\n",
      "Epoch 676/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7304 - binary_accuracy: 0.8165 - val_loss: 0.7886 - val_binary_accuracy: 0.7959\n",
      "Epoch 677/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7363 - binary_accuracy: 0.8103 - val_loss: 0.7886 - val_binary_accuracy: 0.7960\n",
      "Epoch 678/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7473 - binary_accuracy: 0.8026 - val_loss: 0.7886 - val_binary_accuracy: 0.7959\n",
      "Epoch 679/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7696 - binary_accuracy: 0.7855 - val_loss: 0.7886 - val_binary_accuracy: 0.7959\n",
      "Epoch 680/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7310 - binary_accuracy: 0.8166 - val_loss: 0.7886 - val_binary_accuracy: 0.7959\n",
      "Epoch 681/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7456 - binary_accuracy: 0.8027 - val_loss: 0.7886 - val_binary_accuracy: 0.7959\n",
      "Epoch 682/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7493 - binary_accuracy: 0.8007 - val_loss: 0.7885 - val_binary_accuracy: 0.7959\n",
      "Epoch 683/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7435 - binary_accuracy: 0.8052 - val_loss: 0.7885 - val_binary_accuracy: 0.7959\n",
      "Epoch 684/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7484 - binary_accuracy: 0.8025 - val_loss: 0.7885 - val_binary_accuracy: 0.7959\n",
      "Epoch 685/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7706 - binary_accuracy: 0.7836 - val_loss: 0.7885 - val_binary_accuracy: 0.7959\n",
      "Epoch 686/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7502 - binary_accuracy: 0.8000 - val_loss: 0.7885 - val_binary_accuracy: 0.7959\n",
      "Epoch 687/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7544 - binary_accuracy: 0.7981 - val_loss: 0.7885 - val_binary_accuracy: 0.7959\n",
      "Epoch 688/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7476 - binary_accuracy: 0.8016 - val_loss: 0.7885 - val_binary_accuracy: 0.7959\n",
      "Epoch 689/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7603 - binary_accuracy: 0.7908 - val_loss: 0.7885 - val_binary_accuracy: 0.7959\n",
      "Epoch 690/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7429 - binary_accuracy: 0.8060 - val_loss: 0.7884 - val_binary_accuracy: 0.7959\n",
      "Epoch 691/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7461 - binary_accuracy: 0.8021 - val_loss: 0.7884 - val_binary_accuracy: 0.7959\n",
      "Epoch 692/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7671 - binary_accuracy: 0.7867 - val_loss: 0.7884 - val_binary_accuracy: 0.7959\n",
      "Epoch 693/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7681 - binary_accuracy: 0.7860 - val_loss: 0.7884 - val_binary_accuracy: 0.7959\n",
      "Epoch 694/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7579 - binary_accuracy: 0.7932 - val_loss: 0.7884 - val_binary_accuracy: 0.7959\n",
      "Epoch 695/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7444 - binary_accuracy: 0.8046 - val_loss: 0.7884 - val_binary_accuracy: 0.7959\n",
      "Epoch 696/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7428 - binary_accuracy: 0.8056 - val_loss: 0.7883 - val_binary_accuracy: 0.7959\n",
      "Epoch 697/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7581 - binary_accuracy: 0.7937 - val_loss: 0.7883 - val_binary_accuracy: 0.7959\n",
      "Epoch 698/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7483 - binary_accuracy: 0.8018 - val_loss: 0.7883 - val_binary_accuracy: 0.7959\n",
      "Epoch 699/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7514 - binary_accuracy: 0.7999 - val_loss: 0.7883 - val_binary_accuracy: 0.7959\n",
      "Epoch 700/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7532 - binary_accuracy: 0.7978 - val_loss: 0.7883 - val_binary_accuracy: 0.7959\n",
      "Epoch 701/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7698 - binary_accuracy: 0.7849 - val_loss: 0.7883 - val_binary_accuracy: 0.7959\n",
      "Epoch 702/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7422 - binary_accuracy: 0.8065 - val_loss: 0.7883 - val_binary_accuracy: 0.7959\n",
      "Epoch 703/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7401 - binary_accuracy: 0.8075 - val_loss: 0.7883 - val_binary_accuracy: 0.7959\n",
      "Epoch 704/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7484 - binary_accuracy: 0.8001 - val_loss: 0.7882 - val_binary_accuracy: 0.7959\n",
      "Epoch 705/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7447 - binary_accuracy: 0.8045 - val_loss: 0.7882 - val_binary_accuracy: 0.7959\n",
      "Epoch 706/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7512 - binary_accuracy: 0.7995 - val_loss: 0.7882 - val_binary_accuracy: 0.7959\n",
      "Epoch 707/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7482 - binary_accuracy: 0.8010 - val_loss: 0.7882 - val_binary_accuracy: 0.7959\n",
      "Epoch 708/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7521 - binary_accuracy: 0.7987 - val_loss: 0.7882 - val_binary_accuracy: 0.7959\n",
      "Epoch 709/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7551 - binary_accuracy: 0.7961 - val_loss: 0.7882 - val_binary_accuracy: 0.7959\n",
      "Epoch 710/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7267 - binary_accuracy: 0.8198 - val_loss: 0.7882 - val_binary_accuracy: 0.7959\n",
      "Epoch 711/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7458 - binary_accuracy: 0.8026 - val_loss: 0.7881 - val_binary_accuracy: 0.7959\n",
      "Epoch 712/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7478 - binary_accuracy: 0.8022 - val_loss: 0.7881 - val_binary_accuracy: 0.7959\n",
      "Epoch 713/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7487 - binary_accuracy: 0.8002 - val_loss: 0.7881 - val_binary_accuracy: 0.7959\n",
      "Epoch 714/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7465 - binary_accuracy: 0.8028 - val_loss: 0.7881 - val_binary_accuracy: 0.7959\n",
      "Epoch 715/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7320 - binary_accuracy: 0.8144 - val_loss: 0.7881 - val_binary_accuracy: 0.7959\n",
      "Epoch 716/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7444 - binary_accuracy: 0.8041 - val_loss: 0.7881 - val_binary_accuracy: 0.7959\n",
      "Epoch 717/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7697 - binary_accuracy: 0.7842 - val_loss: 0.7881 - val_binary_accuracy: 0.7959\n",
      "Epoch 718/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7471 - binary_accuracy: 0.8036 - val_loss: 0.7881 - val_binary_accuracy: 0.7959\n",
      "Epoch 719/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7211 - binary_accuracy: 0.8229 - val_loss: 0.7881 - val_binary_accuracy: 0.7959\n",
      "Epoch 720/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7571 - binary_accuracy: 0.7926 - val_loss: 0.7880 - val_binary_accuracy: 0.7959\n",
      "Epoch 721/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7618 - binary_accuracy: 0.7903 - val_loss: 0.7880 - val_binary_accuracy: 0.7959\n",
      "Epoch 722/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7754 - binary_accuracy: 0.7805 - val_loss: 0.7880 - val_binary_accuracy: 0.7959\n",
      "Epoch 723/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7518 - binary_accuracy: 0.7986 - val_loss: 0.7880 - val_binary_accuracy: 0.7959\n",
      "Epoch 724/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7479 - binary_accuracy: 0.8017 - val_loss: 0.7880 - val_binary_accuracy: 0.7959\n",
      "Epoch 725/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7503 - binary_accuracy: 0.7997 - val_loss: 0.7880 - val_binary_accuracy: 0.7959\n",
      "Epoch 726/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7419 - binary_accuracy: 0.8051 - val_loss: 0.7879 - val_binary_accuracy: 0.7959\n",
      "Epoch 727/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7553 - binary_accuracy: 0.7960 - val_loss: 0.7879 - val_binary_accuracy: 0.7959\n",
      "Epoch 728/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7496 - binary_accuracy: 0.8002 - val_loss: 0.7879 - val_binary_accuracy: 0.7959\n",
      "Epoch 729/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7392 - binary_accuracy: 0.8080 - val_loss: 0.7879 - val_binary_accuracy: 0.7959\n",
      "Epoch 730/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7583 - binary_accuracy: 0.7919 - val_loss: 0.7879 - val_binary_accuracy: 0.7959\n",
      "Epoch 731/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7446 - binary_accuracy: 0.8034 - val_loss: 0.7879 - val_binary_accuracy: 0.7959\n",
      "Epoch 732/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7479 - binary_accuracy: 0.8026 - val_loss: 0.7879 - val_binary_accuracy: 0.7959\n",
      "Epoch 733/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7266 - binary_accuracy: 0.8183 - val_loss: 0.7879 - val_binary_accuracy: 0.7959\n",
      "Epoch 734/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7597 - binary_accuracy: 0.7910 - val_loss: 0.7879 - val_binary_accuracy: 0.7959\n",
      "Epoch 735/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7436 - binary_accuracy: 0.8047 - val_loss: 0.7878 - val_binary_accuracy: 0.7959\n",
      "Epoch 736/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7389 - binary_accuracy: 0.8089 - val_loss: 0.7878 - val_binary_accuracy: 0.7959\n",
      "Epoch 737/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7515 - binary_accuracy: 0.7979 - val_loss: 0.7878 - val_binary_accuracy: 0.7959\n",
      "Epoch 738/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7398 - binary_accuracy: 0.8083 - val_loss: 0.7878 - val_binary_accuracy: 0.7959\n",
      "Epoch 739/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7507 - binary_accuracy: 0.7989 - val_loss: 0.7878 - val_binary_accuracy: 0.7959\n",
      "Epoch 740/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7468 - binary_accuracy: 0.8019 - val_loss: 0.7878 - val_binary_accuracy: 0.7959\n",
      "Epoch 741/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7542 - binary_accuracy: 0.7946 - val_loss: 0.7878 - val_binary_accuracy: 0.7959\n",
      "Epoch 742/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7465 - binary_accuracy: 0.8034 - val_loss: 0.7877 - val_binary_accuracy: 0.7959\n",
      "Epoch 743/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7502 - binary_accuracy: 0.7989 - val_loss: 0.7877 - val_binary_accuracy: 0.7959\n",
      "Epoch 744/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7371 - binary_accuracy: 0.8090 - val_loss: 0.7877 - val_binary_accuracy: 0.7959\n",
      "Epoch 745/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7401 - binary_accuracy: 0.8073 - val_loss: 0.7877 - val_binary_accuracy: 0.7959\n",
      "Epoch 746/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7493 - binary_accuracy: 0.7994 - val_loss: 0.7877 - val_binary_accuracy: 0.7959\n",
      "Epoch 747/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7433 - binary_accuracy: 0.8037 - val_loss: 0.7877 - val_binary_accuracy: 0.7959\n",
      "Epoch 748/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7432 - binary_accuracy: 0.8053 - val_loss: 0.7877 - val_binary_accuracy: 0.7959\n",
      "Epoch 749/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7304 - binary_accuracy: 0.8147 - val_loss: 0.7877 - val_binary_accuracy: 0.7959\n",
      "Epoch 750/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7774 - binary_accuracy: 0.7780 - val_loss: 0.7877 - val_binary_accuracy: 0.7959\n",
      "Epoch 751/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7340 - binary_accuracy: 0.8116 - val_loss: 0.7876 - val_binary_accuracy: 0.7959\n",
      "Epoch 752/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7658 - binary_accuracy: 0.7868 - val_loss: 0.7876 - val_binary_accuracy: 0.7959\n",
      "Epoch 753/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7469 - binary_accuracy: 0.8022 - val_loss: 0.7876 - val_binary_accuracy: 0.7959\n",
      "Epoch 754/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7535 - binary_accuracy: 0.7962 - val_loss: 0.7876 - val_binary_accuracy: 0.7959\n",
      "Epoch 755/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7466 - binary_accuracy: 0.8024 - val_loss: 0.7876 - val_binary_accuracy: 0.7959\n",
      "Epoch 756/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.7566 - binary_accuracy: 0.7933 - val_loss: 0.7876 - val_binary_accuracy: 0.7959\n",
      "Epoch 757/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7642 - binary_accuracy: 0.7887 - val_loss: 0.7876 - val_binary_accuracy: 0.7959\n",
      "Epoch 758/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7636 - binary_accuracy: 0.7895 - val_loss: 0.7876 - val_binary_accuracy: 0.7959\n",
      "Epoch 759/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7685 - binary_accuracy: 0.7849 - val_loss: 0.7876 - val_binary_accuracy: 0.7959\n",
      "Epoch 760/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7358 - binary_accuracy: 0.8102 - val_loss: 0.7875 - val_binary_accuracy: 0.7959\n",
      "Epoch 761/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7438 - binary_accuracy: 0.8026 - val_loss: 0.7875 - val_binary_accuracy: 0.7959\n",
      "Epoch 762/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7817 - binary_accuracy: 0.7751 - val_loss: 0.7875 - val_binary_accuracy: 0.7959\n",
      "Epoch 763/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7311 - binary_accuracy: 0.8136 - val_loss: 0.7875 - val_binary_accuracy: 0.7959\n",
      "Epoch 764/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7370 - binary_accuracy: 0.8088 - val_loss: 0.7875 - val_binary_accuracy: 0.7959\n",
      "Epoch 765/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7412 - binary_accuracy: 0.8062 - val_loss: 0.7875 - val_binary_accuracy: 0.7959\n",
      "Epoch 766/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7575 - binary_accuracy: 0.7939 - val_loss: 0.7875 - val_binary_accuracy: 0.7959\n",
      "Epoch 767/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7413 - binary_accuracy: 0.8060 - val_loss: 0.7875 - val_binary_accuracy: 0.7959\n",
      "Epoch 768/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7465 - binary_accuracy: 0.8013 - val_loss: 0.7875 - val_binary_accuracy: 0.7958\n",
      "Epoch 769/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7370 - binary_accuracy: 0.8093 - val_loss: 0.7874 - val_binary_accuracy: 0.7959\n",
      "Epoch 770/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7423 - binary_accuracy: 0.8044 - val_loss: 0.7874 - val_binary_accuracy: 0.7959\n",
      "Epoch 771/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7825 - binary_accuracy: 0.7738 - val_loss: 0.7874 - val_binary_accuracy: 0.7959\n",
      "Epoch 772/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7687 - binary_accuracy: 0.7848 - val_loss: 0.7874 - val_binary_accuracy: 0.7959\n",
      "Epoch 773/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7662 - binary_accuracy: 0.7873 - val_loss: 0.7874 - val_binary_accuracy: 0.7959\n",
      "Epoch 774/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7587 - binary_accuracy: 0.7918 - val_loss: 0.7874 - val_binary_accuracy: 0.7959\n",
      "Epoch 775/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7537 - binary_accuracy: 0.7954 - val_loss: 0.7873 - val_binary_accuracy: 0.7959\n",
      "Epoch 776/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7359 - binary_accuracy: 0.8109 - val_loss: 0.7873 - val_binary_accuracy: 0.7959\n",
      "Epoch 777/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7475 - binary_accuracy: 0.8010 - val_loss: 0.7873 - val_binary_accuracy: 0.7959\n",
      "Epoch 778/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7418 - binary_accuracy: 0.8040 - val_loss: 0.7873 - val_binary_accuracy: 0.7959\n",
      "Epoch 779/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7600 - binary_accuracy: 0.7903 - val_loss: 0.7873 - val_binary_accuracy: 0.7958\n",
      "Epoch 780/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7298 - binary_accuracy: 0.8139 - val_loss: 0.7873 - val_binary_accuracy: 0.7958\n",
      "Epoch 781/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7343 - binary_accuracy: 0.8108 - val_loss: 0.7873 - val_binary_accuracy: 0.7959\n",
      "Epoch 782/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7445 - binary_accuracy: 0.8035 - val_loss: 0.7873 - val_binary_accuracy: 0.7959\n",
      "Epoch 783/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7641 - binary_accuracy: 0.7874 - val_loss: 0.7872 - val_binary_accuracy: 0.7959\n",
      "Epoch 784/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7197 - binary_accuracy: 0.8231 - val_loss: 0.7872 - val_binary_accuracy: 0.7959\n",
      "Epoch 785/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7496 - binary_accuracy: 0.7998 - val_loss: 0.7872 - val_binary_accuracy: 0.7959\n",
      "Epoch 786/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7248 - binary_accuracy: 0.8186 - val_loss: 0.7872 - val_binary_accuracy: 0.7959\n",
      "Epoch 787/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7416 - binary_accuracy: 0.8048 - val_loss: 0.7872 - val_binary_accuracy: 0.7959\n",
      "Epoch 788/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7427 - binary_accuracy: 0.8041 - val_loss: 0.7872 - val_binary_accuracy: 0.7959\n",
      "Epoch 789/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7463 - binary_accuracy: 0.8016 - val_loss: 0.7872 - val_binary_accuracy: 0.7959\n",
      "Epoch 790/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7216 - binary_accuracy: 0.8208 - val_loss: 0.7872 - val_binary_accuracy: 0.7959\n",
      "Epoch 791/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7572 - binary_accuracy: 0.7931 - val_loss: 0.7872 - val_binary_accuracy: 0.7959\n",
      "Epoch 792/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7606 - binary_accuracy: 0.7900 - val_loss: 0.7872 - val_binary_accuracy: 0.7959\n",
      "Epoch 793/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7606 - binary_accuracy: 0.7915 - val_loss: 0.7872 - val_binary_accuracy: 0.7958\n",
      "Epoch 794/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7479 - binary_accuracy: 0.8003 - val_loss: 0.7871 - val_binary_accuracy: 0.7958\n",
      "Epoch 795/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7387 - binary_accuracy: 0.8077 - val_loss: 0.7871 - val_binary_accuracy: 0.7958\n",
      "Epoch 796/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7556 - binary_accuracy: 0.7929 - val_loss: 0.7871 - val_binary_accuracy: 0.7957\n",
      "Epoch 797/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7449 - binary_accuracy: 0.8040 - val_loss: 0.7871 - val_binary_accuracy: 0.7958\n",
      "Epoch 798/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7344 - binary_accuracy: 0.8105 - val_loss: 0.7871 - val_binary_accuracy: 0.7958\n",
      "Epoch 799/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7416 - binary_accuracy: 0.8047 - val_loss: 0.7871 - val_binary_accuracy: 0.7958\n",
      "Epoch 800/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7552 - binary_accuracy: 0.7951 - val_loss: 0.7871 - val_binary_accuracy: 0.7958\n",
      "Epoch 801/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7491 - binary_accuracy: 0.7994 - val_loss: 0.7870 - val_binary_accuracy: 0.7958\n",
      "Epoch 802/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7472 - binary_accuracy: 0.8016 - val_loss: 0.7870 - val_binary_accuracy: 0.7958\n",
      "Epoch 803/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7334 - binary_accuracy: 0.8101 - val_loss: 0.7870 - val_binary_accuracy: 0.7958\n",
      "Epoch 804/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7534 - binary_accuracy: 0.7955 - val_loss: 0.7870 - val_binary_accuracy: 0.7958\n",
      "Epoch 805/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7441 - binary_accuracy: 0.8025 - val_loss: 0.7870 - val_binary_accuracy: 0.7958\n",
      "Epoch 806/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7296 - binary_accuracy: 0.8166 - val_loss: 0.7870 - val_binary_accuracy: 0.7959\n",
      "Epoch 807/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7508 - binary_accuracy: 0.7989 - val_loss: 0.7870 - val_binary_accuracy: 0.7959\n",
      "Epoch 808/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7556 - binary_accuracy: 0.7937 - val_loss: 0.7870 - val_binary_accuracy: 0.7958\n",
      "Epoch 809/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7712 - binary_accuracy: 0.7833 - val_loss: 0.7870 - val_binary_accuracy: 0.7958\n",
      "Epoch 810/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7533 - binary_accuracy: 0.7957 - val_loss: 0.7870 - val_binary_accuracy: 0.7958\n",
      "Epoch 811/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7346 - binary_accuracy: 0.8101 - val_loss: 0.7869 - val_binary_accuracy: 0.7958\n",
      "Epoch 812/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7413 - binary_accuracy: 0.8053 - val_loss: 0.7869 - val_binary_accuracy: 0.7958\n",
      "Epoch 813/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7487 - binary_accuracy: 0.7998 - val_loss: 0.7869 - val_binary_accuracy: 0.7958\n",
      "Epoch 814/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7491 - binary_accuracy: 0.7987 - val_loss: 0.7869 - val_binary_accuracy: 0.7958\n",
      "Epoch 815/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7512 - binary_accuracy: 0.7985 - val_loss: 0.7869 - val_binary_accuracy: 0.7958\n",
      "Epoch 816/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7483 - binary_accuracy: 0.8006 - val_loss: 0.7869 - val_binary_accuracy: 0.7958\n",
      "Epoch 817/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7519 - binary_accuracy: 0.7966 - val_loss: 0.7869 - val_binary_accuracy: 0.7958\n",
      "Epoch 818/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7465 - binary_accuracy: 0.8000 - val_loss: 0.7869 - val_binary_accuracy: 0.7958\n",
      "Epoch 819/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7450 - binary_accuracy: 0.8026 - val_loss: 0.7869 - val_binary_accuracy: 0.7958\n",
      "Epoch 820/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7336 - binary_accuracy: 0.8102 - val_loss: 0.7869 - val_binary_accuracy: 0.7958\n",
      "Epoch 821/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7600 - binary_accuracy: 0.7898 - val_loss: 0.7868 - val_binary_accuracy: 0.7958\n",
      "Epoch 822/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7545 - binary_accuracy: 0.7942 - val_loss: 0.7868 - val_binary_accuracy: 0.7957\n",
      "Epoch 823/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7461 - binary_accuracy: 0.8012 - val_loss: 0.7868 - val_binary_accuracy: 0.7958\n",
      "Epoch 824/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7519 - binary_accuracy: 0.7969 - val_loss: 0.7868 - val_binary_accuracy: 0.7957\n",
      "Epoch 825/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7382 - binary_accuracy: 0.8063 - val_loss: 0.7868 - val_binary_accuracy: 0.7957\n",
      "Epoch 826/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7358 - binary_accuracy: 0.8102 - val_loss: 0.7868 - val_binary_accuracy: 0.7959\n",
      "Epoch 827/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7507 - binary_accuracy: 0.7971 - val_loss: 0.7868 - val_binary_accuracy: 0.7959\n",
      "Epoch 828/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7545 - binary_accuracy: 0.7953 - val_loss: 0.7868 - val_binary_accuracy: 0.7958\n",
      "Epoch 829/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7603 - binary_accuracy: 0.7897 - val_loss: 0.7868 - val_binary_accuracy: 0.7959\n",
      "Epoch 830/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7405 - binary_accuracy: 0.8052 - val_loss: 0.7867 - val_binary_accuracy: 0.7959\n",
      "Epoch 831/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7408 - binary_accuracy: 0.8046 - val_loss: 0.7867 - val_binary_accuracy: 0.7958\n",
      "Epoch 832/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7513 - binary_accuracy: 0.7973 - val_loss: 0.7867 - val_binary_accuracy: 0.7958\n",
      "Epoch 833/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7408 - binary_accuracy: 0.8039 - val_loss: 0.7867 - val_binary_accuracy: 0.7959\n",
      "Epoch 834/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7393 - binary_accuracy: 0.8064 - val_loss: 0.7867 - val_binary_accuracy: 0.7958\n",
      "Epoch 835/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7498 - binary_accuracy: 0.7978 - val_loss: 0.7867 - val_binary_accuracy: 0.7959\n",
      "Epoch 836/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7520 - binary_accuracy: 0.7956 - val_loss: 0.7867 - val_binary_accuracy: 0.7958\n",
      "Epoch 837/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7291 - binary_accuracy: 0.8144 - val_loss: 0.7867 - val_binary_accuracy: 0.7959\n",
      "Epoch 838/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7481 - binary_accuracy: 0.8003 - val_loss: 0.7866 - val_binary_accuracy: 0.7959\n",
      "Epoch 839/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7354 - binary_accuracy: 0.8094 - val_loss: 0.7866 - val_binary_accuracy: 0.7958\n",
      "Epoch 840/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7779 - binary_accuracy: 0.7769 - val_loss: 0.7866 - val_binary_accuracy: 0.7959\n",
      "Epoch 841/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7425 - binary_accuracy: 0.8030 - val_loss: 0.7866 - val_binary_accuracy: 0.7958\n",
      "Epoch 842/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7527 - binary_accuracy: 0.7958 - val_loss: 0.7866 - val_binary_accuracy: 0.7958\n",
      "Epoch 843/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7281 - binary_accuracy: 0.8150 - val_loss: 0.7866 - val_binary_accuracy: 0.7958\n",
      "Epoch 844/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7607 - binary_accuracy: 0.7896 - val_loss: 0.7866 - val_binary_accuracy: 0.7958\n",
      "Epoch 845/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7448 - binary_accuracy: 0.8022 - val_loss: 0.7866 - val_binary_accuracy: 0.7958\n",
      "Epoch 846/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7309 - binary_accuracy: 0.8141 - val_loss: 0.7866 - val_binary_accuracy: 0.7958\n",
      "Epoch 847/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7381 - binary_accuracy: 0.8073 - val_loss: 0.7866 - val_binary_accuracy: 0.7958\n",
      "Epoch 848/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7347 - binary_accuracy: 0.8097 - val_loss: 0.7866 - val_binary_accuracy: 0.7958\n",
      "Epoch 849/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7462 - binary_accuracy: 0.7999 - val_loss: 0.7865 - val_binary_accuracy: 0.7957\n",
      "Epoch 850/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7506 - binary_accuracy: 0.7975 - val_loss: 0.7865 - val_binary_accuracy: 0.7958\n",
      "Epoch 851/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7354 - binary_accuracy: 0.8100 - val_loss: 0.7865 - val_binary_accuracy: 0.7958\n",
      "Epoch 852/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7428 - binary_accuracy: 0.8036 - val_loss: 0.7865 - val_binary_accuracy: 0.7958\n",
      "Epoch 853/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7711 - binary_accuracy: 0.7799 - val_loss: 0.7865 - val_binary_accuracy: 0.7958\n",
      "Epoch 854/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7268 - binary_accuracy: 0.8154 - val_loss: 0.7865 - val_binary_accuracy: 0.7958\n",
      "Epoch 855/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7288 - binary_accuracy: 0.8146 - val_loss: 0.7865 - val_binary_accuracy: 0.7959\n",
      "Epoch 856/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7393 - binary_accuracy: 0.8067 - val_loss: 0.7865 - val_binary_accuracy: 0.7958\n",
      "Epoch 857/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7338 - binary_accuracy: 0.8108 - val_loss: 0.7865 - val_binary_accuracy: 0.7958\n",
      "Epoch 858/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7509 - binary_accuracy: 0.7970 - val_loss: 0.7864 - val_binary_accuracy: 0.7958\n",
      "Epoch 859/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7311 - binary_accuracy: 0.8139 - val_loss: 0.7864 - val_binary_accuracy: 0.7958\n",
      "Epoch 860/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7538 - binary_accuracy: 0.7942 - val_loss: 0.7864 - val_binary_accuracy: 0.7959\n",
      "Epoch 861/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7380 - binary_accuracy: 0.8070 - val_loss: 0.7864 - val_binary_accuracy: 0.7958\n",
      "Epoch 862/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7449 - binary_accuracy: 0.8024 - val_loss: 0.7864 - val_binary_accuracy: 0.7958\n",
      "Epoch 863/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7402 - binary_accuracy: 0.8059 - val_loss: 0.7864 - val_binary_accuracy: 0.7958\n",
      "Epoch 864/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7675 - binary_accuracy: 0.7830 - val_loss: 0.7864 - val_binary_accuracy: 0.7959\n",
      "Epoch 865/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7516 - binary_accuracy: 0.7974 - val_loss: 0.7864 - val_binary_accuracy: 0.7958\n",
      "Epoch 866/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7307 - binary_accuracy: 0.8128 - val_loss: 0.7864 - val_binary_accuracy: 0.7959\n",
      "Epoch 867/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7729 - binary_accuracy: 0.7811 - val_loss: 0.7864 - val_binary_accuracy: 0.7958\n",
      "Epoch 868/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7592 - binary_accuracy: 0.7915 - val_loss: 0.7863 - val_binary_accuracy: 0.7958\n",
      "Epoch 869/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7510 - binary_accuracy: 0.7970 - val_loss: 0.7863 - val_binary_accuracy: 0.7957\n",
      "Epoch 870/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7322 - binary_accuracy: 0.8123 - val_loss: 0.7863 - val_binary_accuracy: 0.7957\n",
      "Epoch 871/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7326 - binary_accuracy: 0.8124 - val_loss: 0.7863 - val_binary_accuracy: 0.7957\n",
      "Epoch 872/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7685 - binary_accuracy: 0.7834 - val_loss: 0.7863 - val_binary_accuracy: 0.7957\n",
      "Epoch 873/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7532 - binary_accuracy: 0.7956 - val_loss: 0.7863 - val_binary_accuracy: 0.7957\n",
      "Epoch 874/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7518 - binary_accuracy: 0.7961 - val_loss: 0.7863 - val_binary_accuracy: 0.7957\n",
      "Epoch 875/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7650 - binary_accuracy: 0.7859 - val_loss: 0.7863 - val_binary_accuracy: 0.7957\n",
      "Epoch 876/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7611 - binary_accuracy: 0.7895 - val_loss: 0.7863 - val_binary_accuracy: 0.7957\n",
      "Epoch 877/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7400 - binary_accuracy: 0.8049 - val_loss: 0.7863 - val_binary_accuracy: 0.7957\n",
      "Epoch 878/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7370 - binary_accuracy: 0.8079 - val_loss: 0.7862 - val_binary_accuracy: 0.7958\n",
      "Epoch 879/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7423 - binary_accuracy: 0.8036 - val_loss: 0.7862 - val_binary_accuracy: 0.7958\n",
      "Epoch 880/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7374 - binary_accuracy: 0.8068 - val_loss: 0.7862 - val_binary_accuracy: 0.7958\n",
      "Epoch 881/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7383 - binary_accuracy: 0.8068 - val_loss: 0.7862 - val_binary_accuracy: 0.7958\n",
      "Epoch 882/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7613 - binary_accuracy: 0.7874 - val_loss: 0.7862 - val_binary_accuracy: 0.7958\n",
      "Epoch 883/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7523 - binary_accuracy: 0.7952 - val_loss: 0.7862 - val_binary_accuracy: 0.7958\n",
      "Epoch 884/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7422 - binary_accuracy: 0.8035 - val_loss: 0.7862 - val_binary_accuracy: 0.7958\n",
      "Epoch 885/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7289 - binary_accuracy: 0.8134 - val_loss: 0.7862 - val_binary_accuracy: 0.7958\n",
      "Epoch 886/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7573 - binary_accuracy: 0.7936 - val_loss: 0.7862 - val_binary_accuracy: 0.7958\n",
      "Epoch 887/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7438 - binary_accuracy: 0.8037 - val_loss: 0.7861 - val_binary_accuracy: 0.7958\n",
      "Epoch 888/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7683 - binary_accuracy: 0.7836 - val_loss: 0.7861 - val_binary_accuracy: 0.7958\n",
      "Epoch 889/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7456 - binary_accuracy: 0.8002 - val_loss: 0.7861 - val_binary_accuracy: 0.7958\n",
      "Epoch 890/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7441 - binary_accuracy: 0.8014 - val_loss: 0.7861 - val_binary_accuracy: 0.7958\n",
      "Epoch 891/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7589 - binary_accuracy: 0.7924 - val_loss: 0.7861 - val_binary_accuracy: 0.7958\n",
      "Epoch 892/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7244 - binary_accuracy: 0.8184 - val_loss: 0.7861 - val_binary_accuracy: 0.7958\n",
      "Epoch 893/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7176 - binary_accuracy: 0.8228 - val_loss: 0.7861 - val_binary_accuracy: 0.7958\n",
      "Epoch 894/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7593 - binary_accuracy: 0.7907 - val_loss: 0.7861 - val_binary_accuracy: 0.7958\n",
      "Epoch 895/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7534 - binary_accuracy: 0.7944 - val_loss: 0.7861 - val_binary_accuracy: 0.7958\n",
      "Epoch 896/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7498 - binary_accuracy: 0.7973 - val_loss: 0.7860 - val_binary_accuracy: 0.7958\n",
      "Epoch 897/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7372 - binary_accuracy: 0.8088 - val_loss: 0.7860 - val_binary_accuracy: 0.7958\n",
      "Epoch 898/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7336 - binary_accuracy: 0.8103 - val_loss: 0.7860 - val_binary_accuracy: 0.7958\n",
      "Epoch 899/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7362 - binary_accuracy: 0.8084 - val_loss: 0.7860 - val_binary_accuracy: 0.7958\n",
      "Epoch 900/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7322 - binary_accuracy: 0.8118 - val_loss: 0.7860 - val_binary_accuracy: 0.7958\n",
      "Epoch 901/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7555 - binary_accuracy: 0.7928 - val_loss: 0.7860 - val_binary_accuracy: 0.7958\n",
      "Epoch 902/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7502 - binary_accuracy: 0.7976 - val_loss: 0.7860 - val_binary_accuracy: 0.7958\n",
      "Epoch 903/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7514 - binary_accuracy: 0.7967 - val_loss: 0.7860 - val_binary_accuracy: 0.7959\n",
      "Epoch 904/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7460 - binary_accuracy: 0.8005 - val_loss: 0.7860 - val_binary_accuracy: 0.7958\n",
      "Epoch 905/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7240 - binary_accuracy: 0.8173 - val_loss: 0.7860 - val_binary_accuracy: 0.7958\n",
      "Epoch 906/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7570 - binary_accuracy: 0.7917 - val_loss: 0.7860 - val_binary_accuracy: 0.7958\n",
      "Epoch 907/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7546 - binary_accuracy: 0.7938 - val_loss: 0.7860 - val_binary_accuracy: 0.7958\n",
      "Epoch 908/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7263 - binary_accuracy: 0.8151 - val_loss: 0.7859 - val_binary_accuracy: 0.7958\n",
      "Epoch 909/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7344 - binary_accuracy: 0.8098 - val_loss: 0.7859 - val_binary_accuracy: 0.7958\n",
      "Epoch 910/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7563 - binary_accuracy: 0.7928 - val_loss: 0.7859 - val_binary_accuracy: 0.7958\n",
      "Epoch 911/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7315 - binary_accuracy: 0.8125 - val_loss: 0.7859 - val_binary_accuracy: 0.7958\n",
      "Epoch 912/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7172 - binary_accuracy: 0.8234 - val_loss: 0.7859 - val_binary_accuracy: 0.7958\n",
      "Epoch 913/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7381 - binary_accuracy: 0.8055 - val_loss: 0.7859 - val_binary_accuracy: 0.7958\n",
      "Epoch 914/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7293 - binary_accuracy: 0.8129 - val_loss: 0.7859 - val_binary_accuracy: 0.7958\n",
      "Epoch 915/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7657 - binary_accuracy: 0.7840 - val_loss: 0.7859 - val_binary_accuracy: 0.7958\n",
      "Epoch 916/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7640 - binary_accuracy: 0.7864 - val_loss: 0.7859 - val_binary_accuracy: 0.7958\n",
      "Epoch 917/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7642 - binary_accuracy: 0.7852 - val_loss: 0.7859 - val_binary_accuracy: 0.7958\n",
      "Epoch 918/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7195 - binary_accuracy: 0.8211 - val_loss: 0.7858 - val_binary_accuracy: 0.7958\n",
      "Epoch 919/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7396 - binary_accuracy: 0.8055 - val_loss: 0.7858 - val_binary_accuracy: 0.7958\n",
      "Epoch 920/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7556 - binary_accuracy: 0.7931 - val_loss: 0.7858 - val_binary_accuracy: 0.7958\n",
      "Epoch 921/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7474 - binary_accuracy: 0.7993 - val_loss: 0.7858 - val_binary_accuracy: 0.7958\n",
      "Epoch 922/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7392 - binary_accuracy: 0.8053 - val_loss: 0.7858 - val_binary_accuracy: 0.7958\n",
      "Epoch 923/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.7351 - binary_accuracy: 0.8089 - val_loss: 0.7858 - val_binary_accuracy: 0.7958\n",
      "Epoch 924/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7441 - binary_accuracy: 0.8014 - val_loss: 0.7858 - val_binary_accuracy: 0.7958\n",
      "Epoch 925/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7658 - binary_accuracy: 0.7843 - val_loss: 0.7858 - val_binary_accuracy: 0.7958\n",
      "Epoch 926/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7495 - binary_accuracy: 0.7975 - val_loss: 0.7858 - val_binary_accuracy: 0.7958\n",
      "Epoch 927/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7465 - binary_accuracy: 0.7987 - val_loss: 0.7858 - val_binary_accuracy: 0.7958\n",
      "Epoch 928/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.7370 - binary_accuracy: 0.8067 - val_loss: 0.7857 - val_binary_accuracy: 0.7958\n",
      "Epoch 929/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7454 - binary_accuracy: 0.7999 - val_loss: 0.7857 - val_binary_accuracy: 0.7958\n",
      "Epoch 930/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7564 - binary_accuracy: 0.7920 - val_loss: 0.7857 - val_binary_accuracy: 0.7958\n",
      "Epoch 931/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7296 - binary_accuracy: 0.8135 - val_loss: 0.7857 - val_binary_accuracy: 0.7958\n",
      "Epoch 932/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7420 - binary_accuracy: 0.8031 - val_loss: 0.7857 - val_binary_accuracy: 0.7958\n",
      "Epoch 933/1000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.7480 - binary_accuracy: 0.7985 - val_loss: 0.7857 - val_binary_accuracy: 0.7958\n",
      "Epoch 934/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7215 - binary_accuracy: 0.8193 - val_loss: 0.7857 - val_binary_accuracy: 0.7958\n",
      "Epoch 935/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7558 - binary_accuracy: 0.7927 - val_loss: 0.7857 - val_binary_accuracy: 0.7958\n",
      "Epoch 936/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7465 - binary_accuracy: 0.7991 - val_loss: 0.7857 - val_binary_accuracy: 0.7959\n",
      "Epoch 937/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7416 - binary_accuracy: 0.8043 - val_loss: 0.7857 - val_binary_accuracy: 0.7958\n",
      "Epoch 938/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.7477 - binary_accuracy: 0.7983 - val_loss: 0.7857 - val_binary_accuracy: 0.7958\n",
      "Epoch 939/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7504 - binary_accuracy: 0.7977 - val_loss: 0.7857 - val_binary_accuracy: 0.7958\n",
      "Epoch 940/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7294 - binary_accuracy: 0.8127 - val_loss: 0.7856 - val_binary_accuracy: 0.7959\n",
      "Epoch 941/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7510 - binary_accuracy: 0.7964 - val_loss: 0.7856 - val_binary_accuracy: 0.7958\n",
      "Epoch 942/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7367 - binary_accuracy: 0.8064 - val_loss: 0.7856 - val_binary_accuracy: 0.7959\n",
      "Epoch 943/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.7380 - binary_accuracy: 0.8058 - val_loss: 0.7856 - val_binary_accuracy: 0.7959\n",
      "Epoch 944/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7317 - binary_accuracy: 0.8112 - val_loss: 0.7856 - val_binary_accuracy: 0.7959\n",
      "Epoch 945/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7539 - binary_accuracy: 0.7940 - val_loss: 0.7856 - val_binary_accuracy: 0.7958\n",
      "Epoch 946/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7476 - binary_accuracy: 0.7986 - val_loss: 0.7856 - val_binary_accuracy: 0.7958\n",
      "Epoch 947/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7282 - binary_accuracy: 0.8147 - val_loss: 0.7856 - val_binary_accuracy: 0.7958\n",
      "Epoch 948/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7529 - binary_accuracy: 0.7943 - val_loss: 0.7856 - val_binary_accuracy: 0.7958\n",
      "Epoch 949/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7502 - binary_accuracy: 0.7959 - val_loss: 0.7856 - val_binary_accuracy: 0.7958\n",
      "Epoch 950/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7383 - binary_accuracy: 0.8056 - val_loss: 0.7856 - val_binary_accuracy: 0.7958\n",
      "Epoch 951/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7383 - binary_accuracy: 0.8063 - val_loss: 0.7855 - val_binary_accuracy: 0.7958\n",
      "Epoch 952/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7559 - binary_accuracy: 0.7923 - val_loss: 0.7855 - val_binary_accuracy: 0.7958\n",
      "Epoch 953/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7500 - binary_accuracy: 0.7972 - val_loss: 0.7855 - val_binary_accuracy: 0.7958\n",
      "Epoch 954/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7394 - binary_accuracy: 0.8068 - val_loss: 0.7855 - val_binary_accuracy: 0.7959\n",
      "Epoch 955/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7464 - binary_accuracy: 0.7994 - val_loss: 0.7855 - val_binary_accuracy: 0.7958\n",
      "Epoch 956/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7622 - binary_accuracy: 0.7874 - val_loss: 0.7855 - val_binary_accuracy: 0.7958\n",
      "Epoch 957/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7368 - binary_accuracy: 0.8065 - val_loss: 0.7855 - val_binary_accuracy: 0.7958\n",
      "Epoch 958/1000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.7510 - binary_accuracy: 0.7949 - val_loss: 0.7855 - val_binary_accuracy: 0.7958\n",
      "Epoch 959/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7516 - binary_accuracy: 0.7960 - val_loss: 0.7855 - val_binary_accuracy: 0.7958\n",
      "Epoch 960/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7521 - binary_accuracy: 0.7946 - val_loss: 0.7855 - val_binary_accuracy: 0.7959\n",
      "Epoch 961/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7509 - binary_accuracy: 0.7965 - val_loss: 0.7855 - val_binary_accuracy: 0.7958\n",
      "Epoch 962/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7501 - binary_accuracy: 0.7963 - val_loss: 0.7855 - val_binary_accuracy: 0.7959\n",
      "Epoch 963/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7481 - binary_accuracy: 0.7972 - val_loss: 0.7854 - val_binary_accuracy: 0.7958\n",
      "Epoch 964/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7359 - binary_accuracy: 0.8066 - val_loss: 0.7854 - val_binary_accuracy: 0.7958\n",
      "Epoch 965/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7493 - binary_accuracy: 0.7982 - val_loss: 0.7854 - val_binary_accuracy: 0.7958\n",
      "Epoch 966/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7660 - binary_accuracy: 0.7845 - val_loss: 0.7854 - val_binary_accuracy: 0.7958\n",
      "Epoch 967/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.7440 - binary_accuracy: 0.8024 - val_loss: 0.7854 - val_binary_accuracy: 0.7959\n",
      "Epoch 968/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7276 - binary_accuracy: 0.8135 - val_loss: 0.7854 - val_binary_accuracy: 0.7959\n",
      "Epoch 969/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7475 - binary_accuracy: 0.7992 - val_loss: 0.7854 - val_binary_accuracy: 0.7959\n",
      "Epoch 970/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7427 - binary_accuracy: 0.8022 - val_loss: 0.7854 - val_binary_accuracy: 0.7959\n",
      "Epoch 971/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7593 - binary_accuracy: 0.7883 - val_loss: 0.7854 - val_binary_accuracy: 0.7959\n",
      "Epoch 972/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7697 - binary_accuracy: 0.7824 - val_loss: 0.7854 - val_binary_accuracy: 0.7959\n",
      "Epoch 973/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7714 - binary_accuracy: 0.7805 - val_loss: 0.7853 - val_binary_accuracy: 0.7958\n",
      "Epoch 974/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7430 - binary_accuracy: 0.8018 - val_loss: 0.7853 - val_binary_accuracy: 0.7959\n",
      "Epoch 975/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7340 - binary_accuracy: 0.8085 - val_loss: 0.7853 - val_binary_accuracy: 0.7959\n",
      "Epoch 976/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7453 - binary_accuracy: 0.8007 - val_loss: 0.7853 - val_binary_accuracy: 0.7959\n",
      "Epoch 977/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7345 - binary_accuracy: 0.8090 - val_loss: 0.7853 - val_binary_accuracy: 0.7959\n",
      "Epoch 978/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7384 - binary_accuracy: 0.8059 - val_loss: 0.7853 - val_binary_accuracy: 0.7959\n",
      "Epoch 979/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7509 - binary_accuracy: 0.7949 - val_loss: 0.7853 - val_binary_accuracy: 0.7959\n",
      "Epoch 980/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7353 - binary_accuracy: 0.8085 - val_loss: 0.7853 - val_binary_accuracy: 0.7959\n",
      "Epoch 981/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7407 - binary_accuracy: 0.8025 - val_loss: 0.7853 - val_binary_accuracy: 0.7959\n",
      "Epoch 982/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7313 - binary_accuracy: 0.8105 - val_loss: 0.7853 - val_binary_accuracy: 0.7959\n",
      "Epoch 983/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7346 - binary_accuracy: 0.8077 - val_loss: 0.7852 - val_binary_accuracy: 0.7959\n",
      "Epoch 984/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7598 - binary_accuracy: 0.7884 - val_loss: 0.7852 - val_binary_accuracy: 0.7958\n",
      "Epoch 985/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7547 - binary_accuracy: 0.7909 - val_loss: 0.7852 - val_binary_accuracy: 0.7958\n",
      "Epoch 986/1000\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.7510 - binary_accuracy: 0.7966 - val_loss: 0.7852 - val_binary_accuracy: 0.7959\n",
      "Epoch 987/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7326 - binary_accuracy: 0.8104 - val_loss: 0.7852 - val_binary_accuracy: 0.7959\n",
      "Epoch 988/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7577 - binary_accuracy: 0.7909 - val_loss: 0.7852 - val_binary_accuracy: 0.7959\n",
      "Epoch 989/1000\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7631 - binary_accuracy: 0.7857 - val_loss: 0.7852 - val_binary_accuracy: 0.7959\n",
      "Epoch 990/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.7652 - binary_accuracy: 0.7842 - val_loss: 0.7852 - val_binary_accuracy: 0.7959\n",
      "Epoch 991/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7413 - binary_accuracy: 0.8038 - val_loss: 0.7852 - val_binary_accuracy: 0.7959\n",
      "Epoch 992/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7540 - binary_accuracy: 0.7921 - val_loss: 0.7852 - val_binary_accuracy: 0.7959\n",
      "Epoch 993/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7491 - binary_accuracy: 0.7972 - val_loss: 0.7851 - val_binary_accuracy: 0.7959\n",
      "Epoch 994/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7319 - binary_accuracy: 0.8105 - val_loss: 0.7851 - val_binary_accuracy: 0.7959\n",
      "Epoch 995/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.7103 - binary_accuracy: 0.8274 - val_loss: 0.7851 - val_binary_accuracy: 0.7959\n",
      "Epoch 996/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7514 - binary_accuracy: 0.7952 - val_loss: 0.7851 - val_binary_accuracy: 0.7959\n",
      "Epoch 997/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7653 - binary_accuracy: 0.7844 - val_loss: 0.7851 - val_binary_accuracy: 0.7959\n",
      "Epoch 998/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7633 - binary_accuracy: 0.7845 - val_loss: 0.7851 - val_binary_accuracy: 0.7959\n",
      "Epoch 999/1000\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.7431 - binary_accuracy: 0.8023 - val_loss: 0.7851 - val_binary_accuracy: 0.7959\n",
      "Epoch 1000/1000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.7554 - binary_accuracy: 0.7916 - val_loss: 0.7851 - val_binary_accuracy: 0.7959\n"
     ]
    }
   ],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history3 = FNN_MFCC_y_pt.fit(X_train, y_train, epochs=1000, verbose=1, validation_split=0.3, callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "70b6b3e7-3c24-4d65-bb79-271bfa44db39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history3.history['loss'])\n",
    "plt.plot(history3.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ed8a70f3-f00e-42b3-aef1-dfec909d63df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step - loss: 0.7926 - binary_accuracy: 0.7928\n",
      "Train Accuracy: 0.8005\n",
      "Test Accuracy: 0.7928\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the network\n",
    "train_accuracy = history3.history[\"binary_accuracy\"][-1]\n",
    "result = FNN_MFCC_y_pt.evaluate(X_test,y_test, verbose=1)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {result[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c2b2da4a-58f1-448b-80a5-ebe2a23967b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 30, 512)           50176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 30, 512)           2048      \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 30, 128)           65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 30, 128)           512       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 30, 32)            4128      \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 30, 1)             33        \n",
      "=================================================================\n",
      "Total params: 122,561\n",
      "Trainable params: 121,281\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "FNN_MFCC_y_pt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "469ec051-9bb7-47ef-b6ff-81fd85137291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/jmd/Documents/BOOTCAMP/Capstone/neural_nets/FFN_MFCC_with_patient/assets\n"
     ]
    }
   ],
   "source": [
    "#saving model\n",
    "FNN_MFCC_y_pt.save('/Users/jmd/Documents/BOOTCAMP/Capstone/neural_nets/FFN_MFCC_with_patient')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb5530-f2d6-41a4-a2bb-81f9c6c83398",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a678c-28ed-4c28-a89a-087ce31f4911",
   "metadata": {},
   "source": [
    "## Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a7d4f-334c-4d59-a508-f973e5d66398",
   "metadata": {},
   "source": [
    "How to Approach the Problem:\n",
    "- Current plan:\n",
    "    - Intend to initially fit an RNN to the raw, unpadded signal data and see how it fares. \n",
    "    - Also fit a CNN to the MFCC data and see how that fares\n",
    "    - Stack the outputs of those two with a third CNN that incorporates the patient information provided in the annotations.\n",
    "    \n",
    "- Questions:\n",
    "    - Does this plan make sense?\n",
    "    - How should I go about optimizing my parameters & deciding on network architecture?\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe780c9-7376-4527-a39c-d3fcc4f73f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use glob to extract files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9948ec37-188b-4517-9269-cb3d0009afbb",
   "metadata": {},
   "source": [
    "- do LTSM\n",
    "- 1D CNN \n",
    "\n",
    "\n",
    "- Trim sampling rate to 25% of what it is now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17b860-22e8-4f23-8ce8-bc9a78b770cb",
   "metadata": {},
   "source": [
    "RNN approach, concatenate patient information into a 1D vector to feed into the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd6b67a-684d-4de7-a077-c90258f852df",
   "metadata": {},
   "source": [
    "Look into an ensemble/aggregation model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571ec269-646a-49b6-a94a-508293e05a59",
   "metadata": {},
   "source": [
    "Can incorporate patient info into CNN as well, just need to pad the vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d4ba38-bc99-41d2-8b90-5e4937238320",
   "metadata": {},
   "source": [
    "Look into training accelerometer data on LTSMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862d579-7513-41e4-abb9-94fc2c4048a5",
   "metadata": {},
   "source": [
    "Look into varying model hyperparameters based on frequency of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58bc140-3c6b-4531-a391-e01ecbe2eba9",
   "metadata": {},
   "source": [
    "Look into example architectures for CNN that are used on MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc28a8-bba7-4301-b012-83f5b40b9d2a",
   "metadata": {},
   "source": [
    "make sure to train a dumb feed forward model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6875a0b4-bd38-4ecc-af0f-f18ef89700ae",
   "metadata": {},
   "source": [
    "Try 1024 for an input layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e9a1d0-4b1e-4053-b82c-ac256170e850",
   "metadata": {},
   "source": [
    "1. Train a simple feed forward on the padded and transformed data. \n",
    "- MFCC data with patient demo info into feed forward. \n",
    "2. RNN, with patient info\n",
    "- First train without, then train with. \n",
    "3. CNN on MFCCs with patient info. \n",
    "- First train out, then train with. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
