{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd743c3a-b8bc-468f-8f78-4ab54e3d8fc6",
   "metadata": {},
   "source": [
    "# Building Out Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7256b53-7263-4e5a-a336-d76a4e11eb39",
   "metadata": {},
   "source": [
    "Author: Jake Dumbauld <br>\n",
    "Contact: jacobmilodumbauld@gmail.com<br>\n",
    "Date: 3.15.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ea0fc5-2e66-449a-aaa3-4272ce8da2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8546b-7f82-459c-af06-d5f2babf6370",
   "metadata": {},
   "source": [
    "Defining a Helper Function to Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f9de6d-c204-42ad-a9b7-bfd3e2fe02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_CF(cf_matrix):\n",
    "    \"\"\"\n",
    "    Takes an input confusion matrix as an NP array and returns a seaborn heatmap plot with labels.\n",
    "    \"\"\"\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cf_matrix.flatten()]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcadcee6-443d-4253-9220-74236a1b0ee4",
   "metadata": {},
   "source": [
    "Defining Function to Train Models Iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9cf9bf8-6677-4493-a497-5f12010cf6f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_n_trials(n, config_path, initial_learning_rate):\n",
    "    \"\"\"\n",
    "    Trains a keras model from a given architecture specified at the `config_path` n times. Tracks train_accs, val_accs, test_accs, and generates a running confusion matrix across all trials.\n",
    "    \n",
    "    n: number of times to train the model\n",
    "    config_path: filepath to a saved neural network\n",
    "    initial_learning_rate: initial learning rate for the model to be used in the lr_schedule.\n",
    "    \"\"\"\n",
    "    \n",
    "    #loading in optimal model configuration from my model search\n",
    "    best_config = keras.models.load_model(config_path).get_config()\n",
    "\n",
    "    #defining learning rate\n",
    "    lr_schedule = keras.optimizers.schedules.InverseTimeDecay(\n",
    "                  #initial learning rate copied from model search.\n",
    "                  initial_learning_rate=initial_learning_rate,\n",
    "                  decay_steps=1.0,\n",
    "                  decay_rate=0.1\n",
    "    )\n",
    "\n",
    "    #defining a blank confusion matrix to keep a running total\n",
    "    final_cf = np.zeros((2,2), np.int32)\n",
    "    #defining a lists for other metrics of interest\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    for i in range(0,n):\n",
    "        print(\"Trial \" + str(i+1) + \"/30 Begin\")\n",
    "        model = keras.Sequential.from_config(best_config)\n",
    "\n",
    "        model.compile(\n",
    "            #Optimizer\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            #Loss\n",
    "            loss=keras.losses.BinaryCrossentropy(),\n",
    "            #Metrics\n",
    "            metrics=[keras.metrics.BinaryAccuracy()]\n",
    "        )\n",
    "        #training model with an early stopping callback\n",
    "        es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, callbacks=(es_callback))\n",
    "\n",
    "        #appending training accuracy\n",
    "        train_accs.append(history.history[\"binary_accuracy\"][-1])\n",
    "        #appending validation accuracy\n",
    "        val_accs.append(history.history[\"val_binary_accuracy\"][-1])\n",
    "        \n",
    "        print(\"Evaluating Model \" + str(i+1))\n",
    "        \n",
    "        #appending test accuracy\n",
    "        test_accs.append(model.evaluate(X_test,y_test)[1])\n",
    "        #adding running totals to the overall confusion matrix\n",
    "        y_pred= (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "        cf_matrix = tf.math.confusion_matrix(labels=y_test, predictions=y_pred).numpy()\n",
    "        final_cf += cf_matrix\n",
    "\n",
    "        #necessary to avoid memory issues from iteratively training kears models that I read about online.\n",
    "        backend.clear_session()\n",
    "        #clearing output text after each trial to avoid screen vomit\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    return final_cf, train_accs, val_accs, test_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1cbc4-d705-4ece-b391-818e2ea28211",
   "metadata": {},
   "source": [
    "Importantly - NOT setting random seed here. I want to ensure that there is some randomness in the training process to demonstrate the robustness of my output models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe34c3f-b31d-40d5-840c-d639d89c4cfc",
   "metadata": {},
   "source": [
    "Defining the Model From the Best HPs found in Model Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad177b7-411a-4469-89d6-6ded76869041",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13/30 Begin\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 7s 150ms/step - loss: 0.6575 - binary_accuracy: 0.7388 - val_loss: 0.4707 - val_binary_accuracy: 0.7959\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 7s 142ms/step - loss: 0.4801 - binary_accuracy: 0.7909 - val_loss: 0.4570 - val_binary_accuracy: 0.8054\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 0.4596 - binary_accuracy: 0.8089 - val_loss: 0.4529 - val_binary_accuracy: 0.8149\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.4464 - binary_accuracy: 0.8103 - val_loss: 0.4552 - val_binary_accuracy: 0.8228\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 7s 149ms/step - loss: 0.4323 - binary_accuracy: 0.8390 - val_loss: 0.4440 - val_binary_accuracy: 0.8149\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.4300 - binary_accuracy: 0.8284 - val_loss: 0.4494 - val_binary_accuracy: 0.8101\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 7s 150ms/step - loss: 0.4316 - binary_accuracy: 0.8264 - val_loss: 0.4493 - val_binary_accuracy: 0.8101\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 7s 153ms/step - loss: 0.4444 - binary_accuracy: 0.8157 - val_loss: 0.4407 - val_binary_accuracy: 0.8133\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 7s 146ms/step - loss: 0.4609 - binary_accuracy: 0.8147 - val_loss: 0.4422 - val_binary_accuracy: 0.8180\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 7s 150ms/step - loss: 0.4173 - binary_accuracy: 0.8312 - val_loss: 0.4377 - val_binary_accuracy: 0.8180\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 7s 143ms/step - loss: 0.4240 - binary_accuracy: 0.8352 - val_loss: 0.4374 - val_binary_accuracy: 0.8244\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 0.4121 - binary_accuracy: 0.8348 - val_loss: 0.4364 - val_binary_accuracy: 0.8244\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 7s 145ms/step - loss: 0.3900 - binary_accuracy: 0.8555 - val_loss: 0.4447 - val_binary_accuracy: 0.8212\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.4075 - binary_accuracy: 0.8501 - val_loss: 0.4381 - val_binary_accuracy: 0.8180\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 7s 146ms/step - loss: 0.4328 - binary_accuracy: 0.8256 - val_loss: 0.4373 - val_binary_accuracy: 0.8212\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 7s 143ms/step - loss: 0.4326 - binary_accuracy: 0.8233 - val_loss: 0.4351 - val_binary_accuracy: 0.8259\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.4249 - binary_accuracy: 0.8274 - val_loss: 0.4349 - val_binary_accuracy: 0.8259\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 7s 149ms/step - loss: 0.4080 - binary_accuracy: 0.8421 - val_loss: 0.4394 - val_binary_accuracy: 0.8228\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 7s 145ms/step - loss: 0.4290 - binary_accuracy: 0.8319 - val_loss: 0.4346 - val_binary_accuracy: 0.8244\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 7s 142ms/step - loss: 0.4413 - binary_accuracy: 0.8179 - val_loss: 0.4343 - val_binary_accuracy: 0.8244\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.3865 - binary_accuracy: 0.8469 - val_loss: 0.4341 - val_binary_accuracy: 0.8259\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 7s 150ms/step - loss: 0.4193 - binary_accuracy: 0.8404 - val_loss: 0.4338 - val_binary_accuracy: 0.8244\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 7s 162ms/step - loss: 0.4201 - binary_accuracy: 0.8315 - val_loss: 0.4336 - val_binary_accuracy: 0.8244\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 7s 152ms/step - loss: 0.4269 - binary_accuracy: 0.8331 - val_loss: 0.4333 - val_binary_accuracy: 0.8259\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 7s 154ms/step - loss: 0.4004 - binary_accuracy: 0.8450 - val_loss: 0.4341 - val_binary_accuracy: 0.8275\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 7s 157ms/step - loss: 0.4105 - binary_accuracy: 0.8348 - val_loss: 0.4334 - val_binary_accuracy: 0.8291\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 7s 149ms/step - loss: 0.3966 - binary_accuracy: 0.8535 - val_loss: 0.4332 - val_binary_accuracy: 0.8228\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 7s 153ms/step - loss: 0.4110 - binary_accuracy: 0.8365 - val_loss: 0.4336 - val_binary_accuracy: 0.8275\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 7s 146ms/step - loss: 0.4085 - binary_accuracy: 0.8460 - val_loss: 0.4328 - val_binary_accuracy: 0.8275\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 7s 157ms/step - loss: 0.4163 - binary_accuracy: 0.8372 - val_loss: 0.4333 - val_binary_accuracy: 0.8259\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 7s 150ms/step - loss: 0.3861 - binary_accuracy: 0.8562 - val_loss: 0.4350 - val_binary_accuracy: 0.8259\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 7s 160ms/step - loss: 0.3904 - binary_accuracy: 0.8527 - val_loss: 0.4323 - val_binary_accuracy: 0.8244\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 7s 149ms/step - loss: 0.4108 - binary_accuracy: 0.8403 - val_loss: 0.4323 - val_binary_accuracy: 0.8259\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.3881 - binary_accuracy: 0.8493 - val_loss: 0.4321 - val_binary_accuracy: 0.8275\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 7s 152ms/step - loss: 0.3938 - binary_accuracy: 0.8481 - val_loss: 0.4319 - val_binary_accuracy: 0.8244\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 7s 149ms/step - loss: 0.4183 - binary_accuracy: 0.8359 - val_loss: 0.4331 - val_binary_accuracy: 0.8275\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 7s 145ms/step - loss: 0.4068 - binary_accuracy: 0.8393 - val_loss: 0.4318 - val_binary_accuracy: 0.8259\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 7s 154ms/step - loss: 0.3834 - binary_accuracy: 0.8528 - val_loss: 0.4315 - val_binary_accuracy: 0.8259\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.4023 - binary_accuracy: 0.8451 - val_loss: 0.4322 - val_binary_accuracy: 0.8228\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 0.4086 - binary_accuracy: 0.8440 - val_loss: 0.4315 - val_binary_accuracy: 0.8244\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 7s 154ms/step - loss: 0.4129 - binary_accuracy: 0.8380 - val_loss: 0.4318 - val_binary_accuracy: 0.8275\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 7s 151ms/step - loss: 0.4179 - binary_accuracy: 0.8318 - val_loss: 0.4363 - val_binary_accuracy: 0.8244\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 7s 152ms/step - loss: 0.4206 - binary_accuracy: 0.8332 - val_loss: 0.4328 - val_binary_accuracy: 0.8259\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 7s 153ms/step - loss: 0.3842 - binary_accuracy: 0.8540 - val_loss: 0.4312 - val_binary_accuracy: 0.8259\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 0.3937 - binary_accuracy: 0.8495 - val_loss: 0.4315 - val_binary_accuracy: 0.8307\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 7s 153ms/step - loss: 0.3978 - binary_accuracy: 0.8483 - val_loss: 0.4316 - val_binary_accuracy: 0.8307\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 0.4008 - binary_accuracy: 0.8504 - val_loss: 0.4320 - val_binary_accuracy: 0.8339\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 0.4017 - binary_accuracy: 0.8405 - val_loss: 0.4309 - val_binary_accuracy: 0.8275\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 7s 151ms/step - loss: 0.4328 - binary_accuracy: 0.8278 - val_loss: 0.4324 - val_binary_accuracy: 0.8259\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 0.4310 - binary_accuracy: 0.8252 - val_loss: 0.4310 - val_binary_accuracy: 0.8244\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.3933 - binary_accuracy: 0.8475 - val_loss: 0.4313 - val_binary_accuracy: 0.8323\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 0.4011 - binary_accuracy: 0.8522 - val_loss: 0.4306 - val_binary_accuracy: 0.8275\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 7s 146ms/step - loss: 0.3764 - binary_accuracy: 0.8568 - val_loss: 0.4317 - val_binary_accuracy: 0.8323\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.4198 - binary_accuracy: 0.8313 - val_loss: 0.4319 - val_binary_accuracy: 0.8244\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 0.4264 - binary_accuracy: 0.8364 - val_loss: 0.4312 - val_binary_accuracy: 0.8323\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 0.3898 - binary_accuracy: 0.8541 - val_loss: 0.4316 - val_binary_accuracy: 0.8354\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 7s 145ms/step - loss: 0.4006 - binary_accuracy: 0.8473 - val_loss: 0.4304 - val_binary_accuracy: 0.8275\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 0.3589 - binary_accuracy: 0.8613 - val_loss: 0.4308 - val_binary_accuracy: 0.8323\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 7s 146ms/step - loss: 0.3886 - binary_accuracy: 0.8574 - val_loss: 0.4311 - val_binary_accuracy: 0.8323\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 7s 143ms/step - loss: 0.4025 - binary_accuracy: 0.8380 - val_loss: 0.4307 - val_binary_accuracy: 0.8228\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 0.3956 - binary_accuracy: 0.8493 - val_loss: 0.4303 - val_binary_accuracy: 0.8307\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 7s 146ms/step - loss: 0.3905 - binary_accuracy: 0.8447 - val_loss: 0.4311 - val_binary_accuracy: 0.8323\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 7s 145ms/step - loss: 0.4084 - binary_accuracy: 0.8417 - val_loss: 0.4302 - val_binary_accuracy: 0.8307\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 7s 142ms/step - loss: 0.3937 - binary_accuracy: 0.8496 - val_loss: 0.4301 - val_binary_accuracy: 0.8307\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 7s 143ms/step - loss: 0.3981 - binary_accuracy: 0.8462 - val_loss: 0.4300 - val_binary_accuracy: 0.8307\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 7s 145ms/step - loss: 0.4002 - binary_accuracy: 0.8410 - val_loss: 0.4300 - val_binary_accuracy: 0.8323\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 7s 143ms/step - loss: 0.3886 - binary_accuracy: 0.8504 - val_loss: 0.4301 - val_binary_accuracy: 0.8307\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 7s 156ms/step - loss: 0.3951 - binary_accuracy: 0.8516 - val_loss: 0.4299 - val_binary_accuracy: 0.8307\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 7s 145ms/step - loss: 0.4014 - binary_accuracy: 0.8420 - val_loss: 0.4299 - val_binary_accuracy: 0.8307\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 7s 156ms/step - loss: 0.3955 - binary_accuracy: 0.8436 - val_loss: 0.4300 - val_binary_accuracy: 0.8307\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 7s 145ms/step - loss: 0.4007 - binary_accuracy: 0.8420 - val_loss: 0.4298 - val_binary_accuracy: 0.8307\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 7s 144ms/step - loss: 0.3928 - binary_accuracy: 0.8438 - val_loss: 0.4299 - val_binary_accuracy: 0.8307\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.3958 - binary_accuracy: 0.8499 - val_loss: 0.4298 - val_binary_accuracy: 0.8307\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 0.3869 - binary_accuracy: 0.8453 - val_loss: 0.4301 - val_binary_accuracy: 0.8323\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.3806 - binary_accuracy: 0.8549 - val_loss: 0.4299 - val_binary_accuracy: 0.8323\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 7s 143ms/step - loss: 0.3865 - binary_accuracy: 0.8533 - val_loss: 0.4298 - val_binary_accuracy: 0.8307\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 7s 142ms/step - loss: 0.3777 - binary_accuracy: 0.8519 - val_loss: 0.4300 - val_binary_accuracy: 0.8323\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 7s 154ms/step - loss: 0.4091 - binary_accuracy: 0.8378 - val_loss: 0.4296 - val_binary_accuracy: 0.8323\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.3930 - binary_accuracy: 0.8436 - val_loss: 0.4303 - val_binary_accuracy: 0.8354\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 7s 149ms/step - loss: 0.4142 - binary_accuracy: 0.8338 - val_loss: 0.4296 - val_binary_accuracy: 0.8307\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 0.3944 - binary_accuracy: 0.8470 - val_loss: 0.4297 - val_binary_accuracy: 0.8307\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.3794 - binary_accuracy: 0.8546 - val_loss: 0.4296 - val_binary_accuracy: 0.8307\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 7s 151ms/step - loss: 0.4113 - binary_accuracy: 0.8401 - val_loss: 0.4295 - val_binary_accuracy: 0.8307\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 7s 152ms/step - loss: 0.3799 - binary_accuracy: 0.8554 - val_loss: 0.4300 - val_binary_accuracy: 0.8323\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 7s 152ms/step - loss: 0.3865 - binary_accuracy: 0.8521 - val_loss: 0.4300 - val_binary_accuracy: 0.8323\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 7s 150ms/step - loss: 0.3802 - binary_accuracy: 0.8539 - val_loss: 0.4296 - val_binary_accuracy: 0.8323\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 7s 154ms/step - loss: 0.4059 - binary_accuracy: 0.8450 - val_loss: 0.4295 - val_binary_accuracy: 0.8323\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 7s 154ms/step - loss: 0.3866 - binary_accuracy: 0.8585 - val_loss: 0.4295 - val_binary_accuracy: 0.8323\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.3831 - binary_accuracy: 0.8542 - val_loss: 0.4294 - val_binary_accuracy: 0.8307\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 7s 145ms/step - loss: 0.4078 - binary_accuracy: 0.8367 - val_loss: 0.4295 - val_binary_accuracy: 0.8323\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 7s 145ms/step - loss: 0.3920 - binary_accuracy: 0.8531 - val_loss: 0.4294 - val_binary_accuracy: 0.8323\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.3712 - binary_accuracy: 0.8670 - val_loss: 0.4300 - val_binary_accuracy: 0.8354\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 7s 147ms/step - loss: 0.3627 - binary_accuracy: 0.8664 - val_loss: 0.4304 - val_binary_accuracy: 0.8370\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 0.3988 - binary_accuracy: 0.8378 - val_loss: 0.4293 - val_binary_accuracy: 0.8307\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 7s 152ms/step - loss: 0.3774 - binary_accuracy: 0.8519 - val_loss: 0.4295 - val_binary_accuracy: 0.8323\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 7s 149ms/step - loss: 0.3646 - binary_accuracy: 0.8637 - val_loss: 0.4295 - val_binary_accuracy: 0.8323\n",
      "Epoch 97/100\n",
      " 8/46 [====>.........................] - ETA: 4s - loss: 0.3686 - binary_accuracy: 0.8605"
     ]
    }
   ],
   "source": [
    "#loading in and reshaping data to train model\n",
    "X = np.load('/Users/jmd/Documents/BOOTCAMP/Capstone/arrays/MFCCs_withPatient.npy', allow_pickle=True)\n",
    "y = np.load('/Users/jmd/Documents/BOOTCAMP/Capstone/arrays/target_array.npy', allow_pickle=True)\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = 0.3)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.3)\n",
    "\n",
    "#training model 30 times, randomly initializing each time. \n",
    "CNN_MFCC_w_cf, CNN_MFCC_w_train_accs, CNN_MFCC_w_val_accs, CNN_MFCC_w_test_accs = model_n_trials(30, \n",
    "                                                                                                 '/Users/jmd/Documents/BOOTCAMP/Capstone/neural_nets/CNN_MFCCs_with_patient',\n",
    "                                                                                                 0.00020681360209481224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248695b1-81a7-4d1e-87ae-b7dee86b474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing by thirty to generate averages for the 30 trials run above. \n",
    "plot_CF(CNN_MFCC_final_cf/30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
