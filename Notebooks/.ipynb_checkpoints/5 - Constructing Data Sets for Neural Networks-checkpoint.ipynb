{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ca53ac0-c6d8-4fe5-b915-52a7f3ac6613",
   "metadata": {},
   "source": [
    "# Constructing Data Sets for Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8f4f5b-01d6-42cd-9bd2-b8b08dde84bc",
   "metadata": {},
   "source": [
    "Author: Jake Dumbauld <br>\n",
    "Contact: jacobmilodumbauld@gmail.com<br>\n",
    "Date: 3.15.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26531292-4883-44ea-869f-cc6ef3045131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import os\n",
    "from random import uniform\n",
    "import time\n",
    "\n",
    "#options\n",
    "pd.set_option('display.max_columns', None) #making sure I can see all my columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbddd3f-c18e-4435-b0c2-4144b589757a",
   "metadata": {},
   "source": [
    "Picking up from my df created in `2 - Importing Signal Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec62ff3-0e23-4ded-9efa-6d9fa6d9db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = np.load('/Users/jmd/Documents/BOOTCAMP/Capstone/arrays/patient_signals_4k.npy', allow_pickle=True),\n",
    "                       columns=(['Patient ID', 'Locations', 'Age', 'Sex', 'Height', 'Weight',\n",
    "                                 'Pregnancy status', 'Murmur', 'Murmur locations',\n",
    "                                 'Most audible location', 'Systolic murmur timing',\n",
    "                                 'Systolic murmur shape', 'Systolic murmur grading',\n",
    "                                 'Systolic murmur pitch', 'Systolic murmur quality',\n",
    "                                 'Diastolic murmur timing', 'Diastolic murmur shape',\n",
    "                                 'Diastolic murmur grading', 'Diastolic murmur pitch',\n",
    "                                 'Diastolic murmur quality', 'Campaign', 'Additional ID',\n",
    "                                 'location_count', 'signal_patient_id', 'location', 'signal']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da32c74-a0a0-4eac-8b2e-5b379bcbdfb8",
   "metadata": {},
   "source": [
    "## Dropping duplicated or unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb3fae4-a131-4e6a-ab88-5c15958ec16d",
   "metadata": {},
   "source": [
    "Here I am opting to drop all columns qualifying and grading the murmr. Reason being is that in the field, ideally this model would be deployed with inputs of the signal data itself, and then the demographic information like age, sex, height, weight, and pregnancy status. This information will be useful in the future when evaluating the type of murmurs most misclassified, but right now I am generating my model data sets and thus will be dropping it. </br>\n",
    "\n",
    "Additionally, `Additional_ID` is a reference to another ID in the table, if a patient participated in the study in 2 different campaigns. I will also be dropping this column as I expect the variability in the patients heart rate & sounds from day to day will be enough to avoid problems of multicollinearity if I choose to train any simple models on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f40362-f72e-4044-bdd2-bc51d4695aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Patient ID', 'Locations', 'Age', 'Sex', 'Height', 'Weight',\n",
       "       'Pregnancy status', 'Murmur', 'Murmur locations',\n",
       "       'Most audible location', 'Systolic murmur timing',\n",
       "       'Systolic murmur shape', 'Systolic murmur grading',\n",
       "       'Systolic murmur pitch', 'Systolic murmur quality',\n",
       "       'Diastolic murmur timing', 'Diastolic murmur shape',\n",
       "       'Diastolic murmur grading', 'Diastolic murmur pitch',\n",
       "       'Diastolic murmur quality', 'Campaign', 'Additional ID',\n",
       "       'location_count', 'signal_patient_id', 'location', 'signal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ecce9a9-3d9f-4886-aa52-72dfb2cad1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Locations','signal_patient_id', 'Murmur locations',\n",
    "                   'Most audible location', 'Systolic murmur timing',\n",
    "                   'Systolic murmur shape', 'Systolic murmur grading',\n",
    "                   'Systolic murmur pitch', 'Systolic murmur quality',\n",
    "                   'Diastolic murmur timing', 'Diastolic murmur shape',\n",
    "                   'Diastolic murmur grading', 'Diastolic murmur pitch',\n",
    "                   'Diastolic murmur quality', 'Campaign', 'Additional ID', 'location_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01b919b9-6ce3-45f0-b220-91c45c7b852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb656e3-9b12-4773-80b2-79f1b3b0f163",
   "metadata": {},
   "source": [
    "## Binarizing Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbaba3a-a563-4d84-8b2f-05dc3354d8be",
   "metadata": {},
   "source": [
    "### Binarizing Murmurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0e4fa5-81d9-4d25-af23-b0851de29982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking to see if we have any NaN's\n",
    "df['Murmur'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f43a0f04-cd1c-4951-ada5-7e4936d0beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['Murmur'] == 'Unknown'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a6bffe8-cec4-446c-9790-eb717c598e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Absent     2391\n",
       "Present     616\n",
       "Name: Murmur, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Murmur'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc67d630-bc46-4d15-9d91-ffc926b09f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Murmur'] = df['Murmur'].map({\"Absent\": 0,\n",
    "                                 \"Present\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b85985-6eb7-49e3-a0a9-1d4379e79b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6758d6-fe67-450d-a6bc-33043bdaaada",
   "metadata": {},
   "source": [
    "### Binarizing Pregnancy Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d89e5720-a62f-47f1-8c39-6c15ced2c4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking to see if we have any NaN's\n",
    "df['Pregnancy status'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6f19e4b-7930-48e1-9110-9043c2861d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pregnancy status'] = df['Pregnancy status'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8c5d99-9860-4258-91d3-b6e1b1f315a3",
   "metadata": {},
   "source": [
    "### Binarizing Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94c833b0-1165-403b-be9e-5c6a0fafab70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking to see if we have any NaN's\n",
    "df['Sex'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9a5e755-cf8f-4daa-927a-3a1152dd8767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    1523\n",
       "Male      1484\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe911ff-2904-4ae8-9258-ec7b01db7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'] = df['Sex'].map({\"Male\": 0,\n",
    "                           \"Female\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a64220-84f7-4dd1-9415-ed0389511a13",
   "metadata": {},
   "source": [
    "### Mapping Age to Ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f53f8361-a19d-481d-a645-9e7f2bba06e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking to see if we have any NaN's\n",
    "df['Age'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf5104-21b0-42a7-bc31-d27c2786c8d7",
   "metadata": {},
   "source": [
    "Rather than imputing something potentiall incorrect, I'm going to start my map at 0 with NaN's being set at 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31c932e5-aea4-42e1-917a-ce4d51c4a7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Child          2125\n",
       "Infant          383\n",
       "Adolescent      230\n",
       "Young Adult      24\n",
       "Neonate           8\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83272ae8-024a-4aac-b524-18bcd0f609f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].map({np.nan: 0,\n",
    "                           'Neonate': 1,\n",
    "                           'Infant': 2,\n",
    "                           'Child': 3,\n",
    "                           'Adolescent': 4,\n",
    "                           'Young Adult': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee9d9b20-39b4-4a33-a3ac-8f28aaa40e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2125\n",
       "2     383\n",
       "0     237\n",
       "4     230\n",
       "5      24\n",
       "1       8\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9bc9f-e22e-4d66-988a-4a42c8b82389",
   "metadata": {},
   "source": [
    "### Dummy variables for location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a5d0cd3-bda4-46d4-8be0-06530e3ce532",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ebcc61b-4c67-4d88-934e-a7dd09eee302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46d79419-3706-4c39-b464-1f35faac1f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.pop('signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d366989-8efb-423f-b352-9e84d7713985",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_position = len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3743c4c-0487-445f-9d8d-00e456025dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(last_position, 'signal', last_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adbcd39-e392-46cb-98dd-473265fa5263",
   "metadata": {},
   "source": [
    "### Dealing with NaNs in Height/Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdbb3f4-cbf1-4ba8-99d1-5be125e2345b",
   "metadata": {},
   "source": [
    "Broad strokes - imputed with means of same sex/age groups where possible, otherwise imputed with the mean of the whole sample. For some patients, particularly those who were pregnant, lack of age information made imputation difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00445f87-b425-4ba1-8104-faed62201076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3007 entries, 0 to 3006\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Patient ID        3007 non-null   object\n",
      " 1   Age               3007 non-null   int64 \n",
      " 2   Sex               3007 non-null   int64 \n",
      " 3   Height            2663 non-null   object\n",
      " 4   Weight            2687 non-null   object\n",
      " 5   Pregnancy status  3007 non-null   int64 \n",
      " 6   Murmur            3007 non-null   int64 \n",
      " 7   location_AV       3007 non-null   uint8 \n",
      " 8   location_MV       3007 non-null   uint8 \n",
      " 9   location_PV       3007 non-null   uint8 \n",
      " 10  location_Phc      3007 non-null   uint8 \n",
      " 11  location_TV       3007 non-null   uint8 \n",
      " 12  signal            3007 non-null   object\n",
      "dtypes: int64(4), object(4), uint8(5)\n",
      "memory usage: 202.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e447530-f00a-4bae-814d-5cc08f99b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with NaN heights\n",
    "new_heights = []\n",
    "\n",
    "#iterating through heights\n",
    "for i, height in enumerate(df['Height']):\n",
    "    \n",
    "    #if the height is null \n",
    "    if (pd.isnull(height) == True):        \n",
    "        \n",
    "        #store the age and sex groups of the current patient in memory\n",
    "        age_group = df.iloc[i,1]\n",
    "        sex_group = df.iloc[i,2]\n",
    "        \n",
    "        #creating a condition that checks if age and sex are equal to the age and sex group\n",
    "        condition = (df['Age'] == age_group) & (df['Sex'] == sex_group)\n",
    "        \n",
    "        #computing the mean height of the patient group with same age and sex category\n",
    "        groups_height_mean = df[condition]['Height'].mean()\n",
    "        \n",
    "        #if that mean is null append the mean of the entire sample\n",
    "        if (pd.isnull(groups_height_mean) == True):\n",
    "            \n",
    "            new_heights.append(df['Height'].mean().round(1))\n",
    "        \n",
    "        #else append the group mean\n",
    "        else:\n",
    "            \n",
    "            new_heights.append(groups_height_mean.round(1))\n",
    "    \n",
    "    else:\n",
    "        new_heights.append(df['Height'][i])\n",
    "\n",
    "# reassigning heights with imputation.\n",
    "df['Height'] = new_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "231149f7-b099-484f-8b07-aad658b416fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with NaN weights\n",
    "new_weights = []\n",
    "\n",
    "#iterating through weights\n",
    "for i, weight in enumerate(df['Weight']):\n",
    "    \n",
    "    #if the weight is null \n",
    "    if (pd.isnull(weight) == True):        \n",
    "        \n",
    "        #store the age and sex groups of the current patient in memory\n",
    "        age_group = df.iloc[i,1]\n",
    "        sex_group = df.iloc[i,2]\n",
    "        \n",
    "        #creating a condition that checks if age and sex are equal to the age and sex group\n",
    "        condition = (df['Age'] == age_group) & (df['Sex'] == sex_group)\n",
    "        \n",
    "        #computing the mean weight of the patient group with same age and sex category\n",
    "        groups_weight_mean = df[condition]['Weight'].mean()\n",
    "        \n",
    "        #if that mean is null append the mean of the entire sample\n",
    "        if (pd.isnull(groups_weight_mean) == True):\n",
    "            \n",
    "            new_weights.append(df['Weight'].mean().round(1))\n",
    "        \n",
    "        #else append the group mean\n",
    "        else:\n",
    "            \n",
    "            new_weights.append(groups_weight_mean.round(1))\n",
    "    \n",
    "    else:\n",
    "        new_weights.append(df['Weight'][i])\n",
    "        \n",
    "# reassigning weights with imputation.\n",
    "df['Weight'] = new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14027932-8f78-41d2-9247-0832237addcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient ID          0\n",
       "Age                 0\n",
       "Sex                 0\n",
       "Height              0\n",
       "Weight              0\n",
       "Pregnancy status    0\n",
       "Murmur              0\n",
       "location_AV         0\n",
       "location_MV         0\n",
       "location_PV         0\n",
       "location_Phc        0\n",
       "location_TV         0\n",
       "signal              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2012f03f-6a5e-4f55-bd39-699ebd7e6ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Pregnancy status</th>\n",
       "      <th>Murmur</th>\n",
       "      <th>location_AV</th>\n",
       "      <th>location_MV</th>\n",
       "      <th>location_PV</th>\n",
       "      <th>location_Phc</th>\n",
       "      <th>location_TV</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2530</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.07682987, 0.06061038, 0.039170958, 0.048250...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2530</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.01187718, 0.029969877, 0.01927742, -0.0206...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2530</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.37442628, 0.32439327, 0.095518045, -0.06558...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2530</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.06770988, 0.073658854, 0.072224066, 0.08253...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9979</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.15039496, 0.18560724, 0.17212218, 0.1603406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>85345</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.03814805, 0.06008572, 0.03808801, -0.008758...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>85345</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0061015976, 0.029588033, 0.020953469, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>85349</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115.9</td>\n",
       "      <td>25.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.00026825635, 0.0034792388, 0.014762115, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>85349</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115.9</td>\n",
       "      <td>25.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1387334, 0.08302983, 0.13867667, -0.0078439...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>85349</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115.9</td>\n",
       "      <td>25.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.20991552, 0.118048884, -0.0015913057, 0.006...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3007 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Patient ID  Age  Sex  Height  Weight  Pregnancy status  Murmur  \\\n",
       "0          2530    3    1    98.0    15.9                 0       0   \n",
       "1          2530    3    1    98.0    15.9                 0       0   \n",
       "2          2530    3    1    98.0    15.9                 0       0   \n",
       "3          2530    3    1    98.0    15.9                 0       0   \n",
       "4          9979    3    1   103.0    13.1                 0       1   \n",
       "...         ...  ...  ...     ...     ...               ...     ...   \n",
       "3002      85345    3    1   132.0    38.1                 0       0   \n",
       "3003      85345    3    1   132.0    38.1                 0       0   \n",
       "3004      85349    0    1   115.9    25.1                 1       0   \n",
       "3005      85349    0    1   115.9    25.1                 1       0   \n",
       "3006      85349    0    1   115.9    25.1                 1       0   \n",
       "\n",
       "      location_AV  location_MV  location_PV  location_Phc  location_TV  \\\n",
       "0               0            0            1             0            0   \n",
       "1               1            0            0             0            0   \n",
       "2               0            1            0             0            0   \n",
       "3               0            0            0             0            1   \n",
       "4               0            1            0             0            0   \n",
       "...           ...          ...          ...           ...          ...   \n",
       "3002            1            0            0             0            0   \n",
       "3003            0            0            1             0            0   \n",
       "3004            1            0            0             0            0   \n",
       "3005            0            0            1             0            0   \n",
       "3006            0            0            0             0            1   \n",
       "\n",
       "                                                 signal  \n",
       "0     [0.07682987, 0.06061038, 0.039170958, 0.048250...  \n",
       "1     [-0.01187718, 0.029969877, 0.01927742, -0.0206...  \n",
       "2     [0.37442628, 0.32439327, 0.095518045, -0.06558...  \n",
       "3     [0.06770988, 0.073658854, 0.072224066, 0.08253...  \n",
       "4     [0.15039496, 0.18560724, 0.17212218, 0.1603406...  \n",
       "...                                                 ...  \n",
       "3002  [0.03814805, 0.06008572, 0.03808801, -0.008758...  \n",
       "3003  [-0.0061015976, 0.029588033, 0.020953469, 0.00...  \n",
       "3004  [0.00026825635, 0.0034792388, 0.014762115, -0....  \n",
       "3005  [0.1387334, 0.08302983, 0.13867667, -0.0078439...  \n",
       "3006  [0.20991552, 0.118048884, -0.0015913057, 0.006...  \n",
       "\n",
       "[3007 rows x 13 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58d90590-6058-4c4b-92cd-c000b27f9e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "murmur_array = df['Murmur'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "067b0c27-f676-46a2-b041-49622066ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/jmd/Documents/BOOTCAMP/Capstone/arrays/target_array', murmur_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574dba84-a6b4-47df-97a0-78ed4a470fa5",
   "metadata": {},
   "source": [
    "## MFCC Data w/wo Patient Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f917bd1e-fbd1-4e55-ba55-18d9990f31bb",
   "metadata": {},
   "source": [
    "### Trimming and Padding clips to 12 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb6602bc-ece2-4d6b-a02b-ce784b65ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f00ed94-c671-4dbd-a090-353e72bfdfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = df['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fb8e213-9ffc-498d-b906-f5505fcf450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for signal in signals:\n",
    "    lengths.append(len(signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6a86634-745b-4ba3-b430-6874d1984dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = pd.Series(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a62ee601-a6ea-42a5-89d7-072fa62c08c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     0.734131\n",
       "mean     22.894569\n",
       "std       7.297946\n",
       "min       5.152100\n",
       "25%      19.056152\n",
       "50%      21.488037\n",
       "75%      29.392090\n",
       "max      64.512207\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.describe() / sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cb509ee-3f67-490f-bf76-2ef2d3eca0c6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1.0\n",
      "5 1.0\n",
      "6 0.9986697705354174\n",
      "7 0.9960093116062521\n",
      "8 0.9890256069171932\n",
      "9 0.9787163285666778\n",
      "10 0.9630861323578317\n",
      "11 0.9441303624875291\n",
      "12 0.9218490189557699\n",
      "13 0.8985700033255737\n",
      "14 0.8782840039906884\n",
      "15 0.8540073162620552\n",
      "16 0.8240771533089458\n",
      "17 0.79847023611573\n",
      "18 0.7751912204855338\n",
      "19 0.7509145327569006\n",
      "20 0.6508147655470569\n",
      "21 0.5340871300299301\n",
      "22 0.4672430994346525\n",
      "23 0.4286664449617559\n",
      "24 0.40239441303624873\n",
      "25 0.3831060857998005\n",
      "26 0.36647821749251747\n",
      "27 0.3518456933821084\n",
      "28 0.32790156301962087\n",
      "29 0.28633189225141337\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 30):\n",
    "    print(i, len(lengths[lengths > (i * sr)]) / len(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77299e02-2e8e-4c68-9bcd-7794c1b64136",
   "metadata": {},
   "source": [
    "So it looks like I can work with 12 second clips. To calculate how long that series its we multiply that by the sampling rate which I declared at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80cdfc28-8d4f-4f62-aa2f-6cb626024d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49152"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_len = 12 * sr\n",
    "target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87ff1fc1-5d2d-4000-a53f-d6baac2ae17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3007, 49152)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_signals = []\n",
    "for signal in signals:\n",
    "    if len(signal) == target_len:\n",
    "        new_signals.append(signal)\n",
    "    elif len(signal) > target_len:\n",
    "        new_signals.append(signal[0:target_len])\n",
    "    elif len(signal) < target_len:\n",
    "        padwidth = target_len-len(signal)\n",
    "        new_signals.append(np.pad(signal, (0, padwidth), mode='constant'))\n",
    "    else:\n",
    "        print('wtf')\n",
    "\n",
    "new_signals = np.asarray(new_signals)\n",
    "\n",
    "new_signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3bdaf44-5cf0-477f-a8c8-ed898b0ce256",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for signal in new_signals:\n",
    "    lengths.append(len(signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4136c9b-773b-48fa-9a6d-d96a91917a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = pd.Series(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc66a287-cef1-40aa-920c-4ca87daf90cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     0.734131\n",
       "mean     12.000000\n",
       "std       0.000000\n",
       "min      12.000000\n",
       "25%      12.000000\n",
       "50%      12.000000\n",
       "75%      12.000000\n",
       "max      12.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.describe() / sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd31e5ab-af11-4002-a300-819382aad9c8",
   "metadata": {},
   "source": [
    "12 second clips, padded appropriately!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a2cc8e-9250-4769-bc9f-debb8f72315a",
   "metadata": {},
   "source": [
    "### Transforming Signal Array into MFCC Array With Patient Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a4ed6-c56f-46ab-9395-04bbef800a53",
   "metadata": {},
   "source": [
    "Declaring Variables for MFCC Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83f17863-060d-4f7d-bad1-48ced6e3b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 256\n",
    "n_mfcc = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8d8c4-d18b-460c-8e3c-91f28a6cf6ff",
   "metadata": {},
   "source": [
    "We have a very low sampling rate, and my gut tells me this problem is closer to speech recognition than music classification, so I'm going to shorten the window (`n_fft`)significantly from the default 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a200963f-717f-41f1-8cec-d4ad18ce3956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_info_to_signal(df, i, repeats):\n",
    "    '''\n",
    "    Helper function to take the patient demo info and reshape it into static signals with length equal to the \n",
    "    MFCC array it's being concatenated with.\n",
    "    '''\n",
    "    \n",
    "    demo_info = df.drop(columns=['Patient ID', 'Murmur', 'signal']).iloc[i,:].to_numpy()\n",
    "\n",
    "    demo_info = demo_info.reshape(demo_info.shape[0],1)\n",
    "\n",
    "    demo_info = np.repeat(demo_info, repeats = repeats, axis=1)\n",
    "\n",
    "    return demo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84c635bb-05e3-40df-8660-74110ebae0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3007, 30, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,len(new_signals)):\n",
    "    if i == 0:\n",
    "        \n",
    "        #defines first MFCC from row 1 and concatenates with patient info signal\n",
    "        MFCCs = librosa.feature.mfcc(y = new_signals[i], sr = sr, n_fft = n_fft, n_mfcc = n_mfcc)\n",
    "        demo_info = patient_info_to_signal(df, i, MFCCs.shape[1])\n",
    "        MFCCs_and_patient = np.concatenate((MFCCs, demo_info), axis=0)\n",
    "        \n",
    "        #defines second MFCC from row\n",
    "        MFCCs2 = librosa.feature.mfcc(y = new_signals[i+1], sr = sr, n_fft = n_fft, n_mfcc = n_mfcc)\n",
    "        demo_info = patient_info_to_signal(df, i+1, MFCCs.shape[1])\n",
    "        MFCCs2_and_patient = np.concatenate((MFCCs2, demo_info), axis=0)\n",
    "        \n",
    "        #and this is why we have this whole block. choosing to use .stack to start building the final array\n",
    "        final_patient_MFCC = np.stack((MFCCs_and_patient, MFCCs2_and_patient))\n",
    "        \n",
    "    if i == 1:\n",
    "        continue\n",
    "        \n",
    "    elif i > 1:\n",
    "        #building another MFCC & patient signal \n",
    "        MFCCs = librosa.feature.mfcc(y = new_signals[i], sr = sr, n_fft = n_fft, n_mfcc = n_mfcc) \n",
    "        demo_info = patient_info_to_signal(df, i, MFCCs.shape[1])\n",
    "        MFCCs_and_patient = np.concatenate((MFCCs, demo_info), axis=0)\n",
    "        MFCCs_and_patient = MFCCs_and_patient.reshape(1,MFCCs_and_patient.shape[0],MFCCs_and_patient.shape[1])\n",
    "        \n",
    "        #assembling the final array\n",
    "        final_patient_MFCC = np.concatenate((final_patient_MFCC, MFCCs_and_patient))\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    display(final_patient_MFCC.shape)\n",
    "    \n",
    "np.save('/Users/jmd/Documents/BOOTCAMP/Capstone/arrays/MFCCs_withPatient', final_patient_MFCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "114dec3c-d089-4785-b06e-c8ac311ae0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3007, 20, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,len(new_signals)):\n",
    "    if i == 0:\n",
    "        \n",
    "        #defines first MFCC from row 1\n",
    "        MFCCs = librosa.feature.mfcc(y = new_signals[i], sr = sr, n_fft = n_fft, n_mfcc = n_mfcc)\n",
    "        \n",
    "        #defines second MFCC from row\n",
    "        MFCCs2 = librosa.feature.mfcc(y = new_signals[i+1], sr = sr, n_fft = n_fft, n_mfcc = n_mfcc)\n",
    "        \n",
    "        #and this is why we have this whole block. choosing to use .stack to start building the final array\n",
    "        final_MFCC = np.stack((MFCCs, MFCCs2))\n",
    "        \n",
    "    if i == 1:\n",
    "        continue\n",
    "        \n",
    "    elif i > 1:\n",
    "        #building another MFCC\n",
    "        MFCCs = librosa.feature.mfcc(y = new_signals[i], sr = sr, n_fft = n_fft, n_mfcc = n_mfcc) \n",
    "        MFCCs = MFCCs.reshape(1,MFCCs.shape[0],MFCCs.shape[1])\n",
    "        \n",
    "        #assembling the final array\n",
    "        final_MFCC = np.concatenate((final_MFCC, MFCCs))\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    display(final_MFCC.shape)\n",
    "    \n",
    "np.save('/Users/jmd/Documents/BOOTCAMP/Capstone/arrays/MFCCs_noPatient', final_MFCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28689042-fc9e-4341-9dac-e2515c22789a",
   "metadata": {},
   "source": [
    "## Unprocessed signal data w/wo Patient Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be661b-e13a-480b-a043-22e6cbf30688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
