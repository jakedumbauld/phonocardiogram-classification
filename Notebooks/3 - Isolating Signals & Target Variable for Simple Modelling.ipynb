{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd56645-4834-4546-ac59-b2f4afdf6ff8",
   "metadata": {},
   "source": [
    "# Isolating Signals & Target Variable for Simple Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1be9ae-8bdd-4ef4-bb1f-d3e1118c3a5d",
   "metadata": {},
   "source": [
    "Author: Jake Dumbauld <br>\n",
    "Contact: jacobmilodumbauld@gmail.com<br>\n",
    "Date: 3.15.22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b6f929-b2d4-4d22-9f36-77ec40dd2e05",
   "metadata": {},
   "source": [
    "## Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18604439-308b-4028-ba5a-9a0605b52744",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to generate a dataset that can be fed into a handful of simple statistical models. Another important note, at the time this notebook was created I had not ran into the sampling rate problem that caused me to return to notebook 2. Thus, only the 4k sampling rate data is altered here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370804a2-3f99-4094-ad4f-6f2a8ad8b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "\n",
    "import os\n",
    "from random import uniform\n",
    "import time\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e1dee84-d065-4c17-be08-0720503cc05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Users/jmd/Documents/BOOTCAMP/Capstone/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e48b4ea-589c-4736-ae41-9de7912f39c4",
   "metadata": {},
   "source": [
    "Loading in the dataframe created in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9069d40-2bb3-47cb-8116-cfea69962e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = np.load(root_path + 'arrays/patient_signals_4k.npy', allow_pickle=True),\n",
    "                       columns=(['Patient ID', 'Locations', 'Age', 'Sex', 'Height', 'Weight',\n",
    "                                 'Pregnancy status', 'Murmur', 'Murmur locations',\n",
    "                                 'Most audible location', 'Systolic murmur timing',\n",
    "                                 'Systolic murmur shape', 'Systolic murmur grading',\n",
    "                                 'Systolic murmur pitch', 'Systolic murmur quality',\n",
    "                                 'Diastolic murmur timing', 'Diastolic murmur shape',\n",
    "                                 'Diastolic murmur grading', 'Diastolic murmur pitch',\n",
    "                                 'Diastolic murmur quality', 'Campaign', 'Additional ID',\n",
    "                                 'location_count', 'signal_patient_id', 'location', 'signal']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ad32e-18e0-429d-9cc0-a1467c177592",
   "metadata": {},
   "source": [
    "Defining my sampling rate to be used throughout this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6d9ef08-2d9b-4d3f-86e5-2240eebb1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 4096"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b74f8c-62bc-445b-af4b-6415243d8776",
   "metadata": {},
   "source": [
    "## Binarizing Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766bcd5b-8809-4800-a54d-4730f848a6e9",
   "metadata": {},
   "source": [
    "To feed this information into a simple statistical model, I need convert the strings in the `patient_info` df into something machine readable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a788af-3fb3-4c9b-a408-f48c6150b368",
   "metadata": {},
   "source": [
    "#### Dropping Unknown Murmurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fab8b61-df72-43e8-ba72-84554498db1c",
   "metadata": {},
   "source": [
    "In this dataset, there were 156 audio files for which the listener was unsure if there was a murmur, about 5% of the dataset. Since I'm setting up for a supervised learning process in which the purpose is to develop models that can predict a binary target, I decided to drop these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4dd767-ad46-4684-b630-4e464ee9bd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3163, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900baed9-8162-4b0c-b7fd-7c1768596c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Absent     2391\n",
       "Present     616\n",
       "Unknown     156\n",
       "Name: Murmur, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Murmur'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df390224-770e-4c30-a86f-77b8a3ee4403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['Murmur'] == 'Unknown'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7cf085b-071b-4fe1-a736-7b736f15360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49614adc-abc2-4052-8ba5-fce248344bfd",
   "metadata": {},
   "source": [
    "#### Binarizing Murmurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6132541-b3f7-4684-abb1-02f00c905afe",
   "metadata": {},
   "source": [
    "Simple binarizing of the target variable below. Worth noting here that there is an imbalance in my data, only ~20% of my samples are in the positive class (present murmur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28322b59-239d-4520-bc24-eeb89d6d6d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Absent     2391\n",
       "Present     616\n",
       "Name: Murmur, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Murmur'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7504c2b5-172e-4b2b-9a81-4ebd9a6097f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Murmur'] = df['Murmur'].map({\"Absent\": 0,\n",
    "                                 \"Present\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134bbf3e-1cde-48fd-91d1-a0484ee42f81",
   "metadata": {},
   "source": [
    "## Extracting a Signal DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50bb19b-95d9-477f-bd22-e72a48899fbb",
   "metadata": {},
   "source": [
    "With murmur's binarized, I now needed to deal with the problem of variable signal lengths. The goal was to create an array of signals of all equal length, and a column with my binary target. First, I want to do some simple descriptive statistics on the lengths of my signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "512a8ede-5ff6-4ee9-99be-56dd985fdba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     0.734131\n",
       "mean     22.894569\n",
       "std       7.297946\n",
       "min       5.152100\n",
       "25%      19.056152\n",
       "50%      21.488037\n",
       "75%      29.392090\n",
       "max      64.512207\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_df = df[['Murmur','signal']]\n",
    "\n",
    "signals = signal_df['signal']\n",
    "\n",
    "lengths = []\n",
    "for signal in signals:\n",
    "    lengths.append(len(signal))\n",
    "\n",
    "lengths = pd.Series(lengths)\n",
    "\n",
    "lengths.describe() / sr #sampling rate for the files in this set, so now the lengths are given in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1ffb21-3512-4e72-bfb3-a7a5c9be6af8",
   "metadata": {},
   "source": [
    "With some simple descriptive statistics of my signals, I can see that the average signal length is 22 seconds, min and max of 5 and 64 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f129dc3-795f-4b7d-bba3-2a3b70af207c",
   "metadata": {},
   "source": [
    "To achieve the above goal, I settled on a clip lengh of 12 seconds. I set an admittedly arbitrary threshold that I wanted 90% of the clips to be longer than the clip length I chose, so I wasn't trimming out too much actual data and padding a bunch of zeroes into my dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d92379a-5622-47a1-b353-6262fa054402",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1.0\n",
      "5 1.0\n",
      "6 0.9986697705354174\n",
      "7 0.9960093116062521\n",
      "8 0.9890256069171932\n",
      "9 0.9787163285666778\n",
      "10 0.9630861323578317\n",
      "11 0.9441303624875291\n",
      "12 0.9218490189557699\n",
      "13 0.8985700033255737\n",
      "14 0.8782840039906884\n",
      "15 0.8540073162620552\n",
      "16 0.8240771533089458\n",
      "17 0.79847023611573\n",
      "18 0.7751912204855338\n",
      "19 0.7509145327569006\n",
      "20 0.6508147655470569\n",
      "21 0.5340871300299301\n",
      "22 0.4672430994346525\n",
      "23 0.4286664449617559\n",
      "24 0.40239441303624873\n",
      "25 0.3831060857998005\n",
      "26 0.36647821749251747\n",
      "27 0.3518456933821084\n",
      "28 0.32790156301962087\n",
      "29 0.28633189225141337\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 30):\n",
    "    print(i, len(lengths[lengths > (i * sr)]) / len(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52655949-0c6e-4666-8121-61b2bd9dda17",
   "metadata": {},
   "source": [
    "The above cell shows that this breakpoint ocurrs somewhere between 12 and 13 seconds, this I set my `target_len` in seconds to 12. Multiplied by our sampling rate we get the number of samples to trim each array of amplitude data to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cceb5d7-9288-496d-8370-a57b004734b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_len = 12 * sr\n",
    "target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e06071db-3af1-41c4-b99a-60309007b6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_df['signal'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a564198-cb69-40bb-8e3f-e5c6b571ca46",
   "metadata": {},
   "source": [
    "From here I looped through each signal, trimming it if it was longer than `target_len` or padding it with zeroes if it was shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fa39e3b-d143-4542-962f-847442258221",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_signals = []\n",
    "for signal in signals:\n",
    "    if len(signal) == target_len:\n",
    "        new_signals.append(signal)\n",
    "    elif len(signal) > target_len:\n",
    "        new_signals.append(signal[0:target_len])\n",
    "    elif len(signal) < target_len:\n",
    "        padwidth = target_len-len(signal)\n",
    "        new_signals.append(np.pad(signal, (0, padwidth), mode='constant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5297a7a4-baa7-4bc9-a267-c9e7f0f1553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_signals = np.asarray(new_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb5aecce-6a13-4cd7-973b-da0c22b0ac23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3007, 49152)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_signals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6af9e3-bc8d-4e51-8be3-e20c5f2ff4b2",
   "metadata": {},
   "source": [
    "I then created a df from this to concatenate it with my original signal dataframe after dropping the un-processed signal data. I also did a quick sanity `nan` check. Also, there were a TON of x.shape sanity check cells throughout this notebook that I deleted to make the output cleaner, just a few left in to show what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45edae2d-5cca-459a-b0a0-9f24ef71338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/j9yckf9x41gbrplj0b23dt700000gn/T/ipykernel_38580/3757165246.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signal_df.drop('signal',axis=1,inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.DataFrame(new_signals)\n",
    "\n",
    "signal_df.drop('signal',axis=1,inplace=True)\n",
    "\n",
    "final_df = signal_df.join(temp_df)\n",
    "\n",
    "final_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d44c575-ddc5-4cc7-947b-a303c445fd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3007, 49153)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "153c2747-dd38-4a1e-ac61-28fa051a62c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3007 entries, 0 to 3006\n",
      "Columns: 49153 entries, Murmur to 49151\n",
      "dtypes: float32(49152), int64(1)\n",
      "memory usage: 563.8 MB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1c2f9-41b4-40a9-a0da-f6b163ff06c1",
   "metadata": {},
   "source": [
    "I checked the memory usage of the dataframe to ensure it wasn't too large, before saving it to a numpy array before pulling it into the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddab52bb-bb0e-4d76-80cb-635036735416",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(root_path + 'arrays/signal_murmur_presimple_4k.npy', final_df.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
